1
Foundation
1
Problem: Building a Network1
1.1 Applications2
1.1.1 Classes of Applications
1.2 Requirements3
6
1.2.1Stakeholders7
1.2.2Scalable Connectivity8
1.2.3Cost-Effective Resource Sharing13
1.2.4Support for Common Services17
1.2.5 Manageability
1.3 Architecture
22
23
1.3.1Layering and Protocols24
1.3.2Encapsulation28
1.3.3Multiplexing and Demultiplexing30
1.3.4Seven-Layer OSI Model31
1.3.5 Internet Architecture
1.4 Software
1.4.1
Application Programming Interface
(Sockets)
1.4.2 Example Application
1.5 Performance
33
36
37
40
43
1.5.1Bandwidth and Latency44
1.5.2Delay × Bandwidth Product49
1.5.3High-Speed Networks50
1.5.4 Application Performance Needs
Perspective: Feature Velocity52
55
xixxx
Contents
Broader Perspective
Exercises56
57
267
Direct Links
Problem: Connecting to a Network
2.1 Technology Landscape
2.2 Encoding
2.3 Framing
67
68
74
78
2.3.1Byte-Oriented Protocols (PPP)79
2.3.2Bit-Oriented Protocols (HDLC)81
2.3.3 Clock-Based Framing (SONET)
2.4 Error Detection83
87
2.4.1
Internet Checksum Algorithm
2.4.2 Cyclic Redundancy Check
2.5 Reliable Transmission
89
91
97
2.5.1Stop-and-Wait98
2.5.2Sliding Window100
2.5.3 Concurrent Logical Channels
2.6 Multiaccess Networks112
113
2.6.1Physical Properties114
2.6.2Access Protocol115
2.6.3 Longevity of Ethernet
2.7 Wireless Networks
120
121
2.7.1Basic Issues123
2.7.2802.11/Wi-Fi127
2.7.3 Bluetooth (802.15.1)
2.8 Access Networks
2.8.1
Passive Optical Network
2.8.2 Cellular Network
Perspective: Race to the Edge
Broader Perspective
Exercises
135
137
138
139
145
147
147

CHAPTER 1 Foundation
(keystrokes, voice, or video), and they typically connect to special-purpose devices
(terminals, hand receivers, and television sets).
What distinguishes a computer network from these other types of networks?
Probably the most important characteristic of a computer network is its generality.
Computer networks are built primarily from general-purpose programmable hard-
ware, and they are not optimized for a particular application like making phone calls
or delivering television signals. Instead, they are able to carry many different types of
data, and they support a wide, and ever-growing, range of applications. Today’s com-
puter networks have pretty much taken over the functions previously performed by
single-use networks. This chapter looks at some typical applications of computer
networks and discusses the requirements that a network designer who wishes to
support such applications must be aware of.
Once we understand the requirements, how do we proceed? Fortunately, we will
not be building the ﬁrst network. Others, most notably the community of researchers
responsible for the Internet, have gone before us. We will use the wealth of experience
generated from the Internet to guide our design. This experience is embodied in a
network architecture that identiﬁes the available hardware and software components
and shows how they can be arranged to form a complete network system.
In addition to understanding how networks are built, it is increasingly important
to understand how they are operated or managed and how network applications
are developed. Almost all of us now have computer networks in our homes, ofﬁces,
and in some cases in our cars, so operating networks is no longer a matter only
for a few specialists. And with the proliferation of smartphones, many more of this
generation are developing networked applications than in the past. So we need to
consider networks from these multiple perspectives: builders, operators, and appli-
cation developers.
To start us on the road toward understanding how to build, operate, and pro-
gram a network, this chapter does four things. First, it explores the requirements that
different applications and different communities of people place on the network.
Second, it introduces the idea of a network architecture, which lays the foundation
for the rest of the book. Third, it introduces some of the key elements in the imple-
mentation of computer networks. Finally, it identiﬁes the key metrics that are used
to evaluate the performance of computer networks.
1.1 APPLICATIONS
Most people know the Internet through its applications: the World Wide
Web, email, social media, streaming music or movies, videoconferenc-
ing, instant messaging, file-sharing, to name just a few examples. That1.1 Applications
is to say, we interact with the Internet as users of the network. Inter-
net users represent the largest class of people who interact with the
Internet in some way, but there are several other important constituen-
cies.
There is the group of people who create the applications—a group that
has greatly expanded in recent years as powerful programming platforms
and new devices such as smartphones have created new opportunities to
develop applications quickly and to bring them to a large market.
Then there are those who operate or manage networks—mostly a
behind-the-scenes job, but a critical one and often a very complex one.
With the prevalence of home networks, more and more people are also
becoming, if only in a small way, network operators.
Finally, there are those who design and build the devices and protocols
that collectively make up the Internet. That final constituency is the tradi-
tional target of networking textbooks such as this one and will continue to
be our main focus. However, throughout this book, we will also consider
the perspectives of application developers and network operators.
Considering these perspectives will enable us to better understand the
diverse requirements that a network must meet. Application developers
will also be able to make applications that work better if they understand
how the underlying technology works and interacts with the applications.
So, before we start figuring out how to build a network, let us look more
closely at the types of applications that today’s networks support.
1.1.1 Classes of Applications
The World Wide Web is the Internet application that catapulted the Inter-
net from a somewhat obscure tool used mostly by scientists and engi-
neers to the mainstream phenomenon that it is today. The Web itself has
become such a powerful platform that many people confuse it with the
Internet, and it is a bit of a stretch to say that the Web is a single applica-
tion.
In its basic form, the Web presents an intuitively simple interface. Users
view pages full of textual and graphical objects and click on objects that
they want to learn more about, and a corresponding new page appears.
Most people are also aware that just under the covers, each selectable
object on a page is bound to an identifier for the next page or object to
be viewed. This identifier, called a Uniform Resource Locator (URL), pro-
vides a way of identifying all the possible objects that can be viewed from
34
CHAPTER 1 Foundation
your web browser. For example,
http://www.cs.princeton.edu/~llp/index.html
is the URL for a page providing information about one of this book’s
authors: the string http indicates that the Hypertext Transfer Protocol
(HTTP) should be used to download the page, www.cs.princeton.edu is the
name of the machine that serves the page, and /~llp/index.html uniquely
identifies Larry’s home page at this site.
What most web users are not aware of, however, is that by clicking
on just one such URL, over a dozen messages may be exchanged over
the Internet, and many more than that if the web page is complicated
with lots of embedded objects. This message exchange includes up to
six messages to translate the server name (www.cs.princeton.edu) into its
Internet Protocol (IP) address (128.112.136.35), three messages to set up
a Transmission Control Protocol (TCP) connection between your browser
and this server, four messages for your browser to send the HTTP “GET”
request and for the server to respond with the requested page (and for
each side to acknowledge receipt of that message), and four messages to
tear down the TCP connection. Of course, this does not include the mil-
lions of messages exchanged by Internet nodes throughout the day, just
to let each other know that they exist and are ready to serve web pages,
translate names to addresses, and forward messages toward their ultimate
destination.
Another widespread application class of the Internet is the delivery
of “streaming” audio and video. Services such as video on demand and
Internet radio use this technology. While we frequently start at a web-
site to initiate a streaming session, the delivery of audio and video has
some important differences from fetching a simple web page of text and
images. For example, you often do not want to download an entire video
file—a process that might take a few minutes—before watching the first
scene. Streaming audio and video implies a more timely transfer of mes-
sages from sender to receiver, and the receiver displays the video or plays
the audio pretty much as it arrives.
Note that the difference between streaming applications and the more
traditional delivery of text, graphics, and images is that humans consume
audio and video streams in a continuous manner, and discontinuity—in
the form of skipped sounds or stalled video—is not acceptable. By con-
trast, a regular (nonstreaming) page can be delivered and read in bits and1.1 Applications
pieces. This difference affects how the network supports these different
classes of applications.
A subtly different application class is real-time audio and video. These
applications have considerably tighter timing constraints than streaming
applications. When using a voice-over-IP application such as Skype or a
videoconferencing application, the interactions among the participants
must be timely. When a person at one end gestures, then that action must
be displayed at the other end as quickly as possible.1
When one person tries to interrupt another, the interrupted person
needs to hear that as soon as possible and decide whether to allow the
interruption or to keep talking over the interrupter. Too much delay in this
sort of environment makes the system unusable. Contrast this with video
on demand where, if it takes several seconds from the time the user starts
the video until the first image is displayed, the service is still deemed sat-
isfactory. Also, interactive applications usually entail audio and/or video
flows in both directions, while a streaming application is most likely send-
ing video or audio in only one direction.
Videoconferencing tools that run over the Internet have been around
since the early 1990s but have achieved widespread use in the last few
years, with several commercial products on the market. An example of
one such system is shown in Figure 1.1. Just as downloading a web page
involves a bit more than meets the eye, so too with video applications. Fit-
ting the video content into a relatively low-bandwidth network, for exam-
ple, or making sure that the video and audio remain in sync and arrive in
time for a good user experience are all problems that network and proto-
col designers have to worry about. We will look at these and many other
issues related to multimedia applications later in the book.
Although they are just two examples, downloading pages from the
web and participating in a videoconference demonstrate the diversity
of applications that can be built on top of the Internet and hint at the
complexity of the Internet’s design. Later in the book, we will develop
a more complete taxonomy of application types to help guide our dis-
cussion of key design decisions as we seek to build, operate, and use
networks that have such a wide range of applications. The book con-
cludes by revisiting these two specific applications, as well as several
1 Not quite “as soon as possible”. . . Human factors research indicates 300 ms is a rea-
sonable upper bound for how much round-trip delay can be tolerated in a telephone
call before humans complain, and a 100-ms delay sounds very good.
56
CHAPTER 1 Foundation
■ FIGURE 1.1 A multimedia application including videoconferencing.
others that illustrate the breadth of what is possible on today’s Inter-
net. For now, this quick look at a few typical applications will suffice
to enable us to start looking at the problems that must be addressed
if we are to build a network that supports such application diversity.
1.2 REQUIREMENTS
We have established an ambitious goal for ourselves: to understand how
to build a computer network from the ground up. Our approach to
accomplishing this goal will be to start from first principles and then
ask the kinds of questions we would naturally ask if building an actual
network. At each step, we will use today’s protocols to illustrate various
design choices available to us, but we will not accept these existing arti-
facts as gospel. Instead, we will be asking (and answering) the question of1.2 Requirements
why networks are designed the way they are. While it is tempting to set-
tle for just understanding the way it is done today, it is important to recog-
nize the underlying concepts, because networks are constantly changing
as technology evolves and new applications are invented. It is our experi-
ence that once you understand the fundamental ideas, any new protocol
that you are confronted with will be relatively easy to digest.
1.2.1 Stakeholders
As we noted above, a student of networks can take several perspectives.
When we wrote the first edition of this book, the majority of the popula-
tion had no Internet access at all, and those who did obtained it while at
work, at a university, or by a dial-up modem at home. The set of popular
applications could be counted on one’s fingers. Thus, like most books at
the time, ours focused on the perspective of someone who would design
networking equipment and protocols. We continue to focus on this per-
spective, and our hope is that after reading this book, you will know how
to design the networking equipment and protocols of the future.
However, we also want to cover the perspectives of two additional
stakeholders: those who develop networked applications and those who
manage or operate networks. Let us consider how these three stakehold-
ers might list their requirements for a network:
■An application programmer would list the services that his or her
application needs: for example, a guarantee that each message the
application sends will be delivered without error within a certain
amount of time or the ability to switch gracefully among different
connections to the network as the user moves around.
■A network operator would list the characteristics of a system that
is easy to administer and manage: for example, faults can be easily
isolated, new devices can be added to the network and configured
correctly, and it is easy to account for usage.
■A network designer would list the properties of a cost-effective
design: for example, that network resources are efficiently utilized
and fairly allocated to different users. Issues of performance are also
likely to be important.
This section attempts to distill the requirements of different stake-
holders into a high-level introduction to the major considerations that
drive network design and, in doing so, identify the challenges addressed
throughout the rest of this book.
78
CHAPTER 1 Foundation
1.2.2 Scalable Connectivity
Starting with the obvious, a network must provide connectivity among a
set of computers. Sometimes it is enough to build a limited network that
connects only a few select machines. In fact, for reasons of privacy and
security, many private (corporate) networks have the explicit goal of lim-
iting the set of machines that are connected. In contrast, other networks
(of which the Internet is the prime example) are designed to grow in a way
that allows them the potential to connect all the computers in the world.
A system that is designed to support growth to an arbitrarily large size is
said to scale. Using the Internet as a model, this book addresses the chal-
lenge of scalability.
To understand the requirements of connectivity more fully, we need to
take a closer look at how computers are connected in a network. Connec-
tivity occurs at many different levels. At the lowest level, a network can
consist of two or more computers directly connected by some physical
medium, such as a coaxial cable or an optical fiber. We call such a phys-
ical medium a link, and we often refer to the computers it connects as
nodes. (Sometimes a node is a more specialized piece of hardware rather
than a computer, but we overlook that distinction for the purposes of this
discussion.) As illustrated in Figure 1.2, physical links are sometimes lim-
ited to a pair of nodes (such a link is said to be point-to-point), while in
other cases, more than two nodes may share a single physical link (such
a link is said to be multiple-access). Wireless links, such as those pro-
vided by cellular networks and Wi-Fi networks, are an important class of
multiple-access links. It is always the case that multiple-access links are
limited in size, in terms of both the geographical distance they can cover
and the number of nodes they can connect. For this reason, they often
implement the so-called last mile, connecting end users to the rest of the
network.
If computer networks were limited to situations in which all nodes
are directly connected to each other over a common physical medium,
then either networks would be very limited in the number of comput-
ers they could connect, or the number of wires coming out of the back
of each node would quickly become both unmanageable and very expen-
sive. Fortunately, connectivity between two nodes does not necessarily
imply a direct physical connection between them—indirect connectivity
may be achieved among a set of cooperating nodes. Consider the fol-
lowing two examples of how a collection of computers can be indirectly
connected.1.2 Requirements
■ FIGURE 1.2 Direct links: (a) point-to-point; (b) multiple-access.
Figure 1.3 shows a set of nodes, each of which is attached to one or
more point-to-point links. Those nodes that are attached to at least two
links run software that forwards data received on one link out on another.
If organized in a systematic way, these forwarding nodes form a switched
network. There are numerous types of switched networks, of which the
two most common are circuit-switched and packet-switched. The former
is most notably employed by the telephone system, while the latter is
used for the overwhelming majority of computer networks and will be
the focus of this book. (Circuit switching is, however, making a bit of a
comeback in the optical networking realm, which turns out to be impor-
tant as demand for network capacity constantly grows.) The important
feature of packet-switched networks is that the nodes in such a network
send discrete blocks of data to each other. Think of these blocks of data as
corresponding to some piece of application data such as a file, a piece of
email, or an image. We call each block of data either a packet or a message,
and for now we use these terms interchangeably.
Packet-switched networks typically use a strategy called store-and-
forward. As the name suggests, each node in a store-and-forward net-
work first receives a complete packet over some link, stores the packet in
its internal memory, and then forwards the complete packet to the next
node. In contrast, a circuit-switched network first establishes a dedicated
circuit across a sequence of links and then allows the source node to send
a stream of bits across this circuit to a destination node. The major rea-
son for using packet switching rather than circuit switching in a computer
network is efficiency, discussed in the next subsection.
910
CHAPTER 1 Foundation
■ FIGURE 1.3 Switched network.
The cloud in Figure 1.3 distinguishes between the nodes on the inside
that implement the network (they are commonly called switches, and
their primary function is to store and forward packets) and the nodes on
the outside of the cloud that use the network (they are traditionally called
hosts, and they support users and run application programs). Also note
that the cloud is one of the most important icons of computer network-
ing. In general, we use a cloud to denote any type of network, whether it is
a single point-to-point link, a multiple-access link, or a switched network.
Thus, whenever you see a cloud used in a figure, you can think of it as a
placeholder for any of the networking technologies covered in this book.2
A second way in which a set of computers can be indirectly connected is
showninFigure1.4.Inthissituation,asetofindependentnetworks(clouds)
2 The use of clouds to represent networks predates the term cloud computing by at
least a couple of decades, but there is an increasingly rich connection between these
two usages, which we explore in the Perspective discussion at the end of each chapter.1.2 Requirements
■ FIGURE 1.4 Interconnection of networks.
are interconnected to form an internetwork, or internet for short. We adopt
the Internet’s convention of referring to a generic internetwork of networks
as a lowercase i internet and to the TCP/IP Internet we all use every day as
the capital I Internet. A node that is connected to two or more networks is
commonly called a router or gateway, and it plays much the same role as a
switch—it forwards messages from one network to another. Note that an
internet can itself be viewed as another kind of network, which means that
an internet can be built from a set of internets. Thus, we can recursively
build arbitrarily large networks by interconnecting clouds to form larger
clouds. It can reasonably be argued that this idea of interconnecting widely
differing networks was the fundamental innovation of the Internet and that
the successful growth of the Internet to global size and billions of nodes
was the result of some very good design decisions by the early Internet
architects, which we will discuss later.
Just because a set of hosts is directly or indirectly connected to each
other does not mean that we have succeeded in providing host-to-host
connectivity. The final requirement is that each node must be able to
1112
CHAPTER 1 Foundation
say which of the other nodes on the network it wants to communicate
with. This is done by assigning an address to each node. An address is a
byte string that identifies a node; that is, the network can use a node’s
address to distinguish it from the other nodes connected to the network.
When a source node wants the network to deliver a message to a certain
destination node, it specifies the address of the destination node. If the
sending and receiving nodes are not directly connected, then the switches
and routers of the network use this address to decide how to forward the
message toward the destination. The process of determining systemati-
cally how to forward messages toward the destination node based on its
address is called routing.
SANs, LANs, MANs, and WANs
One way to characterize networks is according to their size. Two well-known
examples are LANs (local area networks) and WANs (wide area networks); the
former typically extend less than 1 km, while the latter can be worldwide.
Other networks are classiﬁed as MANs (metropolitan area networks), which
usually span tens of kilometers. The reason such classiﬁcations are interest-
ing is that the size of a network often has implications for the underlying
technology that can be used, with a key factor being the amount of time it
takes for data to propagate from one end of the network to the other; we
discuss this issue more in later chapters.
An interesting historical note is that the term “wide area network” was
not applied to the ﬁrst WANs because there was no other sort of network to
differentiate them from. When computers were incredibly rare and expen-
sive, there was no point in thinking about how to connect all the computers
in the local area—there was only one computer in that area. Only as comput-
ers began to proliferate did LANs become necessary, and the term “WAN”
was then introduced to describe the larger networks that interconnected
geographically distant computers.
Another kind of network that we need to be aware of is SANs (usually
now expanded as storage area networks, but formerly also known as sys-
tem area networks). SANs are usually conﬁned to a single room and connect
the various components of a large computing system. For example, Fiber
Channel is a common SAN technology used to connect high-performance
computing systems to storage servers and data vaults. Although this book
does not describe such networks in detail, they are worth knowing about
because they are often at the leading edge in terms of performance and
because it is increasingly common to connect such networks into LANs and
WANs.1.2 Requirements
This brief introduction to addressing and routing has presumed that
the source node wants to send a message to a single destination node
(unicast). While this is the most common scenario, it is also possible that
the source node might want to broadcast a message to all the nodes on the
network. Or a source node might want to send a message to some subset
of the other nodes but not all of them, a situation called multicast. Thus,
in addition to node-specific addresses, another requirement of a network
is that it supports multicast and broadcast addresses.
The main idea to take away from this discussion is that we can deﬁne a network
recursively as consisting of two or more nodes connected by a physical link or as
two or more networks connected by a node. In other words, a network can be
constructed from a nesting of networks, where at the bottom level, the network is
implemented by some physical medium. Among the key challenges in providing
network connectivity are the deﬁnition of an address for each node that is reach-
able on the network (be it logical or physical), and the use of such addresses to
forward messages toward the appropriate destination node(s).
1.2.3 Cost-Effective Resource Sharing
As stated above, this book focuses on packet-switched networks. This sec-
tion explains the key requirement of computer networks—efficiency—
that leads us to packet switching as the strategy of choice.
Given a collection of nodes indirectly connected by a nesting of net-
works, it is possible for any pair of hosts to send messages to each other
across a sequence of links and nodes. Of course, we want to do more than
support just one pair of communicating hosts—we want to provide all
pairs of hosts with the ability to exchange messages. The question, then,
is how do all the hosts that want to communicate share the network, espe-
cially if they want to use it at the same time? And, as if that problem is not
hard enough, how do several hosts share the same link when they all want
to use it at the same time?
To understand how hosts share a network, we need to introduce a fun-
damental concept, multiplexing, which means that a system resource is
shared among multiple users. At an intuitive level, multiplexing can be
explained by analogy to a time-sharing computer system, where a single
physical processor is shared (multiplexed) among multiple jobs, each of
which believes it has its own private processor. Similarly, data being sent
by multiple users can be multiplexed over the physical links that make up
a network.
1314
CHAPTER 1 Foundation
To see how this might work, consider the simple network illustrated in
Figure 1.5, where the three hosts on the left side of the network (senders
S1–S3) are sending data to the three hosts on the right (receivers R1–R3)
by sharing a switched network that contains only one physical link. (For
simplicity, assume that host S1 is sending data to host R1, and so on.)
In this situation, three flows of data—corresponding to the three pairs of
hosts—are multiplexed onto a single physical link by switch 1 and then
demultiplexed back into separate flows by switch 2. Note that we are being
intentionally vague about exactly what a “flow of data” corresponds to.
For the purposes of this discussion, assume that each host on the left has
a large supply of data that it wants to send to its counterpart on the right.
■ FIGURE 1.5 Multiplexing multiple logical ﬂows over a single physical link.
There are several different methods for multiplexing multiple flows
onto one physical link. One common method is synchronous time-
division multiplexing (STDM). The idea of STDM is to divide time into
equal-sized quanta and, in a round-robin fashion, give each flow a chance
to send its data over the physical link. In other words, during time quan-
tum 1, data from S1 to R1 are transmitted; during time quantum 2, data
from S2 to R2 are transmitted; in quantum 3, S3 sends data to R3. At this
point, the first flow (S1 to R1) gets to go again, and the process repeats.
Another method is frequency-division multiplexing (FDM). The idea of
FDM is to transmit each flow over the physical link at a different fre-
quency, much the same way that the signals for different TV stations are
transmitted at a different frequency over the airwaves or on a coaxial cable
TV link.1.2 Requirements
Although simple to understand, both STDM and FDM are limited in
two ways. First, if one of the flows (host pairs) does not have any data
to send, its share of the physical link—that is, its time quantum or its
frequency—remains idle, even if one of the other flows has data to trans-
mit. For example, S3 had to wait its turn behind S1 and S2 in the previous
paragraph, even if S1 and S2 had nothing to send. For computer com-
munication, the amount of time that a link is idle can be very large—for
example, consider the amount of time you spend reading a web page
(leaving the link idle) compared to the time you spend fetching the page.
Second, both STDM and FDM are limited to situations in which the maxi-
mum number of flows is fixed and known ahead of time. It is not practical
to resize the quantum or to add additional quanta in the case of STDM or
to add new frequencies in the case of FDM.
The form of multiplexing that addresses these shortcomings, and of
which we make most use in this book, is called statistical multiplexing.
Although the name is not all that helpful for understanding the concept,
statistical multiplexing is really quite simple, with two key ideas. First, it
is like STDM in that the physical link is shared over time—first data from
one flow are transmitted over the physical link, then data from another
flow are transmitted, and so on. Unlike STDM, however, data are trans-
mitted from each flow on demand rather than during a predetermined
time slot. Thus, if only one flow has data to send, it gets to transmit those
data without waiting for its quantum to come around and thus without
having to watch the quanta assigned to the other flows go by unused. It is
this avoidance of idle time that gives packet switching its efficiency.
As defined so far, however, statistical multiplexing has no mechanism
to ensure that all the flows eventually get their turn to transmit over the
physical link. That is, once a flow begins sending data, we need some
way to limit the transmission, so that the other flows can have a turn.
To account for this need, statistical multiplexing defines an upper bound
on the size of the block of data that each flow is permitted to transmit at
a given time. This limited-size block of data is typically referred to as a
packet, to distinguish it from the arbitrarily large message that an applica-
tion program might want to transmit. Because a packet-switched network
limits the maximum size of packets, a host may not be able to send a
complete message in one packet. The source may need to fragment the
message into several packets, with the receiver reassembling the packets
back into the original message.
1516
CHAPTER 1 Foundation
■ FIGURE 1.6 A switch multiplexing packets from multiple sources onto one shared link.
In other words, each flow sends a sequence of packets over the physical
link, with a decision made on a packet-by-packet basis as to which flow’s
packet to send next. Note that if only one flow has data to send, then it
can send a sequence of packets back-to-back; however, should more than
one of the flows have data to send, then their packets are interleaved on
the link. Figure 1.6 depicts a switch multiplexing packets from multiple
sources onto a single shared link.
The decision as to which packet to send next on a shared link can be
made in a number of different ways. For example, in a network consist-
ing of switches interconnected by links such as the one in Figure 1.5, the
decision would be made by the switch that transmits packets onto the
shared link. (As we will see later, not all packet-switched networks actu-
ally involve switches, and they may use other mechanisms to determine
whose packet goes onto the link next.) Each switch in a packet-switched
network makes this decision independently, on a packet-by-packet basis.
One of the issues that faces a network designer is how to make this deci-
sion in a fair manner. For example, a switch could be designed to service
packets on a first-in, first-out (FIFO) basis. Another approach would be
to transmit the packets from each of the different flows that are currently
sending data through the switch in a round-robin manner. This might be
done to ensure that certain flows receive a particular share of the link’s
bandwidth or that they never have their packets delayed in the switch for
more than a certain length of time. A network that attempts to allocate1.2 Requirements
bandwidth to particular flows is sometimes said to support quality of ser-
vice (QoS).
Also, note in Figure 1.6 that since the switch has to multiplex three
incoming packet streams onto one outgoing link, it is possible that the
switch will receive packets faster than the shared link can accommodate.
In this case, the switch is forced to buffer these packets in its mem-
ory. Should a switch receive packets faster than it can send them for an
extended period of time, then the switch will eventually run out of buffer
space, and some packets will have to be dropped. When a switch is oper-
ating in this state, it is said to be congested.
The bottom line is that statistical multiplexing deﬁnes a cost-effective way for
multiple users (e.g., host-to-host ﬂows of data) to share network resources (links
and nodes) in a ﬁne-grained manner. It deﬁnes the packet as the granularity with
which the links of the network are allocated to different ﬂows, with each switch
able to schedule the use of the physical links it is connected to on a per-packet
basis. Fairly allocating link capacity to different ﬂows and dealing with congestion
when it occurs are the key challenges of statistical multiplexing.
1.2.4 Support for Common Services
The previous discussion focused on the challenges involved in providing
cost-effective connectivity among a group of hosts, but it is overly sim-
plistic to view a computer network as simply delivering packets among a
collection of computers. It is more accurate to think of a network as pro-
viding the means for a set of application processes that are distributed
over those computers to communicate. In other words, the next require-
ment of a computer network is that the application programs running on
the hosts connected to the network must be able to communicate in a
meaningful way. From the application developer’s perspective, the net-
work needs to make his or her life easier.
When two application programs need to communicate with each
other, a lot of complicated things must happen beyond simply sending
a message from one host to another. One option would be for application
designers to build all that complicated functionality into each application
program. However, since many applications need common services, it is
much more logical to implement those common services once and then
to let the application designer build the application using those services.
The challenge for a network designer is to identify the right set of com-
1718
CHAPTER 1 Foundation
mon services. The goal is to hide the complexity of the network from the
application without overly constraining the application designer.
■ FIGURE 1.7 Processes communicating over an abstract channel.
Intuitively, we view the network as providing logical channels over
which application-level processes can communicate with each other;
each channel provides the set of services required by that application. In
other words, just as we use a cloud to abstractly represent connectivity
among a set of computers, we now think of a channel as connecting one
process to another. Figure 1.7 shows a pair of application-level processes
communicating over a logical channel that is, in turn, implemented on
top of a cloud that connects a set of hosts. We can think of the channel as
being like a pipe connecting two applications, so that a sending applica-
tion can put data in one end and expect that data to be delivered by the
network to the application at the other end of the pipe.
Like any abstraction, logical process-to-process channels are imple-
mented on top of a collection of physical host-to-host channels. This
is the essence of layering, the cornerstone of network architectures dis-
cussed in the next section.
The challenge is to recognize what functionality the channels should
provide to application programs. For example, does the application1.2 Requirements
require a guarantee that messages sent over the channel are delivered,
or is it acceptable if some messages fail to arrive? Is it necessary that mes-
sages arrive at the recipient process in the same order in which they are
sent, or does the recipient not care about the order in which messages
arrive? Does the network need to ensure that no third parties are able
to eavesdrop on the channel, or is privacy not a concern? In general, a
network provides a variety of different types of channels, with each appli-
cation selecting the type that best meets its needs. The rest of this section
illustrates the thinking involved in defining useful channels.
Identify Common Communication Patterns
Designing abstract channels involves first understanding the communi-
cation needs of a representative collection of applications, then extracting
their common communication requirements, and finally incorporating
the functionality that meets these requirements in the network.
One of the earliest applications supported on any network is a file
access program like the File Transfer Protocol (FTP) or Network File Sys-
tem (NFS). Although many details vary—for example, whether whole files
are transferred across the network or only single blocks of the file are
read/written at a given time—the communication component of remote
file access is characterized by a pair of processes, one that requests that a
file be read or written and a second process that honors this request. The
process that requests access to the file is called the client, and the process
that supports access to the file is called the server.
Reading a file involves the client sending a small request message to a
server and the server responding with a large message that contains the
data in the file. Writing works in the opposite way—the client sends a large
message containing the data to be written to the server, and the server
responds with a small message confirming that the write to disk has taken
place.
A digital library is a more sophisticated application than file transfer,
but it requires similar communication services. For example, the Associ-
ation for Computing Machinery (ACM) operates a large digital library of
computer science literature at
http://portal.acm.org/dl.cfm
This library has a wide range of searching and browsing features to help
users find the articles they want, but ultimately, much of what it does is
1920
CHAPTER 1 Foundation
respond to user requests for files, such as electronic copies of journal arti-
cles.
Using file access, a digital library, and the two video applications
described in the introduction (videoconferencing and video on demand)
as a representative sample, we might decide to provide the following two
types of channels: request/reply channels and message stream channels.
The request/reply channel would be used by the file transfer and digital
library applications. It would guarantee that every message sent by one
side is received by the other side and that only one copy of each message
is delivered. The request/reply channel might also protect the privacy and
integrity of the data that flow over it, so that unauthorized parties cannot
read or modify the data being exchanged between the client and server
processes.
The message stream channel could be used by both the video-on-
demand and videoconferencing applications, provided it is parameter-
ized to support both one-way and two-way traffic and to support different
delay properties. The message stream channel might not need to guaran-
tee that all messages are delivered, since a video application can operate
adequately even if some video frames are not received. It would, however,
need to ensure that those messages that are delivered arrive in the same
order in which they were sent to avoid displaying frames out of sequence.
Like the request/reply channel, the message stream channel might want
to ensure the privacy and integrity of the video data. Finally, the message
stream channel might need to support multicast so that multiple parties
can participate in the teleconference or view the video.
While it is common for a network designer to strive for the small-
est number of abstract channel types that can serve the largest num-
ber of applications, there is a danger in trying to get away with too few
channel abstractions. Simply stated, if you have a hammer, then every-
thing looks like a nail. For example, if all you have are message stream
and request/reply channels, then it is tempting to use them for the next
application that comes along, even if neither type provides exactly the
semantics needed by the application. Thus, network designers will prob-
ably be inventing new types of channels—and adding options to exist-
ing channels—for as long as application programmers are inventing new
applications.
Also note that independently of exactly what functionality a given
channel provides, there is the question of where that functionality is1.2 Requirements
implemented. In many cases, it is easiest to view the host-to-host con-
nectivity of the underlying network as simply providing a bit pipe, with
any high-level communication semantics provided at the end hosts. The
advantage of this approach is that it keeps the switches in the middle
of the network as simple as possible—they simply forward packets—but
it requires the end hosts to take on much of the burden of support-
ing semantically rich process-to-process channels. The alternative is to
push additional functionality onto the switches, thereby allowing the end
hosts to be “dumb” devices (e.g., telephone handsets). We will see this
question of how various network services are partitioned between the
packet switches and the end hosts (devices) as a recurring issue in net-
work design.
Reliable Message Delivery
As suggested by the examples just considered, reliable message delivery
is one of the most important functions that a network can provide. It
is difficult to determine how to provide this reliability, however, without
first understanding how networks can fail. The first thing to recognize is
that computer networks do not exist in a perfect world. Machines crash
and later are rebooted, fibers are cut, electrical interference corrupts bits
in the data being transmitted, switches run out of buffer space, and, as
if these sorts of physical problems are not enough to worry about, the
software that manages the hardware may contain bugs and sometimes
forwards packets into oblivion. Thus, a major requirement of a network is
to recover from certain kinds of failures so that application programs do
not have to deal with them or even be aware of them.
There are three general classes of failure that network designers have to
worry about. First, as a packet is transmitted over a physical link, bit errors
may be introduced into the data; that is, a 1 is turned into a 0 or vice versa.
Sometimes single bits are corrupted, but more often than not, a burst
error occurs—several consecutive bits are corrupted. Bit errors typically
occur because outside forces, such as lightning strikes, power surges, and
microwave ovens, interfere with the transmission of data. The good news
is that such bit errors are fairly rare, affecting on average only one out of
every 106 to 107 bits on a typical copper-based cable and one out of every
1012 to 1014 bits on a typical optical fiber. As we will see, there are tech-
niques that detect these bit errors with high probability. Once detected,
it is sometimes possible to correct for such errors—if we know which bit
or bits are corrupted, we can simply flip them—while in other cases, the
2122
CHAPTER 1 Foundation
damage is so bad that it is necessary to discard the entire packet. In such
a case, the sender may be expected to retransmit the packet.
The second class of failure is at the packet, rather than the bit, level;
that is, a complete packet is lost by the network. One reason this can hap-
pen is that the packet contains an uncorrectable bit error and therefore
has to be discarded. A more likely reason, however, is that one of the nodes
that has to handle the packet—for example, a switch that is forwarding it
from one link to another—is so overloaded that it has no place to store the
packet and therefore is forced to drop it. This is the problem of congestion
just discussed. Less commonly, the software running on one of the nodes
that handles the packet makes a mistake. For example, it might incorrectly
forward a packet out on the wrong link so that the packet never finds its
way to the ultimate destination. As we will see, one of the main difficul-
ties in dealing with lost packets is distinguishing between a packet that is
indeed lost and one that is merely late in arriving at the destination.
The third class of failure is at the node and link level; that is, a physical
link is cut, or the computer it is connected to crashes. This can be caused
by software that crashes, a power failure, or a reckless backhoe operator.
Failures due to misconfiguration of a network device are also common.
While any of these failures can eventually be corrected, they can have a
dramatic effect on the network for an extended period of time. However,
they need not totally disable the network. In a packet-switched network,
for example, it is sometimes possible to route around a failed node or link.
One of the difficulties in dealing with this third class of failure is distin-
guishing between a failed computer and one that is merely slow or, in the
case of a link, between one that has been cut and one that is very flaky
and therefore introduces a high number of bit errors.
The key idea to take away from this discussion is that deﬁning useful chan-
nels involves both understanding the applications’ requirements and recognizing
the limitations of the underlying technology. The challenge is to ﬁll in the gap
between what the application expects and what the underlying technology can
provide. This is sometimes called the semantic gap.
1.2.5 Manageability
A final requirement, which seems to be neglected or left until last all
too often (as we do here), is that networks need to be managed. Man-
aging a network includes upgrading equipment as the network grows1.3 Architecture
to carry more traffic or reach more users, troubleshooting the network
when things go wrong or performance is not as desired, and adding new
features in support of new applications. Network management has his-
torically been a human-intensive aspect of networking, and while it is
unlikely we will get people entirely out of the loop, it is increasingly being
addressed by automation and self-healing designs.
This requirement is partly related to the issue of scalability discussed
above—as the Internet has scaled up to support billions of users and at
least hundreds of millions of hosts, the challenges of keeping the whole
thing running correctly and correctly configuring new devices as they are
added have become increasingly problematic. Configuring a single router
in a network is often a task for a trained expert; configuring thousands
of routers and figuring out why a network of such a size is not behav-
ing as expected can become a task beyond any single human. This is why
automation is becoming so important.
One way to make a network easier to manage is to avoid change. Once
the network is working, simply do not touch it! This mindset exposes the
fundamental tension between stability and feature velocity: the rate at
which new capabilities are introduced into the network. Favoring sta-
bility is the approach the telecommunications industry (not to mention
university system administrators and corporate IT departments) adopted
for many years, making it one of the most slow-moving and risk-averse
industries you will find anywhere. But the recent explosion of the cloud
has changed that dynamic, making it necessary to bring stability and fea-
ture velocity more into balance. The impact of the cloud on the network is
a topic that comes up over and over throughout the book, and one we pay
particular attention to in the Perspective section at the end of each chap-
ter. For now, suffice it to say that managing a rapidly evolving network is
arguably the central challenge in networking today.
1.3 ARCHITECTURE
The previous section established a pretty substantial set of requirements
for network design—a computer network must provide general, cost-
effective, fair, and robust connectivity among a large number of com-
puters. As if this were not enough, networks do not remain fixed at any
single point in time but must evolve to accommodate changes in both
the underlying technologies upon which they are based and changes in
the demands placed on them by application programs. Furthermore, net-
2324
CHAPTER 1 Foundation
works must be manageable by humans of varying levels of skill. Designing
a network to meet these requirements is no small task.
To help deal with this complexity, network designers have developed
general blueprints—usually called network architectures—that guide the
design and implementation of networks. This section defines more care-
fully what we mean by a network architecture by introducing the central
ideas that are common to all network architectures. It also introduces
two of the most widely referenced architectures—the OSI (or seven-layer)
architecture and the Internet architecture.
1.3.1 Layering and Protocols
Abstraction—the hiding of implementation details behind a well-defined
interface—is the fundamental tool used by system designers to manage
complexity. The idea of an abstraction is to define a model that can cap-
ture some important aspect of the system, encapsulate this model in
an object that provides an interface that can be manipulated by other
components of the system, and hide the details of how the object is
implemented from the users of the object. The challenge is to identify
abstractions that simultaneously provide a service that proves useful in
a large number of situations and that can be efficiently implemented in
the underlying system. This is exactly what we were doing when we intro-
duced the idea of a channel in the previous section: we were providing
an abstraction for applications that hides the complexity of the network
from application writers.
Abstractions naturally lead to layering, especially in network systems.
The general idea is that you start with the services offered by the underly-
ing hardware and then add a sequence of layers, each providing a higher
(more abstract) level of service. The services provided at the high lay-
ers are implemented in terms of the services provided by the low layers.
Drawing on the discussion of requirements given in the previous sec-
tion, for example, we might imagine a simple network as having two lay-
ers of abstraction sandwiched between the application program and the
underlying hardware, as illustrated in Figure 1.8. The layer immediately
above the hardware in this case might provide host-to-host connectivity,
abstracting away the fact that there may be an arbitrarily complex net-
work topology between any two hosts. The next layer up builds on the
available host-to-host communication service and provides support for
process-to-process channels, abstracting away the fact that the network
occasionally loses messages, for example.1.3 Architecture
■ FIGURE 1.8 Example of a layered network system.
Layering provides two useful features. First, it decomposes the problem
of building a network into more manageable components. Rather than
implementing a monolithic piece of software that does everything you
will ever want, you can implement several layers, each of which solves
one part of the problem. Second, it provides a more modular design. If
you decide that you want to add some new service, you may only need to
modify the functionality at one layer, reusing the functions provided at all
the other layers.
Thinking of a system as a linear sequence of layers is an oversimpli-
fication, however. Many times, there are multiple abstractions provided
at any given level of the system, each providing a different service to the
higher layers but building on the same low-level abstractions. To see this,
consider the two types of channels discussed in the previous section. One
provides a request/reply service and one supports a message stream ser-
vice. These two channels might be alternative offerings at some level of a
multilevel networking system, as illustrated in Figure 1.9.
■ FIGURE 1.9 Layered system with alternative abstractions available at a given layer.
Using this discussion of layering as a foundation, we are now ready
to discuss the architecture of a network more precisely. For starters, the
abstract objects that make up the layers of a network system are called
protocols. That is, a protocol provides a communication service that
higher-level objects (such as application processes, or perhaps higher-
level protocols) use to exchange messages. For example, we could imagine
2526
CHAPTER 1 Foundation
a network that supports a request/reply protocol and a message stream
protocol, corresponding to the request/reply and message stream chan-
nels discussed above.
Each protocol defines two different interfaces. First, it defines a ser-
vice interface to the other objects on the same computer that want to
use its communication services. This service interface defines the oper-
ations that local objects can perform on the protocol. For example, a
request/reply protocol would support operations by which an application
can send and receive messages. An implementation of the HTTP protocol
could support an operation to fetch a page of hypertext from a remote
server. An application such as a web browser would invoke such an oper-
ation whenever the browser needs to obtain a new page (e.g., when the
user clicks on a link in the currently displayed page).
Second, a protocol defines a peer interface to its counterpart (peer) on
another machine. This second interface defines the form and meaning
of messages exchanged between protocol peers to implement the com-
munication service. This would determine the way in which a request/
reply protocol on one machine communicates with its peer on another
machine. In the case of HTTP, for example, the protocol specification
defines in detail how a GET command is formatted, what arguments can
be used with the command, and how a web server should respond when
it receives such a command.
To summarize, a protocol defines a communication service that it
exports locally (the service interface), along with a set of rules governing
the messages that the protocol exchanges with its peer(s) to implement
this service (the peer interface). This situation is illustrated in Figure 1.10.
■ FIGURE 1.10 Service interfaces and peer interfaces.1.3 Architecture
■ FIGURE 1.11 Example of a protocol graph.
Except at the hardware level, where peers directly communicate with
each other over a physical medium, peer-to-peer communication is
indirect—each protocol communicates with its peer by passing mes-
sages to some lower-level protocol, which in turn delivers the message
to its peer. In addition, there is potentially more than one protocol at any
given level, each providing a different communication service. We there-
fore represent the suite of protocols that make up a network system with
a protocol graph. The nodes of the graph correspond to protocols, and
the edges represent a depends on relation. For example, Figure 1.11 illus-
trates a protocol graph for the hypothetical layered system we have been
discussing—RRP (Request/Reply Protocol) and MSP (Message Stream
Protocol) implement two different types of process-to-process channels,
and both depend on the Host-to-Host Protocol (HHP), which provides a
host-to-host connectivity service.
In this example, suppose that the file access program on host 1 wants
to send a message to its peer on host 2 using the communication ser-
vice offered by RRP. In this case, the file application asks RRP to send the
2728
CHAPTER 1 Foundation
message on its behalf. To communicate with its peer, RRP invokes the ser-
vices of HHP, which in turn transmits the message to its peer on the other
machine. Once the message has arrived at the instance of HHP on host 2,
HHP passes the message up to RRP, which in turn delivers the message
to the file application. In this particular case, the application is said to
employ the services of the protocol stack RRP/HHP.
Note that the term protocol is used in two different ways. Sometimes it
refers to the abstract interfaces—that is, the operations defined by the ser-
vice interface and the form and meaning of messages exchanged between
peers—and sometimes it refers to the module that actually implements
these two interfaces. To distinguish between the interfaces and the mod-
ule that implements these interfaces, we generally refer to the former
as a protocol specification. Specifications are generally expressed using a
combination of prose, pseudocode, state transition diagrams, pictures of
packet formats, and other abstract notations. It should be the case that
a given protocol can be implemented in different ways by different pro-
grammers, as long as each adheres to the specification. The challenge
is ensuring that two different implementations of the same specification
can successfully exchange messages. Two or more protocol modules that
do accurately implement a protocol specification are said to interoperate
with each other.
We can imagine many different protocols and protocol graphs that
satisfy the communication requirements of a collection of applications.
Fortunately, there exist standardization bodies, such as the Internet Engi-
neering Task Force (IETF) and the International Standards Organization
(ISO), that establish policies for a particular protocol graph. We call the
set of rules governing the form and content of a protocol graph a network
architecture. Although beyond the scope of this book, standardization
bodies have established well-defined procedures for introducing, validat-
ing, and finally approving protocols in their respective architectures. We
briefly describe the architectures defined by the IETF and ISO shortly,
but first, there are two additional things we need to explain about the
mechanics of protocol layering.
1.3.2 Encapsulation
Consider what happens when one of the application programs sends a
message to its peer by passing the message to RRP. From RRP’s perspec-
tive, the message it is given by the application is an uninterpreted string
of bytes. RRP does not care that these bytes represent an array of inte-1.3 Architecture
gers, an email message, a digital image, or whatever; it is simply charged
with sending them to its peer. However, RRP must communicate control
information to its peer, instructing it how to handle the message when
it is received. RRP does this by attaching a header to the message. Gen-
erally speaking, a header is a small data structure—from a few bytes to
a few dozen bytes—that is used among peers to communicate with each
other. As the name suggests, headers are usually attached to the front of a
message. In some cases, however, this peer-to-peer control information is
sent at the end of the message, in which case it is called a trailer. The exact
format for the header attached by RRP is defined by its protocol specifi-
cation. The rest of the message—that is, the data being transmitted on
behalf of the application—is called the message’s body or payload. We say
that the application’s data are encapsulated in the new message created
by RRP.
■ FIGURE 1.12 High-level messages are encapsulated inside low-level messages.
This process of encapsulation is then repeated at each level of the pro-
tocol graph; for example, HHP encapsulates RRP’s message by attaching
2930
CHAPTER 1 Foundation
a header of its own. If we now assume that HHP sends the message to
its peer over some network, then when the message arrives at the des-
tination host, it is processed in the opposite order: HHP first interprets
the HHP header at the front of the message (i.e., takes whatever action is
appropriate given the contents of the header) and passes the body of the
message (but not the HHP header) up to RRP, which takes whatever action
is indicated by the RRP header that its peer attached and passes the body
of the message (but not the RRP header) up to the application program.
The message passed up from RRP to the application on host 2 is exactly
the same message as the application passed down to RRP on host 1; the
application does not see any of the headers that have been attached to
it to implement the lower-level communication services. This whole pro-
cess is illustrated in Figure 1.12. Note that in this example, nodes in the
network (e.g., switches and routers) may inspect the HHP header at the
front of the message.
Note that when we say a low-level protocol does not interpret the mes-
sage it is given by some high-level protocol, we mean that it does not
know how to extract any meaning from the data contained in the mes-
sage. It is sometimes the case, however, that the low-level protocol applies
some simple transformation to the data it is given, such as to compress or
encrypt it. In this case, the protocol is transforming the entire body of the
message, including both the original application’s data and all the headers
attached to those data by higher-level protocols.
1.3.3 Multiplexing and Demultiplexing
Recall that a fundamental idea of packet switching is to multiplex mul-
tiple flows of data over a single physical link. This same idea applies up
and down the protocol graph, not just to switching nodes. In Figure 1.11,
for example, we can think of RRP as implementing a logical communica-
tion channel, with messages from two different applications multiplexed
over this channel at the source host and then demultiplexed back to the
appropriate application at the destination host.
Practically speaking, this simply means that the header that RRP
attaches to its messages contains an identifier that records the application
to which the message belongs. We call this identifier RRP’s demultiplexing
key, or demux key for short. At the source host, RRP includes the appro-
priate demux key in its header. When the message is delivered to RRP on
the destination host, it strips its header, examines the demux key, and
demultiplexes the message to the correct application.1.3 Architecture
RRP is not unique in its support for multiplexing; nearly every protocol
implements this mechanism. For example, HHP has its own demux key
to determine which messages to pass up to RRP and which to pass up
to MSP. However, there is no uniform agreement among protocols—even
those within a single network architecture—on exactly what constitutes a
demux key. Some protocols use an 8-bit field (meaning they can support
only 256 high-level protocols), and others use 16- or 32-bit fields. Also,
some protocols have a single demultiplexing field in their header, while
others have a pair of demultiplexing fields. In the former case, the same
demux key is used on both sides of the communication, while in the latter
case, each side uses a different key to identify the high-level protocol (or
application program) to which the message is to be delivered.
1.3.4 Seven-Layer OSI Model
The ISO was one of the first organizations to formally define a common
way to connect computers. Their architecture, called the Open Systems
Interconnection (OSI) architecture and illustrated in Figure 1.13, defines a
partitioning of network functionality into seven layers, where one or more
protocols implement the functionality assigned to a given layer. In this
sense, the schematic given is not a protocol graph per se but rather a ref-
erence model for a protocol graph. It is often referred to as the seven-layer
model. While there is no OSI-based network running today, the terminol-
ogy it defined is still widely used, so it is still worth a cursory look.
Starting at the bottom and working up, the physical layer handles the
transmission of raw bits over a communications link. The data link layer
then collects a stream of bits into a larger aggregate called a frame. Net-
work adaptors, along with device drivers running in the node’s operating
system, typically implement the data link level. This means that frames,
not raw bits, are actually delivered to hosts. The network layer handles
routing among nodes within a packet-switched network. At this layer, the
unit of data exchanged among nodes is typically called a packet rather
than a frame, although they are fundamentally the same thing. The lower
three layers are implemented on all network nodes, including switches
within the network and hosts connected to the exterior of the network.
The transport layer then implements what we have up to this point been
calling a process-to-process channel. Here, the unit of data exchanged is
commonly called a message rather than a packet or a frame. The trans-
port layer and higher layers typically run only on the end hosts and not
on the intermediate switches or routers.
3132
CHAPTER 1 Foundation
■ FIGURE 1.13 The OSI seven-layer model.
Skipping ahead to the top (seventh) layer and working our way back
down, we find the application layer. Application-layer protocols include
things like the Hypertext Transfer Protocol (HTTP), which is the basis of
the World Wide Web and is what enables web browsers to request pages
from web servers. Below that, the presentation layer is concerned with
the format of data exchanged between peers—for example, whether an
integer is 16, 32, or 64 bits long, whether the most significant byte is trans-
mitted first or last, or how a video stream is formatted. Finally, the session
layer provides a name space that is used to tie together the potentially
different transport streams that are part of a single application. For exam-
ple, it might manage an audio stream and a video stream that are being
combined in a teleconferencing application.1.3 Architecture
1.3.5 Internet Architecture
The Internet architecture, which is also sometimes called the TCP/IP
architecture after its two main protocols, is depicted in Figure 1.14. An
alternative representation is given in Figure 1.15. The Internet architec-
ture evolved out of experiences with an earlier packet-switched network
called the ARPANET. Both the Internet and the ARPANET were funded by
the Advanced Research Projects Agency (ARPA), one of the research and
development funding agencies of the U.S. Department of Defense. The
Internet and ARPANET were around before the OSI architecture, and the
experience gained from building them was a major influence on the OSI
reference model.
■ FIGURE 1.14 Internet protocol graph.
■ FIGURE 1.15 Alternative view of the Internet architecture. The “subnetwork” layer was historically referred to as the
“network” layer and is now often referred to as “layer 2” (inﬂuenced by the OSI model).
While the seven-layer OSI model can, with some imagination, be
applied to the Internet, a simpler stack is often used instead. At the low-
est level is a wide variety of network protocols, denoted NET1 , NET2 ,
and so on. In practice, these protocols are implemented by a combina-
tion of hardware (e.g., a network adaptor) and software (e.g., a network
device driver). For example, you might find Ethernet or wireless proto-
cols (such as the 802.11 Wi-Fi standards) at this layer. (These protocols in
turn may actually involve several sublayers, but the Internet architecture
3334
CHAPTER 1 Foundation
does not presume anything about them.) The next layer consists of a sin-
gle protocol—the Internet Protocol (IP). This is the protocol that supports
the interconnection of multiple networking technologies into a single,
logical internetwork. The layer on top of IP contains two main protocols—
the Transmission Control Protocol (TCP) and the User Datagram Protocol
(UDP). TCP and UDP provide alternative logical channels to application
programs: TCP provides a reliable byte-stream channel, and UDP pro-
vides an unreliable datagram delivery channel (datagram may be thought
of as a synonym for message). In the language of the Internet, TCP and
UDP are sometimes called end-to-end protocols, although it is equally
correct to refer to them as transport protocols.
Running above the transport layer is a range of application protocols,
such as HTTP, FTP, Telnet (remote login), and the Simple Mail Transfer
Protocol (SMTP), that enable the interoperation of popular applications.
To understand the difference between an application layer protocol and
an application, think of all the different World Wide Web browsers that are
or have been available (e.g., Firefox, Chrome, Safari, Netscape, Mosaic,
Internet Explorer). There is a similarly large number of different imple-
mentations of web servers. The reason that you can use any one of these
application programs to access a particular site on the Web is that they all
conform to the same application layer protocol: HTTP. Confusingly, the
same term sometimes applies to both an application and the application
layer protocol that it uses (e.g., FTP is often used as the name of an appli-
cation that implements the FTP protocol).
Most people who work actively in the networking field are familiar with
both the Internet architecture and the seven-layer OSI architecture, and
there is general agreement on how the layers map between architectures.
The Internet’s application layer is considered to be at layer 7, its transport
layer is layer 4, the IP (internetworking or just network) layer is layer 3,
and the link or subnet layer below IP is layer 2.
The Internet architecture has three features that are worth highlight-
ing. First, as best illustrated by Figure 1.15, the Internet architecture does
not imply strict layering. The application is free to bypass the defined
transport layers and to directly use IP or one of the underlying networks.
In fact, programmers are free to define new channel abstractions or appli-
cations that run on top of any of the existing protocols.
Second, if you look closely at the protocol graph in Figure 1.14, you will
notice an hourglass shape—wide at the top, narrow in the middle, and
wide at the bottom. This shape actually reflects the central philosophy of1.3 Architecture
the architecture. That is, IP serves as the focal point for the architecture—
it defines a common method for exchanging packets among a wide col-
lection of networks. Above IP, there can be arbitrarily many transport
protocols, each offering a different channel abstraction to application
programs. Thus, the issue of delivering messages from host to host is com-
pletely separated from the issue of providing a useful process-to-process
communication service. Below IP, the architecture allows for arbitrarily
many different network technologies, ranging from Ethernet to wireless
to single point-to-point links.
A final attribute of the Internet architecture (or, more accurately, of the
IETF culture) is that in order for a new protocol to be officially included in
the architecture, there must be both a protocol specification and at least
one (and preferably two) representative implementations of the specifica-
tion. The existence of working implementations is required for standards
to be adopted by the IETF. This cultural assumption of the design com-
munity helps to ensure that the architecture’s protocols can be efficiently
implemented. Perhaps the value the Internet culture places on working
software is best exemplified by a quote on T-shirts commonly worn at
IETF meetings:
We reject kings, presidents, and voting. We believe in rough consensus and
running code.
(David Clark)
IETF and standardization
Although we call it the “Internet architecture” rather than the “IETF archi-
tecture,” it is fair to say that the IETF is the primary standardization body
responsible for its deﬁnition, as well as the speciﬁcation of many of its pro-
tocols, such as TCP, UDP, IP, DNS, and BGP. But the Internet architecture
also embraces many protocols deﬁned by other organizations, including
IEEE’s 802.11 Ethernet and Wi-Fi standards, W3C’s HTTP/HTML web speciﬁca-
tions, 3GPP’s 4G and 5G cellular networks standards, and ITU-T’s H.232 video
encoding standards, to name a few.
In addition to deﬁning architectures and specifying protocols, there are
yet other organizations that support the larger goal of interoperability. One
example is the IANA (Internet Assigned Numbers Authority), which, as its
name implies, is responsible for handing out the unique identiﬁers needed
to make the protocols work. IANA, in turn, is a department within the ICANN
(Internet Corporation for Assigned Names and Numbers), a nonproﬁt orga-
nization that is responsible for the overall stewardship of the Internet.
3536
CHAPTER 1 Foundation
Of these three attributes of the Internet architecture, the hourglass design philos-
ophy is important enough to bear repeating. The hourglass’s narrow waist repre-
sents a minimal and carefully chosen set of global capabilities that allows both
higher-level applications and lower-level communication technologies to coex-
ist, share capabilities, and evolve rapidly. The narrow-waist model is critical to the
Internet’s ability to adapt to new user demands and changing technologies.
1.4 SOFTWARE
Network architectures and protocol specifications are essential things,
but a good blueprint is not enough to explain the phenomenal success
of the Internet: The number of computers connected to the Internet has
grown exponentially for over three decades (although precise numbers
are hard to come by). The number of users of the Internet was estimated
to be around 4.1 billion by the end of 2018—roughly half of the world’s
population.
What explains the success of the Internet? There are certainly many
contributing factors (including a good architecture), but one thing that
has made the Internet such a runaway success is the fact that so much
of its functionality is provided by software running on general-purpose
computers. The significance of this is that new functionality can be added
readily with “just a small matter of programming.” As a result, new appli-
cations and services have been showing up at an incredible pace.
A related factor is the massive increase in computing power available
in commodity machines. Although computer networks have always been
capable in principle of transporting any kind of information, such as dig-
ital voice samples, digitized images, and so on, this potential was not
particularly interesting if the computers sending and receiving those data
were too slow to do anything useful with the information. Virtually all of
today’s computers are capable of playing back digitized audio and video
at a speed and resolution that are quite usable.
In the years since the first edition of this book appeared, the writing
of networked applications has become a mainstream activity and not a
job just for a few specialists. Many factors have played into this, including
better tools to make the job easier and the opening up of new markets
such as applications for smartphones.
The point to note is that knowing how to implement network software
is an essential part of understanding computer networks, and while the odds are you will not be tasked to implement a low-level protocol like IP,
there is a good chance you will find reason to implement an application-
level protocol—the elusive “killer app” that will lead to unimaginable
fame and fortune. To get you started, this section introduces some of
the issues involved in implementing a network application on top of the
Internet. Typically, such programs are simultaneously an application (i.e.,
designed to interact with users) and a protocol (i.e., communicates with
peers across the network).
1.4.1 Application Programming Interface (Sockets)
The place to start when implementing a network application is the inter-
face exported by the network. Since most network protocols are in soft-
ware (especially those high in the protocol stack) and nearly all computer
systems implement their network protocols as part of the operating sys-
tem, when we refer to the interface “exported by the network,” we are
generally referring to the interface that the OS provides to its network-
ing subsystem. This interface is often called the network application pro-
gramming interface (API).
Although each operating system is free to define its own network API
(and most have), over time, certain of these APIs have become widely sup-
ported; that is, they have been ported to operating systems other than
their native system. This is what has happened with the socket interface
originally provided by the Berkeley distribution of Unix, which is now sup-
ported in virtually all popular operating systems and is the foundation of
language-specific interfaces, such as the Java or Python socket library. We
use Linux and C for all code examples in this book, Linux because it is
open source and C because it remains the language of choice for network
internals. (C also has the advantage of exposing all the low-level details,
which is helpful in understanding the underlying ideas.)
Before describing the socket interface, it is important to keep two
concerns separate in your mind. Each protocol provides a certain set
of services, and the API provides a syntax by which those services can
be invoked on a particular computer system. The implementation is
then responsible for mapping the tangible set of operations and objects
defined by the API onto the abstract set of services defined by the proto-
col. If you have done a good job of defining the interface, then it will be
possible to use the syntax of the interface to invoke the services of many
different protocols. Such generality was certainly a goal of the socket
interface, although it is far from perfect.
3738
CHAPTER 1 Foundation
The main abstraction of the socket interface, not surprisingly, is the
socket. A good way to think of a socket is as the point where a local applica-
tion process attaches to the network. The interface defines operations for
creating a socket, attaching the socket to the network, sending/receiving
messages through the socket, and closing the socket. To simplify the dis-
cussion, we will limit ourselves to showing how sockets are used with TCP.
The first step is to create a socket, which is done with the following
operation:
int socket(int domain, int type, int protocol);
The reason that this operation takes three arguments is that the socket
interface was designed to be general enough to support any underlying
protocol suite. Specifically, the domain argument specifies the protocol
family that is going to be used: PF_INET denotes the Internet family,
PF_UNIX denotes the Unix pipe facility, and PF_PACKET denotes direct
access to the network interface (i.e., it bypasses the TCP/IP protocol
stack). The type argument indicates the semantics of the communica-
tion. SOCK_STREAM is used to denote a byte stream. SOCK_DGRAM is
an alternative that denotes a message-oriented service, such as that pro-
vided by UDP. The protocol argument identifies the specific protocol that
is going to be used. In our case, this argument is UNSPEC because the
Sockets enabled application explosion
It is hard to overstate the importance of the socket API. It deﬁnes the demar-
cation point between the applications running on top of the Internet and
the details of how the Internet is implemented. As a consequence of sock-
ets providing a well-deﬁned and stable interface, writing Internet applica-
tions exploded into a multibillion-dollar industry. Starting from the humble
beginnings of the client/server paradigm and a handful of simple application
programs like email, ﬁle transfer, and remote login, everyone now has access
to a never-ending supply of cloud applications from their smartphones.
This section lays the foundation by revisiting the simplicity of a client
program opening a socket so it can exchange messages with a server pro-
gram, but today, a rich software ecosystem is layered on top of the socket
API. This layer includes a plethora of cloud-based tools that lower the barrier
for implementing scalable applications. We return to the interplay between
the cloud and the network in every chapter, starting with the Perspective sec-
tion at the end of Chapter 1.1.4 Software
combination of PF_INET and SOCK_STREAM implies TCP. Finally, the
return value from socket is a handle for the newly created socket—that is,
an identifier by which we can refer to the socket in the future. It is given
as an argument to subsequent operations on this socket.
The next step depends on whether you are a client or a server. On a
server machine, the application process performs a passive open—the
server says that it is prepared to accept connections, but it does not actu-
ally establish a connection. The server does this by invoking the following
three operations:
int bind(int socket, struct sockaddr *address, int addr_len);
int listen(int socket, int backlog);
int accept(int socket, struct sockaddr *address, int *addr_len);
The bind operation, as its name suggests, binds the newly created
socket to the specified address. This is the network address of the local
participant—the server. Note that, when used with the Internet protocols,
address is a data structure that includes both the IP address of the server
and a TCP port number. Ports are used to indirectly identify processes.
They are a form of demux keys. The port number is usually some well-
known number specific to the service being offered; for example, web
servers commonly accept connections on port 80.
The listen operation then defines how many connections can be pend-
ing on the specified socket. Finally, the accept operation carries out the
passive open. It is a blocking operation that does not return until a remote
participant has established a connection, and when it does complete, it
returns a new socket that corresponds to this just-established connec-
tion, and the address argument contains the remote participant’s address.
Note that when accept returns, the original socket that was given as an
argument still exists and still corresponds to the passive open; it is used in
future invocations of accept.
On the client machine, the application process performs an active
open; that is, it says who it wants to communicate with by invoking the
following single operation:
int connect(int socket, struct sockaddr *address, int addr_len);
This operation does not return until TCP has successfully established a
connection, at which time the application is free to begin sending data. In
this case, address contains the remote participant’s address. In practice,
the client usually specifies only the remote participant’s address and lets
3940
CHAPTER 1 Foundation
the system fill in the local information. Whereas a server usually listens
for messages on a well-known port, a client typically does not care which
port it uses for itself; the OS simply selects an unused one.
Once a connection is established, the application processes invoke the
following two operations to send and receive data:
int send(int socket, char *message, int msg_len, int flags);
int recv(int socket, char *buffer, int buf_len, int flags);
The first operation sends the given message over the specified socket,
while the second operation receives a message from the specified socket
into the given buffer. Both operations take a set of flags that control certain
details of the operation.
1.4.2 Example Application
We now show the implementation of a simple client/server program that
uses the socket interface to send messages over a TCP connection. The
program also uses other Linux networking utilities, which we introduce
as we go. Our application allows a user on one machine to type in and
send text to a user on another machine. It is a simplified version of the
Linux talk program, which is similar to the program at the core of instant
messaging applications.
Client
We start with the client side, which takes the name of the remote machine
as an argument. It calls the Linux utility to translate this name into the
remote host’s IP address. The next step is to construct the address data
structure (sin) expected by the socket interface. Note that this data struc-
ture specifies that we will be using the socket to connect to the Internet
(AF_INET). In our example, we use TCP port 5432 as the well-known
server port; this happens to be a port that has not been assigned to any
other Internet service. The final step in setting up the connection is to call
socket and connect. Once the operation returns, the connection is estab-
lished and the client program enters its main loop, which reads text from
standard input and sends it over the socket.
#include <stdio.h>
#include <sys/types.h>
#include <sys/socket.h>
#include <netinet/in.h>
#include <netdb.h>1.4 Software
#define SERVER_PORT 5432
#define MAX_LINE 256
int
main(int argc, char * argv[])
{
FILE *fp;
struct hostent *hp;
struct sockaddr_in sin;
char *host;
char buf[MAX_LINE];
int s;
int len;
if (argc==2) {
host = argv[1];
}
else {
fprintf(stderr, "usage: simplex-talk host\n");
exit(1);
}
/* translate host name into peer’s IP address */
hp = gethostbyname(host);
if (!hp) {
fprintf(stderr, "simplex-talk: unknown host: %s\n", host);
exit(1);
}
/* build address data structure */
bzero((char *)&sin, sizeof(sin));
sin.sin_family = AF_INET;
bcopy(hp->h_addr, (char *)&sin.sin_addr, hp->h_length);
sin.sin_port = htons(SERVER_PORT);
/* active open */
if ((s = socket(PF_INET, SOCK_STREAM, 0)) < 0) {
perror("simplex-talk: socket");
exit(1);
4142
CHAPTER 1 Foundation
}
if (connect(s, (struct sockaddr *)&sin, sizeof(sin)) < 0)
{
perror("simplex-talk: connect");
close(s);
exit(1);
}
/* main loop: get and send lines of text */
while (fgets(buf, sizeof(buf), stdin)) {
buf[MAX_LINE-1] = ’\0’;
len = strlen(buf) + 1;
send(s, buf, len, 0);
}
}
Server
The server is equally simple. It first constructs the address data structure
by filling in its own port number (SERVER_PORT). By not specifying an
IP address, the application program is willing to accept connections on
any of the local host’s IP addresses. Next, the server performs the prelimi-
nary steps involved in a passive open; it creates the socket, binds it to the
local address, and sets the maximum number of pending connections to
be allowed. Finally, the main loop waits for a remote host to try to con-
nect, and when one does, it receives and prints out the characters that
arrive on the connection.
#include <stdio.h>
#include <sys/types.h>
#include <sys/socket.h>
#include <netinet/in.h>
#include <netdb.h>
#define SERVER_PORT5432
#define MAX_PENDING5
#define MAX_LINE256
int
main()
{
struct sockaddr_in sin;1.5 Performance
char buf[MAX_LINE];
int buf_len, addr_len;
int s, new_s;
/* build address data structure */
bzero((char *)&sin, sizeof(sin));
sin.sin_family = AF_INET;
sin.sin_addr.s_addr = INADDR_ANY;
sin.sin_port = htons(SERVER_PORT);
/* setup passive open */
if ((s = socket(PF_INET, SOCK_STREAM, 0)) < 0) {
perror("simplex-talk: socket");
exit(1);
}
if ((bind(s, (struct sockaddr *)&sin, sizeof(sin))) < 0) {
perror("simplex-talk: bind");
exit(1);
}
listen(s, MAX_PENDING);
/* wait for connection, then receive and print text */
while(1) {
if ((new_s = accept(s, (struct sockaddr *)&sin, &addr_len)) < 0)
{
perror("simplex-talk: accept");
exit(1);
}
while (buf_len = recv(new_s, buf, sizeof(buf), 0))
fputs(buf, stdout);
close(new_s);
}
}
1.5 PERFORMANCE
Up to this point, we have focused primarily on the functional aspects of
networks. Like any computer system, however, computer networks are
also expected to perform well. This is because the effectiveness of com-
putations distributed over the network often depends directly on the effi-
ciency with which the network delivers the computation’s data. While the
4344
CHAPTER 1 Foundation
old programming adage “first get it right and then make it fast” remains
true, in networking, it is often necessary to “design for performance.” It
is therefore important to understand the various factors that impact net-
work performance.
1.5.1 Bandwidth and Latency
Network performance is measured in two fundamental ways: bandwidth
(also called throughput) and latency (also called delay). The bandwidth
of a network is given by the number of bits that can be transmitted over
the network in a certain period of time. For example, a network might
have a bandwidth of 10 million bits/second (Mbps), meaning that it is
able to deliver 10 million bits every second. It is sometimes useful to think
of bandwidth in terms of how long it takes to transmit each bit of data. On
a 10-Mbps network, for example, it takes 0.1 microsecond (µs) to transmit
each bit.
Bandwidth and throughput are subtly different terms. First of all, band-
width is literally a measure of the width of a frequency band. For example,
legacy voice-grade telephone lines supported a frequency band ranging
from 300 to 3300 Hz; it was said to have a bandwidth of 3300 Hz − 300 Hz =
3000 Hz. If you see the word bandwidth used in a situation in which it is
being measured in hertz, then it probably refers to the range of signals
that can be accommodated.
When we talk about the bandwidth of a communication link, we nor-
mally refer to the number of bits per second that can be transmitted on
the link. This is also sometimes called the data rate. We might say that the
bandwidth of an Ethernet link is 10 Mbps. A useful distinction can also
be made, however, between the maximum data rate that is available on
the link and the number of bits per second that we can actually transmit
over the link in practice. We tend to use the word throughput to refer to
the measured performance of a system. Thus, because of various ineffi-
ciencies of implementation, a pair of nodes connected by a link with a
bandwidth of 10 Mbps might achieve a throughput of only 2 Mbps. This
would mean that an application on one host could send data to the other
host at 2 Mbps.
Finally, we often talk about the bandwidth requirements of an applica-
tion. This is the number of bits per second that it needs to transmit over
the network to perform acceptably. For some applications, this might be
“whatever I can get”; for others, it might be some fixed number (prefer-
ably not more than the available link bandwidth); and for others, it might1.5 Performance
be a number that varies with time. We will provide more on this topic later
in this section.
While you can talk about the bandwidth of the network as a whole,
sometimes you want to be more precise, focusing, for example, on the
bandwidth of a single physical link or of a logical process-to-process
channel. At the physical level, bandwidth is constantly improving, with no
end in sight. Intuitively, if you think of a second of time as a distance you
could measure with a ruler and bandwidth as how many bits fit in that dis-
tance, then you can think of each bit as a pulse of some width. For exam-
ple, each bit on a 1-Mbps link is 1 µs wide, while each bit on a 2-Mbps link
is 0.5 µs wide, as illustrated in Figure 1.16. The more sophisticated the
transmitting and receiving technology, the narrower each bit can become
and, thus, the higher the bandwidth. For logical process-to-process chan-
nels, bandwidth is also influenced by other factors, including how many
times the software that implements the channel has to handle, and possi-
bly transform, each bit of data.
■ FIGURE 1.16 Bits transmitted at a particular bandwidth can be regarded as having some width: (a) bits transmitted at
1 Mbps (each bit is 1 microsecond wide); (b) bits transmitted at 2 Mbps (each bit is 0.5 microseconds wide).
The second performance metric, latency, corresponds to how long it
takes a message to travel from one end of a network to the other. (As with
bandwidth, we could focus on the latency of a single link or an end-to-
end channel.) Latency is measured strictly in terms of time. For example,
a transcontinental network might have a latency of 24 ms; that is, it takes
a message 24 ms to travel from one coast of North America to the other.
There are many situations in which it is more important to know how long
it takes to send a message from one end of a network to the other and back
rather than the one-way latency. We call this the round-trip time (RTT) of
the network.
We often think of latency as having three components. First, there is
the speed-of-light propagation delay. This delay occurs because nothing,
4546
CHAPTER 1 Foundation
including a bit on a wire, can travel faster than the speed of light. If you
know the distance between two points, you can calculate the speed-of-
light latency, although you have to be careful, because light travels across
different media at different speeds: it travels at 3.0 × 108 m/s in a vacuum,
2.3 × 108 m/s in a copper cable, and 2.0 × 108 m/s in an optical fiber. Sec-
ond, there is the amount of time it takes to transmit a unit of data. This is
a function of the network bandwidth and the size of the packet in which
the data are carried. Third, there may be queuing delays inside the net-
work, since packet switches generally need to store packets for some time
before forwarding them on an outbound link. So we could define the total
latency as
Latency = Propagation + Transmit + Queue
Propagation = Distance/SpeedOfLight
Transmit = Size/Bandwidth
where Distance is the length of the wire over which the data will travel,
SpeedOfLight is the effective speed of light over that wire, Size is the size of
the packet, and Bandwidth is the bandwidth at which the packet is trans-
mitted. Note that if the message contains only 1 bit and we are talking
about a single link (as opposed to a whole network), then the Transmit
and Queue terms are not relevant, and latency corresponds to the propa-
gation delay only.
Bandwidth and latency combine to define the performance charac-
teristics of a given link or channel. Their relative importance, however,
depends on the application. For some applications, latency dominates
bandwidth. For example, a client that sends a 1-byte message to a server
and receives a 1-byte message in return is latency bound. Assuming that
no serious computation is involved in preparing the response, the appli-
cation will perform much differently on a transcontinental channel with a
100-ms RTT than it will on an across-the-room channel with a 1-ms RTT.
Whether the channel is 1 Mbps or 100 Mbps is relatively insignificant,
however, since the former implies that the time to transmit a byte (Trans-
mit) is 8 µs and the latter implies Transmit = 0.08 µs.
In contrast, consider a digital library program that is being asked to
fetch a 25-MB image—the more bandwidth that is available, the faster it
will be able to return the image to the user. Here, the bandwidth of the
channel dominates performance. To see this, suppose that the channel
has a bandwidth of 10 Mbps. It will take 20 seconds to transmit the image
(25 × 106 × 8 bits / (10 × 106 Mbps = 20 seconds), making it relatively1.5 Performance
unimportant if the image is on the other side of a 1-ms channel or a 100-
ms channel; the difference between a 20.001-second response time and a
20.1-second response time is negligible.
How big is a “mega”?
There are several pitfalls you need to be aware of when working with the
common units of networking, such as MB and Mbps. The ﬁrst is to distin-
guish carefully between bits and bytes. Throughout this book, we always use
a lowercase b for bits and a capital B for bytes. The second is to be sure you
are using the appropriate deﬁnition of giga (G), mega (M), and kilo (K). Mega,
for example, can mean either 220 or 106 . Similarly, kilo can mean either 210
or 103 , and giga can mean either 230 or 109 . What is worse, in networking,
we typically use both deﬁnitions. Here is why.
Network bandwidth, which is often speciﬁed in terms of Mbps, is typically
governed by the speed of the clock that paces the transmission of the bits. A
clock that is running at 10 MHz is used to transmit bits at 10 Mbps. Because
the mega in MHz means 106 hertz, Mbps is usually also deﬁned as 106 bits
per second. (Similarly, Gbps is 109 bits per second.) On the other hand, when
we talk about a message that we want to transmit, we often give its size in
bytes. Because messages are stored in the computer’s memory, and memory
is typically measured in powers of two, the K in kB is usually taken to mean
210 . (Similarly, MB usually means 220 and GB usually means 230 .) When you
put the two together, it is not uncommon to talk about sending a 64-kB mes-
sage over a 100-Mbps channel, which should be interpreted to mean 64 ×
210 × 8 bits are being transmitted at a rate of 100 × 106 bits per second. This
is the interpretation we use throughout the book, unless explicitly stated
otherwise.
The good news is that many times, we are satisﬁed with a back-of-the-
envelope calculation, in which case it is perfectly reasonable to make the
approximation that 106 is really equal to 220 (making it easy to convert
between the two deﬁnitions of mega). This approximation introduces only
a 5% error. We can even make the approximation in some cases that a byte
has 10 bits, a 20% error but good enough for order-of-magnitude estimates.
While we are making quick-and-dirty calculations, 100 ms is a reasonable
number to use for a cross-country round-trip time—at least when the coun-
try in question is the United States—and 1 ms is a good approximation of
an RTT across a local area network. In the case of the former, we increase the
48-ms round-trip time implied by the speed of light over a ﬁber to 100 ms,
because there are, as we have said, other sources of delay, such as the pro-
cessing time in the switches inside the network. You can also be sure that
the path taken by the ﬁber between two points will not be a straight line.
4748
CHAPTER 1 Foundation
■ FIGURE 1.17 Perceived latency (response time) versus round-trip time for various object sizes and link speeds.
Figure 1.17 gives you a sense of how latency or bandwidth can domi-
nate performance in different circumstances. The graph shows how long
it takes to move objects of various sizes (1 byte, 2 kB, 1 MB) across net-
works with RTTs ranging from 1 to 100 ms and link speeds of either 1.5
or 10 Mbps. We use logarithmic scales to show relative performance. For
a 1-byte object (say, a keystroke), latency remains almost exactly equal to
the RTT, so that you cannot distinguish between a 1.5-Mbps network and
a 10-Mbps network. For a 2-kB object (say, an email message), the link
speed makes quite a difference on a 1-ms RTT network but a negligible
difference on a 100-ms RTT network. And for a 1-MB object (say, a digital
image), the RTT makes no difference—it is the link speed that dominates
performance across the full range of RTT.
Note that throughout this book, we use the terms latency and delay in a
generic way to denote how long it takes to perform a particular function,
such as delivering a message or moving an object. When we are referring
to the specific amount of time it takes a signal to propagate from one end
of a link to another, we use the term propagation delay. Also, we make it1.5 Performance
clear in the context of the discussion whether we are referring to the one-
way latency or the round-trip time.
As an aside, computers are becoming so fast that when we connect
them to networks, it is sometimes useful to think, at least figuratively, in
terms of instructions per mile. Consider what happens when a computer
that is able to execute 100 billion instructions per second sends a message
out on a channel with a 100-ms RTT. (To make the math easier, assume
that the message covers a distance of 5000 miles.) If that computer sits
idle the full 100 ms waiting for a reply message, then it has forfeited the
ability to execute 10 billion instructions, or 2 million instructions per mile.
It had better have been worth going over the network to justify this waste.
1.5.2 Delay × Bandwidth Product
It is also useful to talk about the product of these two metrics, often
called the delay × bandwidth product. Intuitively, if we think of a chan-
nel between a pair of processes as a hollow pipe (see Figure 1.18), where
the latency corresponds to the length of the pipe and the bandwidth gives
the diameter of the pipe, then the delay × bandwidth product gives the
volume of the pipe—the maximum number of bits that could be in transit
through the pipe at any given instant. Said another way, if latency (mea-
sured in time) corresponds to the length of the pipe, then given the width
of each bit (also measured in time), you can calculate how many bits fit in
the pipe. For example, a transcontinental channel with a one-way latency
of 50 ms and a bandwidth of 45 Mbps is able to hold
50 × 10−3 sec × 45 × 106 bits/sec = 2.25 × 106 bits,
or approximately 280 kB of data. In other words, this example channel
(pipe) holds as many bytes as the memory of a personal computer from
the early 1980s could hold.
■ FIGURE 1.18 Network as a pipe.
The delay × bandwidth product is important to know when construct-
ing high-performance networks because it corresponds to how many bits
the sender must transmit before the first bit arrives at the receiver. If the
4950
CHAPTER 1 Foundation
sender is expecting the receiver to somehow signal that bits are starting
to arrive, and it takes another channel latency for this signal to propagate
back to the sender, then the sender can send up one RTT × bandwidth
worth of data before hearing from the receiver that all is well. The bits
in the pipe are said to be “in flight,” which means that if the receiver
tells the sender to stop transmitting, it might receive up to one RTT ×
bandwidth’s worth of data before the sender manages to respond. In our
example above, that amount corresponds to 5.5 × 106 bits (671 kB) of data.
On the other hand, if the sender does not fill the pipe—i.e., does not send
a whole RTT × bandwidth product’s worth of data before it stops to wait
for a signal—the sender will not fully utilize the network.
Note that most of the time we are interested in the RTT scenario, which
we simply refer to as the delay × bandwidth product, without explicitly
saying that “delay” is the RTT (i.e., multiply the one-way delay by two).
Usually, whether the “delay” in delay × bandwidth means one-way latency
or RTT is made clear by the context. Table 1.1 shows some examples of
RTT × bandwidth products for some typical network links.
Table 1.1 Example delay × bandwidth products.
Link type
Wireless LAN
Satellite
Cross-country ﬁber
BandwidthOne-way
distanceRTTRTT × bandwidth
54 Mbps
1 Gbps
10 Gbps50 m
35,000 km
4000 km0.33 μs
230 ms
40 ms18 bits
230 Mb
400 Mb
1.5.3 High-Speed Networks
The seeming continual increase in bandwidth causes network designers
to start thinking about what happens in the limit or, stated another way,
what is the impact on network design of having infinite bandwidth avail-
able.
Although high-speed networks bring a dramatic change in the band-
width available to applications, in many respects, their impact on how
we think about networking comes in what does not change as bandwidth
increases: the speed of light. To quote Scotty from Star Trek, “Ye cannae
change the laws of physics.” In other words, “high speed” does not mean
that latency improves at the same rate as bandwidth; the transcontinental
RTT of a 1-Gbps link is the same 100 ms as it is for a 1-Mbps link.
To appreciate the significance of ever-increasing bandwidth in the face
of fixed latency, consider what is required to transmit a 1-MB file over a1.5 Performance
1-Mbps network versus over a 1-Gbps network, both of which have an
RTT of 100 ms. In the case of the 1-Mbps network, it takes 80 round-trip
times to transmit the file; during each RTT, 1.25% of the file is sent. In
contrast, the same 1-MB file does not even come close to filling 1 RTT’s
worth of the 1-Gbps link, which has a delay × bandwidth product of
12.5 MB.
Figure 1.19 illustrates the difference between the two networks. In
effect, the 1-MB file looks like a stream of data that needs to be trans-
mitted across a 1-Mbps network, while it looks like a single packet on a
1-Gbps network. To help drive this point home, consider that a 1-MB file
is to a 1-Gbps network what a 1-kB packet is to a 1-Mbps network.
■ FIGURE 1.19 Relationship between bandwidth and latency. A 1-MB ﬁle would ﬁll the 1-Mbps link 80 times but only
ﬁll 1/12th of a 1-Gbps link.
Another way to think about the situation is that more data can be trans-
mitted during each RTT on a high-speed network, so much so that a single
RTT becomes a significant amount of time. Thus, while you would not
think twice about the difference between a file transfer taking 101 RTTs
rather than 100 RTTs (a relative difference of only 1%), suddenly the differ-
ence between 1 RTT and 2 RTTs is significant—a 100% increase. In other
words, latency, rather than throughput, starts to dominate our thinking
about network design.
Perhaps the best way to understand the relationship between through-
put and latency is to return to basics. The effective end-to-end throughput
that can be achieved over a network is given by the simple relationship
5152
CHAPTER 1 Foundation
Throughput = TransferSize / TransferTime,
where TransferTime includes not only the elements of one-way identified
earlier in this section but also any additional time spent requesting or set-
ting up the transfer. Generally, we represent this relationship as
TransferTime = RTT + 1/Bandwidth × TransferSize
We use in this calculation to account for a request message being sent
across the network and the data being sent back. For example, consider a
situation where a user wants to fetch a 1-MB file across a 1-Gbps network
with a round-trip time of 100 ms. This includes both the transmit time for
1 MB (1 / 1 Gbps × 1 MB = 8 ms) and the 100-ms RTT, for a total transfer
time of 108 ms. This means that the effective throughput will be
1 MB / 108 ms = 74.1 Mbps,
not 1 Gbps. Clearly, transferring a larger amount of data will help improve
the effective throughput, where in the limit, an infinitely large transfer size
will cause the effective throughput to approach the network bandwidth.
On the other hand, having to endure more than 1 RTT—for example, to
retransmit missing packets—will hurt the effective throughput for any
transfer of finite size and will be most noticeable for small transfers.
1.5.4 Application Performance Needs
The discussion in this section has taken a network-centric view of perfor-
mance; that is, we have talked in terms of what a given link or channel
will support. The unstated assumption has been that application pro-
grams have simple needs—they want as much bandwidth as the network
can provide. This is certainly true of the aforementioned digital library
program that is retrieving a 250-MB image; the more bandwidth that is
available, the faster the program will be able to return the image to the
user.
However, some applications are able to state an upper limit on how
much bandwidth they need. Video applications are a prime example.
Suppose one wants to stream a video that is one-quarter the size of a stan-
dard TV screen; that is, it has a resolution of 352 by 240 pixels. If each pixel
is represented by 24 bits of information, as would be the case for 24-bit
color, then the size of each frame would be (352 × 240 × 24) / 8 = 247.5 kB.
If the application needs to support a frame rate of 30 frames per second,1.5 Performance
then it might request a throughput rate of 75 Mbps. The ability of the net-
work to provide more bandwidth is of no interest to such an application
because it has only so much data to transmit in a given period of time.
Unfortunately, the situation is not as simple as this example sug-
gests. Because the difference between any two adjacent frames in a video
stream is often small, it is possible to compress the video by transmit-
ting only the differences between adjacent frames. Each frame can also
be compressed because not all the detail in a picture is readily perceived
by a human eye. The compressed video does not flow at a constant rate,
but varies with time according to factors such as the amount of action and
detail in the picture and the compression algorithm being used. There-
fore, it is possible to say what the average bandwidth requirement will be,
but the instantaneous rate may be more or less.
The key issue is the time interval over which the average is computed.
Suppose that this example video application can be compressed down to
the point that it needs only 2 Mbps, on average. If it transmits 1 megabit
in a 1-second interval and 3 megabits in the following 1-second inter-
val, then over the 2-second interval, it is transmitting at an average rate
of 2 Mbps; however, this will be of little consolation to a channel that
was engineered to support no more than 2 megabits in any one second.
Clearly, just knowing the average bandwidth needs of an application will
not always suffice.
Generally, however, it is possible to put an upper bound on how large
a burst an application like this is likely to transmit. A burst might be
described by some peak rate that is maintained for some period of time.
Alternatively, it could be described as the number of bytes that can be sent
at the peak rate before reverting to the average rate or some lower rate.
If this peak rate is higher than the available channel capacity, then the
excess data will have to be buffered somewhere, to be transmitted later.
Knowing how big a burst might be sent allows the network designer to
allocate sufficient buffer capacity to hold the burst.
Analogous to the way an application’s bandwidth needs can be some-
thing other than “all it can get,” an application’s delay requirements may
be more complex than simply “as little delay as possible.” In the case of
delay, it sometimes does not matter so much whether the one-way latency
of the network is 100 ms or 500 ms as how much the latency varies from
packet to packet. The variation in latency is called jitter.
Consider the situation in which the source sends a packet once every
33 ms, as would be the case for a video application transmitting frames
30 times a second. If the packets arrive at the destination spaced out
5354
CHAPTER 1 Foundation
exactly 33 ms apart, then we can deduce that the delay experienced by
each packet in the network was exactly the same. If the spacing between
when packets arrive at the destination—sometimes called the interpacket
gap—is variable, however, then the delay experienced by the sequence
of packets must have also been variable, and the network is said to have
introduced jitter into the packet stream, as shown in Figure 1.20. Such
variation is generally not introduced in a single physical link, but it can
happen when packets experience different queuing delays in a multi-
hop packet-switched network. This queuing delay corresponds to the
component of latency defined earlier in this section, which varies with
time.
■ FIGURE 1.20 Network-induced jitter.
To understand the relevance of jitter, suppose that the packets being
transmitted over the network contain video frames, and in order to dis-
play these frames on the screen, the receiver needs to receive a new one
every 33 ms. If a frame arrives early, then it can simply be saved by the
receiver until it is time to display it. Unfortunately, if a frame arrives late,
then the receiver will not have the frame it needs in time to update the
screen, and the video quality will suffer; it will not be smooth. Note that
it is not necessary to eliminate jitter, only to know how bad it is. The rea-
son for this is that if the receiver knows the upper and lower bounds on
the latency that a packet can experience, it can delay the time at which
it starts playing back the video (i.e., displays the first frame) long enough
to ensure that in the future it will always have a frame to display when
it needs it. The receiver delays the frame, effectively smoothing out the
jitter, by storing it in a buffer.1.5 Performance
his chapter introduces some of the stakeholders in computer
networks—network designers, application developers, end users,
and network operators—to help motivate the technical require-
ments that shape how networks are designed and built. This pre-
sumes all design decisions are purely technical, but of course,
that is usually not the case. Many other factors, ranging from
market forces to government policy and ethical considera-
tions, also inﬂuence how networks are designed and built.
T
Of these, the marketplace is the most inﬂuential and cor-
responds to the interplay between network operators
(e.g., AT&T, Comcast, Verizon, DT, NTT, China Unicom),
network equipment venders (e.g., Cisco, Juniper,
Ericsson, Nokia, Huawei, NEC), application and service
providers (e.g., Facebook, Google, Amazon, Microsoft,
PERSPECTIVE: FEATURE VELOCITY
Apple, Netﬂix, Spotify), and, of course, subscribers and
customers (i.e., individuals but also enterprises and
businesses). The lines between these players are not
always crisp, with many companies playing multiple
roles. The most notable examples of this are the large
cloud providers, who (a) build their own networking equip-
ment using commodity components, (b) deploy and oper-
ate their own networks, and (c) provide end user services and
applications on top of their networks.
When you account for these other factors in the technical design
process, you realize there are a couple of implicit assumptions in
the textbook version of the story that need to be reevaluated. One
is that designing a network is a one-time activity. Build it once and use
it forever (modulo hardware upgrades so users can enjoy the beneﬁts
of the latest performance improvements). A second is that the job of building the
network is largely divorced from the job of operating the network. Neither of these
assumptions is quite right.
The network’s design is clearly evolving, and we have documented these changes
with each new edition of the textbook over the years. Doing that on a timeline mea-
sured in years has historically been good enough, but anyone who has downloaded
and used the latest smartphone app knows how glacially slow anything measured in
years is by today’s standards. Designing for evolution has to be part of the decision-
making process.
5556
CHAPTER 1 Foundation
On the second point, the companies that build networks are almost always the
same ones that operate them. They are collectively known as network operators, and
they include the companies listed above. But if we again look to the cloud for inspi-
ration, we see that develop-and-operate is not true just at the company level, but it
is also how the fastest-moving cloud companies organize their engineering teams:
around the DevOps model. (If you are unfamiliar with DevOps, we recommend you
read Site Reliability Engineering: How Google Runs Production Systems to see how it is
practiced.)
What this all means is that computer networks are now in the midst of a major
transformation, with network operators trying to simultaneously accelerate the pace
of innovation (sometimes known as feature velocity) and yet continue to offer a
reliable service (preserve stability). And they are increasingly doing this by adopt-
ing the best practices of cloud providers, which can be summarized as having two
major themes: (1) take advantage of commodity hardware and move all intelligence
into software and (2) adopt agile engineering processes that break down barriers
between development and operations.
This transformation is sometimes called the “cloudiﬁcation” or “softwarization” of
the network, and while the Internet has always had a robust software ecosystem,
it has historically been limited to the applications running on top of the network
(e.g., using the socket API described in Section 1.4). What has changed is that today,
these same cloud-inspired engineering practices are being applied to the internals
of the network. This new approach, known as Software Deﬁned Networks (SDNs), is a
game changer, not so much in terms of how we address the fundamental technical
challenges of framing, routing, fragmentation/reassembly, packet scheduling, con-
gestion control, security, and so on but in terms of how rapidly the network evolves
to support new features.
This transformation is so important that we take it up again in the Perspective
section at the end of each chapter. As these discussions will explore, what happens
in the networking industry is partly about technology but also partly about many
other nontechnical factors, all of which is a testament to how deeply embedded the
Internet is in our lives.
I BROADER PERSPECTIVE
■To continue reading about the cloudification of the Internet, see the
text section Perspective: Race to the Edge.
■To learn more about DevOps, we recommend Site Reliability Engi-
neering: How Google Runs Production Systems (Beyer, Jones, Petoff,
& Murphy [eds], O’Reilly © 2016).
CHAPTER 2 Direct Links
Connecting two nodes with a suitable medium is only the ﬁrst step, however. Five
additional problems must be addressed before the nodes can successfully exchange
packets, and once addressed, we will have provided layer 2 (L2) connectivity (using
terminology from the OSI architecture).
The ﬁrst is encoding bits onto the transmission medium so that they can be under-
stood by a receiving node. Second is the matter of delineating the sequence of bits
transmitted over the link into complete messages that can be delivered to the end
node. This is the framing problem, and the messages delivered to the end hosts are
often called frames (or sometimes packets). Third, because frames are sometimes
corrupted during transmission, it is necessary to detect these errors and take the
appropriate action; this is the error detection problem. The fourth issue is making
a link appear reliable in spite of the fact that it corrupts frames from time to time.
Finally, in those cases where the link is shared by multiple hosts—as is often the case
with wireless links, for example—it is necessary to mediate access to this link. This is
the media access control problem.
Although these ﬁve issues—encoding, framing, error detection, reliable delivery,
and access mediation—can be discussed in the abstract, they are very real problems
that are addressed in different ways by different networking technologies. This chap-
ter considers these issues in the context of speciﬁc network technologies: point-to-
point ﬁber links (for which SONET is the prevalent example); Carrier Sense Multiple
Access (CSMA) networks (of which classical Ethernet and Wi-Fi are the most famous
examples); ﬁber-to-the-home (for which PON is the dominant standard); and mobile
wireless (where 4G is rapidly morphing into 5G).
The goal of this chapter is simultaneously to survey the available link-level tech-
nology and to explore these ﬁve fundamental issues. We will examine what it takes
to make a wide variety of different physical media and link technologies useful as
building blocks for the construction of robust, scalable networks.
2.1 TECHNOLOGY LANDSCAPE
Before diving into the challenges outlined in the problem statement at
the beginning of this chapter, it is helpful to first get a lay of the land,
which includes a wide array of link technologies. This is due, in part, to
the diverse circumstances under which users are trying to connect their
devices.
At one end of the spectrum, network operators that build global net-
works must deal with links that span hundreds or thousands of kilometers
connecting refrigerator-sized routers. At the other end of the spectrum, a2.1 Technology Landscape
typical user encounters links mostly as a way to connect a computer to
the existing Internet. Sometimes this link will be a wireless (Wi-Fi) link
in a coffee shop; sometimes it is an Ethernet link in an office building or
university; sometimes it is a smartphone connected to a cellular network;
for an increasingly large slice of the population, it is a fiber optic link pro-
vided by an ISP; and many others use some sort of copper wire or cable
to connect. Fortunately, there are many common strategies used on these
seemingly disparate types of links so that they can all be made reliable
and useful to higher layers in the protocol stack. This chapter examines
those strategies.
■ FIGURE 2.1 An end user’s view of the Internet.
Figure 2.1 illustrates various types of links that might be found in
today’s Internet. On the left, we see a variety of end user devices rang-
ing from smartphones and tablets to full-fledged computers connected
by various means to an ISP. While those links might use different tech-
nologies, they all look the same in this picture—a straight line connecting
a device to a router. There are links that connect routers together inside
the ISP, as well as links that connect the ISP to the “rest of the Internet,”
which consists of lots of other ISPs and the hosts to which they connect.
These links all look alike not just because we are not very good artists
but because part of the role of a network architecture is to provide a com-
mon abstraction of something as complex and diverse as a link. The idea
is that your laptop or smartphone does not have to care what sort of link
it is connected to—the only thing that matters is that it has a link to the
6970
CHAPTER 2 Direct Links
Internet. Similarly, a router does not have to care what sort of link con-
nects it to other routers—it can send a packet on the link with a pretty
good expectation that the packet will reach the other end of the link.
How do we make all these different types of links look sufficiently alike
to end users and routers? Essentially, we have to deal with all the physi-
cal limitations and shortcomings of links that exist in the real world. We
sketched out some of these issues in the opening problem statement for
this chapter, but before we can discuss these, we need to first introduce
some simple physics. All of these links are made of some physical material
that can propagate signals, such as radio waves or other sorts of elec-
tromagnetic radiation, but what we really want to do is send bits. In the
later sections of this chapter, we will look at how to encode bits for trans-
mission on a physical medium, followed by the other issues mentioned
above. By the end of this chapter, we will understand how to send com-
plete packets over just about any sort of link, no matter what physical
medium is involved.
Shannon–Hartley theorem
There has been an enormous body of work done in the related areas of
signal processing and information theory, studying everything from how
signals degrade over distance to how much data a given signal can effec-
tively carry. The most notable piece of work in this area is a formula known
as the Shannon–Hartley theorem. Simply stated, this theorem gives an upper
bound to the capacity of a link, in terms of bits per second (bps), as a func-
tion of the signal-to-noise ratio of the link, measured in decibels (dB), and
the bandwidth of the channel, measured in hertz (Hz). (As noted previously,
“bandwidth” is a bit of an overloaded term in communications; here, we use
it to refer to the range of frequencies available for communication.)
As an example, we can apply the Shannon–Hartley theorem to determine
the rate at which we can expect to transmit data over a voice-grade phone
line without suffering from too high an error rate. A standard voice-grade
phone line typically supports a frequency range of 300 Hz to 3300 Hz, a chan-
nel bandwidth of 3 kHz.
The theorem is typically given by the following formula:
C = B log2 (1 + S/N ),
where C is the achievable channel capacity measured in bits per second, B is
the bandwidth of the channel in Hz (3300 Hz − 300 Hz = 3000 Hz), S is the2.1 Technology Landscape
average signal power, and N is the average noise power. The signal-to-noise
ratio (S/N, or SNR) is usually expressed in decibels, related as follows:
SNR = 10 × log10 (S/N ).
Thus, a typical signal-to-noise ratio of 30 dB would imply that S/N = 1000.
Thus, we have
C = 3000 × log2 (1001),
which equals approximately 30 kbps, roughly what one could expect from a
dial-up modem over a voice-grade telephone line in the 1990s.
The Shannon–Hartley theorem is equally applicable to all sorts of links
ranging from wireless to coaxial cable to optical ﬁber. It should be apparent
that there are really only two ways to build a high-capacity link: start with
a high-bandwidth channel or achieve a high signal to noise ratio. But even
those conditions will not guarantee a high capacity link—it often takes quite
a bit of ingenuity on the part of people who design channel coding schemes
to achieve the theoretical limits of a channel. This ingenuity is particularly
apparent today in wireless links, where there is a great incentive to get the
most bits per second from a given amount of wireless spectrum (the channel
bandwidth) and signal power level (and hence SNR).
One way to characterize links, then, is by the medium they use—
typically, copper wire in some form, such as twisted pair (some Ethernets
and landline phones) and coaxial (cable); optical fiber, which is used for
both fiber-to-the-home and many long-distance links in the Internet’s
backbone; or air/free space for wireless links.
Another important link characteristic is the frequency, measured in
hertz, with which the electromagnetic waves oscillate. The distance
between a pair of adjacent maxima or minima of a wave, typically mea-
sured in meters, is called the wave’s wavelength. Since all electromagnetic
waves travel at the speed of light (which in turn depends on the medium),
that speed divided by the wave’s frequency is equal to its wavelength. We
have already seen the example of a voice-grade telephone line, which
carries continuous electromagnetic signals ranging between 300 Hz and
3300 Hz; a 300-Hz wave traveling through copper would have a wave-
length of
7172
CHAPTER 2 Direct Links
SpeedOfLightInCopper/Frequency
= 2/3 × 3 × 108 /300
= 667 × 103 meters.
Generally, electromagnetic waves span a much wider range of frequen-
cies, ranging from radio waves to infrared light, visible light, x-rays, and
gamma rays. Figure 2.2 depicts the electromagnetic spectrum and shows
which media are commonly used to carry which frequency bands.
■ FIGURE 2.2 Electromagnetic spectrum.
What Figure 2.2 does not show is where the cellular network fits in.
This is a bit complicated, because the specific frequency bands that are
licensed for cellular networks vary around the world, and even further
complicated by the fact that network operators often simultaneously sup-
port both old/legacy technologies and new/next-generation technolo-
gies, each of which occupies a different frequency band. The high-level
summary is that traditional cellular technologies range from 700 MHz to
2400 MHz, with new mid-spectrum allocations now happening at 6 GHz,
and millimeter-wave (mmWave) allocations opening above 24 GHz. This
mmWave band is likely to become an important part of the 5G mobile
network.
So far, we understand a link to be a physical medium carrying signals
in the form of electromagnetic waves. Such links provide the foundation
for transmitting all sorts of information, including the kind of data we are
interested in transmitting—binary data (1s and 0s). We say that the binary
data are encoded in the signal. The problem of encoding binary data onto2.1 Technology Landscape
electromagnetic signals is a complex topic. To help make the topic more
manageable, we can think of it as being divided into two layers. The lower
layer is concerned with modulation—varying the frequency, amplitude,
or phase of the signal to effect the transmission of information. A simple
example of modulation is to vary the power (amplitude) of a single wave-
length. Intuitively, this is equivalent to turning a light on and off. Because
the issue of modulation is secondary to our discussion of links as a build-
ing block for computer networks, we simply assume that it is possible to
transmit a pair of distinguishable signals—think of them as a “high” sig-
nal and a “low” signal—and we consider only the upper layer, which is
concerned with the much simpler problem of encoding binary data onto
these two signals. The next section discusses such encodings.
Another way to classify links is in terms of how they are used. Various
economic and deployment issues tend to influence where different link
types are found. Most consumers interact with the Internet either through
wireless networks (which they encounter in coffee shops, airports, uni-
versities, etc.) or through so-called last-mile links (or alternatively, access
networks) provided by an ISP, as illustrated in Figure 2.1. These link types
are summarized in Table 2.1. They typically are chosen because they are
cost-effective ways of reaching millions of consumers. DSL (Digital Sub-
scriber Line), for example, is an older technology that was deployed over
the existing twisted pair copper wires that already existed for plain old
telephone services; G.Fast is a copper-based technology typically used
within multidwelling apartment buildings, and PON (Passive Optical Net-
work) is a newer technology that is commonly used to connect homes and
businesses over recently deployed fiber.
Table 2.1 Common services
available for the last-mile
connection to your home.
ServiceBandwidth
DSL (copper)up to 100 Mbps
G.Fast (copper)up to 1 Gbps
PON (optical)up to 10 Gbps
And of course there is also the mobile or cellular network (also referred
to as 4G, but which is rapidly evolving into 5G) that connects our mobile
devices to the Internet. This technology can also serve as the sole Internet
connection into our homes or offices but comes with the added benefit of
7374
CHAPTER 2 Direct Links
allowing us to maintain Internet connectivity while moving from place to
place.
These example technologies are common options for the last-mile
connection to your home or business, but they are not sufficient for build-
ing a complete network from scratch. To do that, you will also need some
long-distance backbone links to interconnect cities. Modern backbone
links are almost exclusively fiber today, and they typically use a technol-
ogy called SONET (Synchronous Optical Network), which was originally
developed to meet the demanding management requirements of tele-
phone carriers.
Finally, in addition to last-mile, backbone, and mobile links, there are
the links that you find inside a building or a campus—generally referred
to as local area networks (LANs). Ethernet and its wireless cousin, Wi-Fi,
are the dominant technologies in this space.
This survey of link types is by no means exhaustive, but it should have
given you a taste of the diversity of link types that exist and some of the
reasons for that diversity. In the coming sections, we will see how net-
working protocols can take advantage of that diversity and present a con-
sistent view of the network to higher layers in spite of all the low-level
complexity and economic factors.
2.2 ENCODING
The first step in turning nodes and links into usable building blocks is to
understand how to connect them in such a way that bits can be transmit-
ted from one node to the other. As mentioned in the preceding section,
signals propagate over physical links. The task, therefore, is to encode the
binary data that the source node wants to send into the signals that the
links are able to carry and then to decode the signal back into the cor-
responding binary data at the receiving node. We ignore the details of
modulation and assume we are working with two discrete signals: high
and low. In practice, these signals might correspond to two different volt-
ages on a copper-based link, two different power levels on an optical link,
or two different amplitudes on a radio transmission.
Most of the functions discussed in this chapter are performed by a net-
work adaptor—a piece of hardware that connects a node to a link. The
network adaptor contains a signaling component that actually encodes
bits into signals at the sending node and decodes signals into bits at
the receiving node. Thus, as illustrated in Figure 2.3, signals travel over2.2 Encoding
a link between two signaling components, and bits flow between network
adaptors.
■ FIGURE 2.3 Signals travel between signaling components; bits ﬂow between adaptors.
Let us return to the problem of encoding bits onto signals. The obvi-
ous thing to do is to map the data value 1 onto the high signal and the
data value 0 onto the low signal. This is exactly the mapping used by an
encoding scheme called, cryptically enough, nonreturn to zero (NRZ). For
example, Figure 2.4 schematically depicts the NRZ-encoded signal (bot-
tom) that corresponds to the transmission of a particular sequence of bits
(top).
■ FIGURE 2.4 NRZ encoding of a bit stream.
The problem with NRZ is that a sequence of several consecutive 1s
means that the signal stays high on the link for an extended period of
time; similarly, several consecutive 0s mean that the signal stays low for
a long time. There are two fundamental problems caused by long strings
of 1s or 0s. The first is that it leads to a situation known as baseline wander.
Specifically, the receiver keeps an average of the signal it has seen so far
and then uses this average to distinguish between low and high signals.
Whenever the signal is significantly lower than this average, the receiver
concludes that it has just seen a 0; likewise, a signal that is significantly
higher than the average is interpreted to be a 1. The problem, of course, is
that too many consecutive 1s or 0s cause this average to change, making
it more difficult to detect a significant change in the signal.
The second problem is that frequent transitions from high to low and
vice versa are necessary to enable clock recovery. Intuitively, the clock
recovery problem is that both the encoding and decoding processes are
driven by a clock—every clock cycle, the sender transmits a bit and the
7576
CHAPTER 2 Direct Links
receiver recovers a bit. The sender’s and the receiver’s clocks have to be
precisely synchronized in order for the receiver to recover the same bits
the sender transmits. If the receiver’s clock is even slightly faster or slower
than the sender’s clock, then it does not correctly decode the signal. You
could imagine sending the clock to the receiver over a separate wire, but
this is typically avoided because it makes the cost of cabling twice as high.
So, instead, the receiver derives the clock from the received signal—the
clock recovery process. Whenever the signal changes, such as on a tran-
sition from 1 to 0 or from 0 to 1, then the receiver knows it is at a clock
cycle boundary, and it can resynchronize itself. However, a long period of
time without such a transition leads to clock drift. Thus, clock recovery
depends on having lots of transitions in the signal, no matter what data
are being sent.
One approach that addresses this problem, called nonreturn to zero
inverted (NRZI), has the sender make a transition from the current sig-
nal to encode a 1 and stay at the current signal to encode a 0. This solves
the problem of consecutive 1s but obviously does nothing for consecu-
tive 0s. NRZI is illustrated in Figure 2.5. An alternative, called Manchester
encoding, does a more explicit job of merging the clock with the signal
by transmitting the exclusive OR of the NRZ-encoded data and the clock.
(Think of the local clock as an internal signal that alternates from low
to high; a low/high pair is considered one clock cycle.) The Manchester
encoding is also illustrated in Figure 2.5. Observe that the Manchester
encoding results in 0 being encoded as a low-to-high transition and 1
being encoded as a high-to-low transition. Because both 0s and 1s result
in a transition to the signal, the clock can be effectively recovered at the
receiver. (There is also a variant of the Manchester encoding, called Dif-
ferential Manchester, in which a 1 is encoded with the first half of the
signal equal to the last half of the previous bit’s signal and a 0 is encoded
with the first half of the signal opposite to the last half of the previous bit’s
signal.)
The problem with the Manchester encoding scheme is that it doubles
the rate at which signal transitions are made on the link, which means
that the receiver has half the time to detect each pulse of the signal. The
rate at which the signal changes is called the link’s baud rate. In the case of
the Manchester encoding, the bit rate is half the baud rate, so the encod-
ing is considered only 50% efficient. Keep in mind that if the receiver had
been able to keep up with the faster baud rate required by the Manchester2.2 Encoding
■ FIGURE 2.5 Diﬀerent encoding strategies.
encoding in Figure 2.5, then both NRZ and NRZI could have been able to
transmit twice as many bits in the same time period.
Note that bit rate is not necessarily less than or equal to the baud rate,
as the Manchester encoding suggests. If the modulation scheme is able to
utilize (and recognize) four different signals, as opposed to just two (e.g.,
“high” and “low”), then it is possible to encode 2 bits into each clock inter-
val, resulting in a bit rate that is twice the baud rate. Similarly, being able
to modulate among eight different signals means being able to transmit
3 bits per clock interval. In general, it is important to keep in mind we
have oversimplified modulation, which is much more sophisticated than
transmitting “high” and “low” signals. It is not uncommon to vary a com-
bination of a signal’s phase and amplitude, making it possible to encode
16 or even 64 different patterns (often called symbols) during each clock
interval. QAM (Quadrature Amplitude Modulation) is a widely used exam-
ple of such a modulation scheme.
A final encoding that we consider, called 4B/5B, attempts to address the
inefficiency of the Manchester encoding without suffering from the prob-
lem of having extended durations of high or low signals. The idea of 4B/5B
is to insert extra bits into the bit stream so as to break up long sequences
of 0s or 1s. Specifically, every 4 bits of actual data are encoded in a 5-bit
code that is then transmitted to the receiver; hence, the name 4B/5B. The
5-bit codes are selected in such a way that each one has no more than
one leading 0 and no more than two trailing 0s. Thus, when sent back-
to-back, no pair of 5-bit codes results in more than three consecutive 0s
being transmitted. The resulting 5-bit codes are then transmitted using
the NRZI encoding, which explains why the code is only concerned about
consecutive 0s—NRZI already solves the problem of consecutive 1s. Note
that the 4B/5B encoding results in 80% efficiency.
7778
CHAPTER 2 Direct Links
Table 2.2 4B/5B encoding.
4-bit data symbol5-bit code
000011110
000101001
001010100
001110101
010001010
010101011
011001110
011101111
100010010
100110011
101010110
101110111
110011010
110111011
111011100
111111101
Table 2.2 gives the 5-bit codes that correspond to each of the 16 pos-
sible 4-bit data symbols. Note that since 5 bits are enough to encode 32
different codes, and we are using only 16 of these for data, there are 16
codes left over that we can use for other purposes. Of these, code 11111
is used when the line is idle, code 00000 corresponds to when the line is
dead, and 00100 is interpreted to mean halt. Of the remaining 13 codes, 7
are not valid because they violate the “one leading 0, two trailing 0s” rule,
and the other 6 represent various control symbols. Some of the framing
protocols described later in this chapter make use of these control sym-
bols.
2.3 FRAMING
Now that we have seen how to transmit a sequence of bits over a point-
to-point link—from adaptor to adaptor—let us consider the scenario in
Figure 2.6. Recall from Chapter 1 that we are focusing on packet-switched
networks, which means that blocks of data (called frames at this level),
not bit streams, are exchanged between nodes. It is the network adaptor
that enables the nodes to exchange frames. When node A wishes to trans-
mit a frame to node B, it tells its adaptor to transmit a frame from the2.3 Framing
node’s memory. This results in a sequence of bits being sent over the link.
The adaptor on node B then collects together the sequence of bits arriving
on the link and deposits the corresponding frame in B’s memory. Recog-
nizing exactly what set of bits constitutes a frame—that is, determining
where the frame begins and ends—is the central challenge faced by the
adaptor.
■ FIGURE 2.6 Bits ﬂow between adaptors, frames between hosts.
There are several ways to address the framing problem. This section
uses three different protocols to illustrate the various points in the design
space. Note that while we discuss framing in the context of point-to-point
links, the problem is a fundamental one that must also be addressed in
multiple-access networks like Ethernet and Wi-Fi.
2.3.1 Byte-Oriented Protocols (PPP)
One of the oldest approaches to framing—it has its roots in connect-
ing terminals to mainframes—is to view each frame as a collection of
bytes (characters) rather than a collection of bits. Early examples of
such byte-oriented protocols are the Binary Synchronous Communica-
tion (BISYNC) protocol, developed by IBM in the late 1960s, and the Dig-
ital Data Communication Message Protocol (DDCMP), used in Digital
Equipment Corporation’s DECNET. (Once upon a time, large computer
companies like IBM and DEC also built private networks for their cus-
tomers.) The widely used Point-to-Point Protocol (PPP) is a recent exam-
ple of this approach.
At a high level, there are two approaches to byte-oriented framing. The
first is to use special characters known as sentinel characters to indicate
where frames start and end. The idea is to denote the beginning of a frame
by sending a special SYN (synchronization) character. The data portion of
the frame is then sometimes contained between two more special charac-
ters: STX (start of text) and ETX (end of text). BISYNC used this approach.
7980
CHAPTER 2 Direct Links
The problem with the sentinel approach, of course, is that one of the
special characters might appear in the data portion of the frame. The
standard way to overcome this problem is by “escaping” the character by
preceding it with a DLE (data-link-escape) character whenever it appears
in the body of a frame; the DLE character is also escaped (by preceding
it with an extra DLE) in the frame body. (C programmers may notice that
this is analogous to the way a quotation mark is escaped by the backslash
when it occurs inside a string.) This approach is often called character
stuffing because extra characters are inserted in the data portion of the
frame.
The alternative to detecting the end of a frame with a sentinel value
is to include the number of bytes in the frame at the beginning of the
frame, in the frame header. DDCMP used this approach. One danger with
this approach is that a transmission error could corrupt the count field,
in which case the end of the frame would not be correctly detected. (A
similar problem exists with the sentinel-based approach if the ETX field
becomes corrupted.) Should this happen, the receiver will accumulate as
many bytes as the bad count field indicates and then use the error detec-
tion field to determine that the frame is bad. This is sometimes called a
framing error. The receiver will then wait until it sees the next SYN charac-
ter to start collecting the bytes that make up the next frame. It is therefore
possible that a framing error will cause back-to-back frames to be incor-
rectly received.
The Point-to-Point Protocol (PPP), which is commonly used to carry
Internet Protocol packets over various sorts of point-to-point links, uses
sentinels and character stuffing. The format for a PPP frame is given in
Figure 2.7.
■ FIGURE 2.7 PPP frame format.
This figure is the first of many that you will see in this book that are
used to illustrate frame or packet formats, so a few words of explanation
are in order. We show a packet as a sequence of labeled fields. Above each
field is a number indicating the length of that field in bits. Note that the
packets are transmitted beginning with the leftmost field.2.3 Framing
The special start-of-text character, denoted as the Flag field, is
01111110. The Address and Control fields usually contain default values
and so are uninteresting. The (Protocol) field is used for demultiplexing;
it identifies the high-level protocol, such as IP. The frame payload size
can be negotiated, but it is 1500 bytes by default. The Checksum field is
either 2 (by default) or 4 bytes long. Note that despite its common name,
this field is actually a CRC and not a checksum (as described in the next
section).
The PPP frame format is unusual in that several of the field sizes are
negotiated rather than fixed. This negotiation is conducted by a protocol
called the Link Control Protocol (LCP). PPP and LCP work in tandem: LCP
sends control messages encapsulated in PPP frames—such messages are
denoted by an LCP identifier in the PPP (Protocol) field—and then turns
around and changes PPP’s frame format based on the information con-
tained in those control messages. LCP is also involved in establishing a
link between two peers when both sides detect that communication over
the link is possible (e.g., when each optical receiver detects an incoming
signal from the fiber to which it connects).
2.3.2 Bit-Oriented Protocols (HDLC)
Unlike byte-oriented protocols, a bit-oriented protocol is not concerned
with byte boundaries—it simply views the frame as a collection of bits.
These bits might come from some character set, such as ASCII; they might
be pixel values in an image; or they could be instructions and operands
from an executable file. The Synchronous Data Link Control (SDLC) pro-
tocol developed by IBM is an example of a bit-oriented protocol; SDLC
was later standardized by the ISO as the High-Level Data Link Control
(HDLC) protocol. In the following discussion, we use HDLC as an exam-
ple; its frame format is given in Figure 2.8.
■ FIGURE 2.8 HDLC frame format.
HDLC denotes both the beginning and the end of a frame with the
distinguished bit sequence 01111110. This sequence is also transmitted
8182
CHAPTER 2 Direct Links
during any times that the link is idle so that the sender and receiver can
keep their clocks synchronized. In this way, both protocols essentially use
the sentinel approach. Because this sequence might appear anywhere
in the body of the frame—in fact, the bits 01111110 might cross byte
boundaries—bit-oriented protocols use the analog of the DLE character,
a technique known as bit stuffing.
Bit stuffing in the HDLC protocol works as follows. On the sending side,
any time five consecutive 1s have been transmitted from the body of the
message (i.e., excluding when the sender is trying to transmit the distin-
guished 01111110 sequence), the sender inserts a 0 before transmitting
the next bit. On the receiving side, should five consecutive 1s arrive, the
receiver makes its decision based on the next bit it sees (i.e., the bit fol-
lowing the five 1s). If the next bit is a 0, it must have been stuffed, and
so the receiver removes it. If the next bit is a 1, then one of two things is
true: either this is the end-of-frame marker or an error has been intro-
duced into the bit stream. By looking at the next bit, the receiver can
distinguish between these two cases. If it sees a 0 (i.e., the last 8 bits it
has looked at are 01111110), then it is the end-of-frame marker; if it sees
a 1 (i.e., the last 8 bits it has looked at are 01111111), then there must
have been an error and the whole frame is discarded. In the latter case,
the receiver has to wait for the next 01111110 before it can start receiv-
ing again, and, as a consequence, there is the potential that the receiver
will fail to receive two consecutive frames. Obviously, there are still ways
that framing errors can go undetected, such as when an entire spurious
end-of-frame pattern is generated by errors, but these failures are rela-
tively unlikely. Robust ways of detecting errors are discussed in a later
section.
An interesting characteristic of bit stuffing, as well as character stuff-
ing, is that the size of a frame is dependent on the data that are being sent
in the payload of the frame. It is in fact not possible to make all frames
exactly the same size, given that the data that might be carried in any
frame is arbitrary. (To convince yourself of this, consider what happens
if the last byte of a frame’s body is the ETX character.) A form of framing
that ensures that all frames are of the same size is described in the next
subsection.2.3 Framing
What’s in a layer
One of the important contributions of the OSI reference model was to pro-
vide some vocabulary for talking about protocols and, in particular, protocol
layers. This vocabulary has provided fuel for plenty of arguments along the
lines of “your protocol does function X at layer Y, and the OSI reference model
says it should be done at layer Z—that is a layer violation.” In fact, ﬁguring
out the right layer at which to perform a given function can be very difﬁcult,
and the reasoning is usually a lot more complicated than “what does the OSI
model say?” It is partly for this reason that this book avoids a rigidly layerist
approach. Instead, it shows you a lot of functions that need to be performed
by protocols and looks at some ways in which they have been successfully
implemented.
In spite of our nonlayerist approach, sometimes we need convenient
ways to talk about classes of protocols, and the name of the layer at which
they operate is often the best choice. Thus, for example, this chapter focuses
primarily on link-layer protocols. (Bit encoding is the exception, being con-
sidered a physical-layer function.) Link-layer protocols can be identiﬁed by
the fact that they run over single links—the type of network discussed in this
chapter. Network-layer protocols, by contrast, run over switched networks
that contain lots of links interconnected by switches or routers.
Note that protocol layers are supposed to be helpful—they provide help-
ful ways to talk about classes of protocols, and they help us divide the prob-
lem of building networks into manageable subtasks. However, they are not
meant to be overly restrictive—the mere fact that something is a layer vio-
lation does not end the argument about whether it is a worthwhile thing to
do. In other words, layering makes a good servant but a poor master.
2.3.3 Clock-Based Framing (SONET)
A third approach to framing is exemplified by the Synchronous Optical
Network (SONET) standard. For lack of a widely accepted generic term,
we refer to this approach simply as clock-based framing. SONET was first
proposed by Bell Communications Research (Bellcore) and then devel-
oped under the American National Standards Institute (ANSI) for digital
transmission over optical fiber; it has since been adopted by the ITU-T.
SONET has for many years been the dominant standard for long-distance
transmission of data over optical networks.
An important point to make about SONET before we go any further
is that the full specification is substantially larger than this book. Thus,
the following discussion will necessarily cover only the high points of
8384
CHAPTER 2 Direct Links
the standard. Also, SONET addresses both the framing problem and the
encoding problem. It also addresses a problem that is very important for
phone companies—the multiplexing of several low-speed links onto one
high-speed link. (In fact, much of SONET’s design reflects the fact that
phone companies have to be concerned with multiplexing large numbers
of the 64-kbps channels that traditionally are used for telephone calls.)
We begin with SONET’s approach to framing and discuss the other issues
next.
As with the previously discussed framing schemes, a SONET frame has
some special information that tells the receiver where the frame starts
and ends; however, that is about as far as the similarities go. Notably, no
bit stuffing is used, so that a frame’s length does not depend on the data
being sent. So the question to ask is “how does the receiver know where
each frame starts and ends?” We consider this question for the lowest-
speed SONET link, which is known as STS-1 and runs at 51.84 Mbps. An
STS-1 frame is shown in Figure 2.9. It is arranged as 9 rows of 90 bytes
each, and the first 3 bytes of each row are overhead, with the rest being
available for data that are being transmitted over the link. The first 2 bytes
of the frame contain a special bit pattern, and it is these bytes that enable
the receiver to determine where the frame starts. However, since bit stuff-
ing is not used, there is no reason why this pattern will not occasionally
turn up in the payload portion of the frame. To guard against this, the
receiver looks for the special bit pattern consistently, hoping to see it
appearing once every 810 bytes, since each frame is 9 × 90 = 810 bytes
long. When the special pattern turns up in the right place enough times,
the receiver concludes that it is in sync and can then interpret the frame
correctly.
■ FIGURE 2.9 A SONET STS-1 frame.2.3 Framing
One of the things we are not describing due to the complexity of SONET
is the detailed use of all the other overhead bytes. Part of this complexity
can be attributed to the fact that SONET runs across the carrier’s optical
network, not just over a single link. (Recall that we are glossing over the
fact that the carriers implement a network, and we are instead focusing on
the fact that we can lease a SONET link from them and then use this link
to build our own packet-switched network.) Additional complexity comes
from the fact that SONET provides a considerably richer set of services
than just data transfer. For example, 64 kbps of a SONET link’s capacity is
set aside for a voice channel that is used for maintenance.
The overhead bytes of a SONET frame are encoded using NRZ, the sim-
ple encoding described in the previous section where 1s are high and 0s
are low. However, to ensure that there are plenty of transitions to allow
the receiver to recover the sender’s clock, the payload bytes are scrambled.
This is done by calculating the exclusive OR (XOR) of the data to be trans-
mitted and by the use of a well-known bit pattern. The bit pattern, which
is 127 bits long, has plenty of transitions from 1 to 0, so that XORing it with
the transmitted data is likely to yield a signal with enough transitions to
enable clock recovery.
SONET supports the multiplexing of multiple low-speed links in the
following way. A given SONET link runs at one of a finite set of possible
rates, ranging from 51.84 Mbps (STS-1) to 39,813,120 Mbps (STS-768).1
Note that all of these rates are integer multiples of STS-1. The significance
for framing is that a single SONET frame can contain subframes for mul-
tiple lower-rate channels. A second related feature is that each frame is
125 µs long. This means that at STS-1 rates, a SONET frame is 810 bytes
long, while at STS-3 rates, each SONET frame is 2430 bytes long. Note the
synergy between these two features: 3 × 810 = 2430, meaning that three
STS-1 frames fit exactly in a single STS-3 frame.
Intuitively, the STS-N frame can be thought of as consisting of N STS-1
frames, where the bytes from these frames are interleaved; that is, a byte
from the first frame is transmitted, then a byte from the second frame is
transmitted, and so on. The reason for interleaving the bytes from each
STS-N frame is to ensure that the bytes in each STS-1 frame are evenly
1 STS stands for Synchronous Transport Signal, which is how SONET talks about
frames. There is a parallel term—Optical Carrier (OC)—that is used to talk about the
underlying optical signal that carries SONET frames. We say these two terms are par-
allel because STS-3 and OC-3, to use a concrete example, both imply a transmission
rate of 155.52 Mbps. Since we focus on framing here, we will stick with STS, but it is
more likely that you will hear someone refer to an optical link by its “OC” name.
8586
CHAPTER 2 Direct Links
paced; that is, bytes show up at the receiver at a smooth 51 Mbps rather
than all being bunched up during one particular (1/N)th of the 125-µs
interval.
■ FIGURE 2.10 Three STS-1 frames multiplexed onto one STS-3c frame.
Although it is accurate to view an STS-N signal as being used to multi-
plex N STS-1 frames, the payload from these STS-1 frames can be linked
together to form a larger STS-N payload; such a link is denoted STS-Nc
(for concatenated). One of the fields in the overhead is used for this pur-
pose. Figure 2.10 schematically depicts concatenation in the case of three
STS-1 frames being concatenated into a single STS-3c frame. The signif-
icance of a SONET link being designated as STS-3c rather than STS-3 is
that in the former case, the user of the link can view it as a single 155.25-
Mbps pipe, whereas an STS-3 should really be viewed as three 51.84-Mbps
links that happen to share a fiber.
■ FIGURE 2.11 SONET frames out of phase.
Finally, the preceding description of SONET is overly simplistic in that
it assumes that the payload for each frame is completely contained within
the frame. (Why would it not be?) In fact, we should view the STS-1 frame
just described as simply a placeholder for the frame, where the actual
payload may float across frame boundaries. This situation is illustrated
in Figure 2.11. Here we see both the STS-1 payload floating across two2.4 Error Detection
STS-1 frames and the payload shifted some number of bytes to the right
and, therefore, wrapped around. One of the fields in the frame overhead
points to the beginning of the payload. The value of this capability is that
it simplifies the task of synchronizing the clocks used throughout the car-
riers’ networks, which is something that carriers spend a lot of their time
worrying about.
2.4 ERROR DETECTION
As discussed in Chapter 1, bit errors are sometimes introduced into
frames. This happens, for example, because of electrical interference or
thermal noise. Although errors are rare, especially on optical links, some
mechanism is needed to detect these errors so that corrective action can
be taken. Otherwise, the end user is left wondering why the C program
that successfully compiled just a moment ago now suddenly has a syn-
tax error in it, when all that happened in the interim is that it was copied
across a network file system.
There is a long history of techniques for dealing with bit errors in com-
puter systems, dating back to at least the 1940s. Hamming and Reed–
Solomon codes are two notable examples that were developed for use in
punch card readers, when storing data on magnetic disks, and in early
core memories. This section describes some of the error detection tech-
niques most commonly used in networking.
Detecting errors is only one part of the problem. The other part is the
correction of errors once detected. Two basic approaches can be taken
when the recipient of a message detects an error. One is to notify the
sender that the message was corrupted so that the sender can retrans-
mit a copy of the message. If bit errors are rare, then in all probabil-
ity, the retransmitted copy will be error-free. Alternatively, some types of
error detection algorithms allow the recipient to reconstruct the correct
message even after it has been corrupted; such algorithms rely on error-
correcting codes, discussed below.
One of the most common techniques for detecting transmission errors
is a technique known as the cyclic redundancy check (CRC). It is used in
nearly all the link-level protocols discussed in this chapter. This section
outlines the basic CRC algorithm, but before discussing that approach,
we first describe the simpler checksum scheme used by several Internet
protocols.
8788
CHAPTER 2 Direct Links
The basic idea behind any error detection scheme is to add redun-
dant information to a frame that can be used to determine if errors have
been introduced. In the extreme, we could imagine transmitting two com-
plete copies of the data. If the two copies are identical at the receiver,
then it is probably the case that both are correct. If they differ, then an
error was introduced into one (or both) of them, and they must be dis-
carded. This is a rather poor error detection scheme for two reasons. First,
it sends n redundant bits for an n-bit message. Second, many errors will
go undetected—any error that happens to corrupt the same bit positions
in the first and second copies of the message. In general, the goal of error-
detecting codes is to provide a high probability of detecting errors com-
bined with a relatively low number of redundant bits.
Fortunately, we can do a lot better than this simple scheme. In gen-
eral, we can provide a quite strong error detection capability while send-
ing only k redundant bits for an n-bit message, where k is much smaller
than n. On an Ethernet, for example, a frame carrying up to 12,000 bits
(1500 bytes) of data requires only a 32-bit CRC code or, as it is commonly
expressed, uses CRC-32. Such a code will catch the overwhelming major-
ity of errors, as we will see below.
We say that the extra bits we send are redundant because they add no
new information to the message. Instead, they are derived directly from
the original message using some well-defined algorithm. Both the sender
and the receiver know exactly what that algorithm is. The sender applies
the algorithm to the message to generate the redundant bits. It then trans-
mits both the message and those few extra bits. When the receiver applies
the same algorithm to the received message, it should (in the absence
of errors) come up with the same result as the sender. It compares the
result with the one sent to it by the sender. If they match, it can con-
clude (with high likelihood) that no errors were introduced in the message
during transmission. If they do not match, it can be sure that either the
message or the redundant bits were corrupted, and it must take appro-
priate action—that is, discarding the message or correcting it if that is
possible.
One note on the terminology for these extra bits follows. In general,
they are referred to as error-detecting codes. In specific cases, when the
algorithm to create the code is based on addition, they may be called a
checksum. We will see that the Internet checksum is appropriately named:2.4 Error Detection
it is an error check that uses a summing algorithm. Unfortunately, the
word checksum is often used imprecisely to mean any form of error-
detecting code, including CRCs. This can be confusing, so we urge you to
use the word checksum only to apply to codes that actually do use addi-
tion and to use error-detecting code to refer to the general class of codes
described in this section.
2.4.1 Internet Checksum Algorithm
Our first approach to error detection is exemplified by the Internet check-
sum. Although it is not used at the link level, it nevertheless provides the
same sort of functionality as CRCs, so we discuss it here.
The idea behind the Internet checksum is very simple—you add up
all the words that are transmitted and then transmit the result of that
sum. The result is the checksum. The receiver performs the same cal-
culation on the received data and compares the result with the received
checksum. If any transmitted data, including the checksum itself, is cor-
rupted, then the results will not match, so the receiver knows that an error
occurred.
You can imagine many different variations on the basic idea of a check-
sum. The exact scheme used by the Internet protocols works as follows.
Consider the data being checksummed as a sequence of 16-bit integers.
Add them together using 16-bit ones’ complement arithmetic (explained
below) and then take the ones’ complement of the result. That 16-bit
number is the checksum.
In ones’ complement arithmetic, a negative integer (−x) is represented
as the complement of x; that is, each bit of x is inverted. When adding
numbers in ones’ complement arithmetic, a carryout from the most sig-
nificant bit needs to be added to the result. Consider, for example, the
addition of −5 and −3 in ones’ complement arithmetic on 4-bit integers:
+5 is 0101, so −5 is 1010; +3 is 0011, so −3 is 1100. If we add 1010 and
1100, ignoring the carry, we get 0110. In ones’ complement arithmetic,
the fact that this operation caused a carry from the most significant bit
causes us to increment the result, giving 0111, which is the ones’ comple-
ment representation of −8 (obtained by inverting the bits in 1000), as we
would expect.
The following routine gives a straightforward implementation of the
Internet’s checksum algorithm. The count argument gives the length of
8990
CHAPTER 2 Direct Links
buf measured in 16-bit units. The routine assumes that buf has already
been padded with 0s to a 16-bit boundary.
u_short
cksum(u_short *buf, int count)
{
register u_long sum = 0;
while (count--)
{
sum += *buf++;
if (sum & 0xFFFF0000)
{
/* carry occurred, so wrap around */
sum &= 0xFFFF;
sum++;
}
}
return ~(sum & 0xFFFF);
}
This code ensures that the calculation uses ones’ complement arith-
metic rather than the twos’ complement that is used in most machines.
Note the if statement inside the while loop. If there is a carry into the top
16 bits of sum, then we increment sum just as in the previous example.
Compared to our repetition code, this algorithm scores well for using
a small number of redundant bits—only 16 for a message of any length—
but it does not score extremely well for strength of error detection. For
example, a pair of single-bit errors, one of which increments a word and
one of which decrements another word by the same amount, will go
undetected. The reason for using an algorithm like this in spite of its rel-
atively weak protection against errors (compared to a CRC, for example)
is simple: this algorithm is much easier to implement in software. Expe-
rience has suggested that a checksum of this form was adequate, but one
reason it is adequate is that this checksum is the last line of defense in
an end-to-end protocol. The majority of errors are picked up by stronger
error detection algorithms, such as CRCs, at the link level.2.4 Error Detection
Simple probability calculations
When dealing with network errors and other unlikely (we hope) events, we
often have use for simple back-of-the-envelope probability estimates. A use-
ful approximation is that if two independent events have small probabilities
p and q, then the probability of either event is p + q. The exact answer is
1 − (1 − p)(1 − q) = p + q − pq, but for small probabilities like p = q = 0.01,
our estimate gives us 0.02, while the exact value is .0199. Close enough.
For a simple application of this, suppose that the per-bit error rate on a
link is 1 in 107 . Now suppose we are interested in estimating the probability
of at least 1 bit in a 10,000-bit packet being errored. Using the above approx-
imation repeatedly over all the bits, we can say that we are interested in the
probability of either the ﬁrst bit being errored, or the second bit, or the third,
etc. Assuming bit errors are all independent (which they are not), we can
therefore estimate that the probability of at least one error in a 10,000-bit
(104 bits) packet is 104 × 10−7 = 10−3 . The exact answer, computed as 1 −
P(no errors), would be 1 − (1 − 10−7 )10,000 = 0.00099950.
For a slightly more complex application, we compute the probability of
exactly two errors in such a packet; this is the probability of an error that
would sneak past a 1-parity-bit checksum. If we consider two particular bits
in the packet, say, bits i and j, the probability of those exact bits being errored
is 10−7 × 10−7 . The total number of possible bit pairs in the packet is roughly
5 × 107 , so again using the approximation of repeatedly adding the probabil-
ities of many rare events (in this case, of any possible bit pair being errored),
our total probability of at least two errored bits is 5 × 107 × 10−14 = 5 × 10−7 .
2.4.2 Cyclic Redundancy Check
It should be clear by now that a major goal in designing error detec-
tion algorithms is to maximize the probability of detecting errors using
only a small number of redundant bits. Cyclic redundancy checks use
some fairly powerful mathematics to achieve this goal. For example, a 32-
bit CRC gives strong protection against common bit errors in messages
that are thousands of bytes long. The theoretical foundation of the cyclic
redundancy check is rooted in a branch of mathematics called finite fields.
While this may sound daunting, the basic ideas can be easily understood.
To start, think of an (n + 1)-bit message as being represented by an n
degree polynomial, that is, a polynomial whose highest-order term is x n .
The message is represented by a polynomial by using the value of each bit
in the message as the coefficient for each term in the polynomial, start-
ing with the most significant bit to represent the highest-order term. For
9192
CHAPTER 2 Direct Links
example, an 8-bit message consisting of the bits 10011010 corresponds to
the polynomial
M(x) = (1 × x 7 ) + (0 × x 6 ) + (0 × x 5 ) + (1 × x 4 )
+ (1 × x 3 ) + (0 × x 2 ) + (1 × x 1 ) + (0 × x 0 ),
M(x) = x 7 + x 4 + x 3 + x 1 .
We can thus think of a sender and a receiver as exchanging polynomials
with each other.
For the purposes of calculating a CRC, a sender and receiver have to
agree on a divisor polynomial, C(x), which is a polynomial of degree k.
For example, suppose C(x) = x 3 + x 2 + 1. In this case, k = 3. The answer to
the question “where did C(x) come from?” is, in most practical cases, “you
look it up in a book.” In fact, the choice of C(x) has a significant impact on
what types of errors can be reliably detected, as we discuss below. There
are a handful of divisor polynomials that are very good choices for vari-
ous environments, and the exact choice is normally made as part of the
protocol design. For example, the Ethernet standard uses a well-known
polynomial of degree 32.
When a sender wishes to transmit a message M(x) that is n + 1 bits
long, what is actually sent is the (n + 1)-bit message plus k bits. We call the
complete transmitted message, including the redundant bits, P (x). What
we are going to do is contrive to make the polynomial representing P (x)
exactly divisible by C(x); we explain how this is achieved below. If P (x) is
transmitted over a link and there are no errors introduced during trans-
mission, then the receiver should be able to divide P (x) by C(x) exactly,
leaving a remainder of zero. On the other hand, if some error is introduced
into P (x) during transmission, then in all likelihood, the received polyno-
mial will no longer be exactly divisible by C(x), and thus the receiver will
obtain a nonzero remainder, implying that an error has occurred.
It will help to understand the following if you know a little about poly-
nomial arithmetic; it is just slightly different from normal integer arith-
metic. We are dealing with a special class of polynomial arithmetic here,
where coefficients may be only one or zero, and operations on the coef-
ficients are performed using modulo 2 arithmetic. This is referred to as
“polynomial arithmetic modulo 2.” Since this is a networking book, not a
mathematics text, let us focus on the key properties of this type of arith-
metic for our purposes (which we ask you to accept on faith):2.4 Error Detection
■Any polynomial B(x) can be divided by a divisor polynomial C(x) if
B(x) is of higher degree than C(x).
■Any polynomial B(x) can be divided once by a divisor polynomial
C(x) if B(x) is of the same degree as C(x).
■The remainder obtained when B(x) is divided by C(x) is obtained by
performing the exclusive OR (XOR) operation on each pair of match-
ing coefficients.
For example, the polynomial x 3 + 1 can be divided by x 3 + x 2 + 1
(because they are both of degree 3) and the remainder would be 0 × x 3 +
1 × x 2 + 0 × x 1 + 0 × x 0 = x 2 (obtained by XORing the coefficients of each
term). In terms of messages, we could say that 1001 can be divided by
1101 and leaves a remainder of 0100. You should be able to see that the
remainder is just the bitwise exclusive OR of the two messages.
Now that we know the basic rules for dividing polynomials, we are able
to do long division, which is necessary to deal with longer messages. An
example appears below.
Recall that we wanted to create a polynomial for transmission that is
derived from the original message M(x), is k bits longer than M(x), and is
exactly divisible by C(x). We can do this in the following way:
1. Multiply M(x) by x k ; that is, add k zeros at the end of the message. Call
this zero-extended message T (x).
2. Divide T (x) by C(x) and find the remainder.
3. Subtract the remainder from T (x).
It should be obvious that what is left at this point is a message that
is exactly divisible by C(x). We may also note that the resulting message
consists of M(x) followed by the remainder obtained in step 2, because
when we subtracted the remainder (which can be no more than k bits
long), we were just XORing it with the k zeros added in step 1. This part
will become clearer with an example.
Consider the message x 7 + x 4 + x 3 + x 1 , or 10011010. We begin by
multiplying by x 3 , since our divisor polynomial is of degree 3. This gives
10011010000. We divide this by C(x), which corresponds to 1101 in this
case. Figure 2.12 shows the polynomial long division operation. Given the
9394
CHAPTER 2 Direct Links
rules of polynomial arithmetic described above, the long division opera-
tion proceeds much as it would if we were dividing integers. Thus, in the
first step of our example, we see that the divisor 1101 divides once into the
first 4 bits of the message (1001), since they are of the same degree, and
leaves a remainder of 100 (1101 XOR 1001). The next step is to bring down
a digit from the message polynomial until we get another polynomial
with the same degree as C(x), in this case 1001. We calculate the remain-
der again (100) and continue until the calculation is complete. Note that
the “result” of the long division, which appears at the top of the calcu-
lation, is not really of much interest—it is the remainder at the end that
matters.
■ FIGURE 2.12 CRC calculation using polynomial long division.
You can see from the very bottom of Figure 2.12 that the remainder of
the example calculation is 101. So we know that 10011010000 minus 101
would be exactly divisible by C(x), and this is what we send. The minus
operation in polynomial arithmetic is the logical XOR operation, so we
actually send 10011010101. As noted above, this turns out to be just the
original message with the remainder from the long division calculation
appended to it. The recipient divides the received polynomial by C(x)
and, if the result is 0, concludes that there were no errors. If the result
is nonzero, it may be necessary to discard the corrupted message; with
some codes, it may be possible to correct a small error (e.g., if the error
affected only 1 bit). A code that enables error correction is called an error-
correcting code (ECC).
Now we will consider the question of where the polynomial C(x) comes
from. Intuitively, the idea is to select this polynomial so that it is very2.4 Error Detection
unlikely to divide evenly into a message that has errors introduced into
it. If the transmitted message is P (x), we may think of the introduction of
errors as the addition of another polynomial E(x), so the recipient sees
P (x) + E(x). The only way that an error could slip by undetected would
be if the received message could be evenly divided by C(x), and since we
know that P (x) can be evenly divided by C(x), this could only happen if
E(x) can be divided evenly by C(x). The trick is to pick C(x) so that this is
very unlikely for common types of errors.
One common type of error is a single-bit error, which can be expressed
as E(x) = x i when it affects bit position i. If we select C(x) such that the
first and the last term (that is, the x k and x 0 terms) are nonzero, then we
already have a two-term polynomial that cannot divide evenly into the
one term E(x). Such a C(x) can, therefore, detect all single-bit errors. In
general, it is possible to prove that the following types of errors can be
detected by a C(x) with the stated properties:
■all single-bit errors, as long as the x k and x 0 terms have nonzero
coefficients;
■all double-bit errors, as long as C(x) has a factor with at least three
terms;
■
any odd number of errors, as long as C(x) contains the factor (x + 1);
We have mentioned that it is possible to use codes that not only detect
the presence of errors but also enable errors to be corrected. Since the
details of such codes require yet more complex mathematics than that
required to understand CRCs, we will not dwell on them here. However, it
is worth considering the merits of correction versus detection.
At first glance, it would seem that correction is always better, since
with detection, we are forced to throw away the message and, in gen-
eral, ask for another copy to be transmitted. This uses up bandwidth
and may introduce latency while waiting for the retransmission. How-
ever, there is a downside to correction, as it generally requires a greater
number of redundant bits to send an error-correcting code that is as
strong (that is, able to cope with the same range of errors) as a code that
only detects errors. Thus, while error detection requires more bits to be
sent when errors occur, error correction requires more bits to be sent
all the time. As a result, error correction tends to be most useful when
(1) errors are quite probable, as they may be, for example, in a wireless
9596
CHAPTER 2 Direct Links
environment, or (2) the cost of retransmission is too high, for example,
because of the latency involved retransmitting a packet over a satellite
link.
The use of error-correcting codes in networking is sometimes referred
to as forward error correction (FEC) because the correction of errors is
handled “in advance” by sending extra information rather than waiting
for errors to happen and dealing with them later by retransmission. FEC
is commonly used in wireless networks such as 802.11.
■
any “burst” error (i.e., sequence of consecutive errored bits) for
which the length of the burst is less than k bits. (Most burst errors
of length greater than k bits can also be detected.)
Six versions of C(x) are widely used in link-level protocols. For exam-
ple, Ethernet uses CRC-32, which is defined as follows:
■
CRC-32 = x 32 + x 26 + x 23 + x 22 + x 16 + x 12 + x 11 + x 10 + x 8 + x 7 + x 5 +
x 4 + x 2 + x + 1.
Finally, we note that the CRC algorithm, while seemingly complex, is
easily implemented in hardware using a k-bit shift register and XOR gates.
The number of bits in the shift register equals the degree of the generator
polynomial (k). Figure 2.13 shows the hardware that would be used for the
generator x 3 + x 2 + 1 from our previous example. The message is shifted in
from the left, beginning with the most significant bit and ending with the
string of k zeros that is attached to the message, just as in the long division
example. When all the bits have been shifted in and appropriately XORed,
the register contains the remainder—that is, the CRC (most significant bit
on the right). The position of the XOR gates is determined as follows: if
the bits in the shift register are labeled 0 through k − 1, from left to right,
then put an XOR gate in front of bit n if there is a term x n in the generator
■ FIGURE 2.13 CRC calculation using shift register.2.5 Reliable Transmission
polynomial. Thus, we see an XOR gate in front of positions 0 and 2 for the
generator x 3 + x 2 + x 0 .
2.5 RELIABLE TRANSMISSION
As we saw in the previous section, frames are sometimes corrupted while
in transit, with an error code like CRC used to detect such errors. While
some error codes are strong enough also to correct errors, in practice, the
overhead is typically too large to handle the range of bit and burst errors
that can be introduced on a network link. Even when error-correcting
codes are used (e.g., on wireless links), some errors will be too severe to
be corrected. As a result, some corrupt frames must be discarded. A link-
level protocol that wants to deliver frames reliably must somehow recover
from these discarded (lost) frames.
It is worth noting that reliability is a function that may be provided at
the link level, but many modern link technologies omit this function. Fur-
thermore, reliable delivery is frequently provided at higher levels, includ-
ing both transport and, sometimes, the application layer. Exactly where it
should be provided is a matter of some debate and depends on many fac-
tors. We describe the basics of reliable delivery here, since the principles
are common across layers, but you should be aware that we are not just
talking about a link-layer function.
Reliable delivery is usually accomplished using a combination of two
fundamental mechanisms—acknowledgments and timeouts. An acknowl-
edgment (ACK for short) is a small control frame that a protocol sends
back to its peer saying that it has received an earlier frame. By control
frame, we mean a header without any data, although a protocol can piggy-
back an ACK on a data frame it just happens to be sending in the opposite
direction. The receipt of an acknowledgment indicates to the sender of
the original frame that its frame was successfully delivered. If the sender
does not receive an acknowledgment after a reasonable amount of time,
then it retransmits the original frame. This action of waiting a reasonable
amount of time is called a timeout.
The general strategy of using acknowledgments and timeouts to imple-
ment reliable delivery is sometimes called automatic repeat request
(abbreviated ARQ). This section describes three different ARQ algorithms
using generic language; that is, we do not give detailed information about
a particular protocol’s header fields.
9798
CHAPTER 2 Direct Links
2.5.1 Stop-and-Wait
The simplest ARQ scheme is the stop-and-wait algorithm. The idea of
stop-and-wait is straightforward: after transmitting one frame, the sender
waits for an acknowledgment before transmitting the next frame. If the
acknowledgment does not arrive after a certain period of time, the sender
times out and retransmits the original frame.
■ FIGURE 2.14 Timeline showing four diﬀerent scenarios for the stop-and-wait algorithm. (a) The ACK is received before
the timer expires; (b) the original frame is lost; (c) the ACK is lost; (d) the timeout ﬁres too soon.
Figure 2.14 illustrates timelines for four different scenarios that result
from this basic algorithm. The sending side is represented on the left,
the receiving side is depicted on the right, and time flows from top to
bottom. Figure 2.14(a) shows the situation in which the ACK is received
before the timer expires; (b) and (c) show the situation in which the orig-
inal frame and the ACK, respectively, are lost; and (d) shows the situation
in which the timeout fires too soon. Recall that by “lost” we mean that the
frame was corrupted while in transit, that this corruption was detected2.5 Reliable Transmission
by an error code on the receiver, and that the frame was subsequently
discarded.
The packet timelines shown in this section are examples of a frequently
used tool in teaching, explaining, and designing protocols. They are use-
ful because they capture visually the behavior over time of a distributed
system—something that can be quite hard to analyze. When designing
a protocol, you often have to be prepared for the unexpected—a system
crashes, a message gets lost, or something that you expected to happen
quickly turns out to take a long time. These sorts of diagrams can often
help us understand what might go wrong in such cases and thus help a
protocol designer be prepared for every eventuality.
There is one important subtlety in the stop-and-wait algorithm. Sup-
pose the sender sends a frame and the receiver acknowledges it, but the
acknowledgment is either lost or delayed in arriving. This situation is
illustrated in timelines (c) and (d) of Figure 2.14. In both cases, the sender
times out and retransmits the original frame, but the receiver will think
that it is the next frame, since it correctly received and acknowledged the
first frame. This has the potential to cause duplicate copies of a frame
to be delivered. To address this problem, the header for a stop-and-wait
protocol usually includes a 1-bit sequence number—that is, the sequence
number can take on the values 0 and 1—and the sequence numbers used
for each frame alternate, as illustrated in Figure 2.15. Thus, when the
■ FIGURE 2.15 Timeline for stop-and-wait with 1-bit sequence number.
99100
CHAPTER 2 Direct Links
sender retransmits frame 0, the receiver can determine that it is seeing
a second copy of frame 0 rather than the first copy of frame 1 and there-
fore can ignore it (the receiver still acknowledges it, in case the first ACK
was lost).
The main shortcoming of the stop-and-wait algorithm is that it allows
the sender to have only one outstanding frame on the link at a time, and
this may be far below the link’s capacity. Consider, for example, a 1.5-
Mbps link with a 45-ms round-trip time. This link has a delay × bandwidth
product of 67.5 kbits, or approximately 8 kB. Since the sender can send
only one frame per RTT, and assuming a frame size of 1 kB, this implies a
maximum sending rate of
Bits-Per-Frame / Time-Per-Frame = 1024 × 8 / 0.045 = 182 kbps,
or about one-eighth of the link’s capacity. To use the link fully, then, we
would like the sender to be able to transmit up to eight frames before hav-
ing to wait for an acknowledgment.
The signiﬁcance of the delay × bandwidth product is that it represents the amount
of data that could be in transit. We would like to be able to send this much data
without waiting for the ﬁrst acknowledgment. The principle at work here is often
referred to as keeping the pipe full. The algorithms presented in the following two
subsections do exactly this.
2.5.2 Sliding Window
Consider again the scenario in which the link has a delay × bandwidth
product of 8 kB and frames are 1 kB in size. We would like the sender to
be ready to transmit the ninth frame at pretty much the same moment
that the ACK for the first frame arrives. The algorithm that allows us to
do this is called sliding window, and an illustrative timeline is given in
Figure 2.16.
The Sliding Window Algorithm
The sliding window algorithm works as follows. First, the sender assigns
a sequence number, denoted SeqNum, to each frame. For now, let us
ignore the fact that SeqNum is implemented by a finite-size header field
and instead assume that it can grow infinitely large. The sender main-2.5 Reliable Transmission
■ FIGURE 2.16 Timeline for the sliding window algorithm.
tains three variables: the send window size, denoted SWS, gives the upper
bound on the number of outstanding (unacknowledged) frames that
the sender can transmit; LAR denotes the sequence number of the last
acknowledgment received; and LFS denotes the sequence number of the
last frame sent. The sender also maintains the following invariant:
LFS - LAR ≤ SWS
This situation is illustrated in Figure 2.17.
■ FIGURE 2.17 Sliding window on sender.
When an acknowledgment arrives, the sender moves LAR to the right,
thereby allowing the sender to transmit another frame. Also, the sender
associates a timer with each frame it transmits, and it retransmits the
frame should the timer expire before an ACK is received. Note that the
sender has to be willing to buffer up to SWS frames, since it must be pre-
pared to retransmit them until they are acknowledged.
The receiver maintains the following three variables: the receive win-
dow size, denoted RWS, gives the upper bound on the number of out-
of-order frames that the receiver is willing to accept; LAF denotes the
101102
CHAPTER 2 Direct Links
sequence number of the largest acceptable frame; and LFR denotes the
sequence number of the last frame received. The receiver also maintains
the following invariant:
LAF - LFR ≤ RWS
This situation is illustrated in Figure 2.18.
■ FIGURE 2.18 Sliding window on receiver.
When a frame with sequence number SeqNum arrives, the receiver
takes the following action. If SeqNum ≤ LFR or SeqNum > LAF, then
the frame is outside the receiver’s window and it is discarded. If LFR <
SeqNum ≤ LAF, then the frame is within the receiver’s window and it
is accepted. Now the receiver needs to decide whether or not to send
an ACK. Let SeqNumToAck denote the largest sequence number not yet
acknowledged, such that all frames with sequence numbers less than or
equal to SeqNumToAck have been received. The receiver acknowledges
the receipt of SeqNumToAck, even if higher numbered packets have been
received. This acknowledgment is said to be cumulative. It then sets LFR
= SeqNumToAck and adjusts LAF = LFR + RWS.
For example, suppose LFR = 5 (i.e., the last ACK the receiver sent was
for sequence number 5), and RWS = 4. This implies that LAF = 9. Should
frames 7 and 8 arrive, they will be buffered because they are within the
receiver’s window. However, no ACK needs to be sent since frame 6 has yet
to arrive. Frames 7 and 8 are said to have arrived out of order. (Technically,
the receiver could resend an ACK for frame 5 when frames 7 and 8 arrive.)
Should frame 6 then arrive—perhaps it is late because it was lost the first
time and had to be retransmitted, or perhaps it was simply delayed—the
receiver acknowledges frame 8, bumps LFR to 8, and sets LAF to 12.2 If
2 While it is unlikely that a packet could be delayed or arrive out of order on a point-
to-point link, this same algorithm is used on multihop connections where such
delays are possible.2.5 Reliable Transmission
frame 6 was in fact lost, then a timeout will have occurred at the sender,
causing it to retransmit frame 6.
We observe that when a timeout occurs, the amount of data in transit
decreases, since the sender is unable to advance its window until frame 6
is acknowledged. This means that when packet losses occur, this scheme
is no longer keeping the pipe full. The longer it takes to notice that a
packet loss has occurred, the more severe this problem becomes.
Note that in this example, the receiver could have sent a negative
acknowledgment (NACK) for frame 6 as soon as frame 7 arrived. However,
this is unnecessary, since the sender’s timeout mechanism is sufficient to
catch this situation, and sending NACKs adds additional complexity to
the receiver. Also, as we mentioned, it would have been legitimate to send
additional acknowledgments of frame 5 when frames 7 and 8 arrived;
in some cases, a sender can use duplicate ACKs as a clue that a frame
was lost. Both approaches help to improve performance by allowing early
detection of packet losses.
Yet another variation on this scheme would be to use selective acknowl-
edgments. That is, the receiver could acknowledge exactly those frames
it has received rather than just the highest numbered frame received
in order. So, in the above example, the receiver could acknowledge the
receipt of frames 7 and 8. Giving more information to the sender makes it
potentially easier for the sender to keep the pipe full but adds complexity
to the implementation.
The sending window size is selected according to how many frames
we want to have outstanding on the link at a given time; SWS is easy
to compute for a given delay × bandwidth product. On the other hand,
the receiver can set RWS to whatever it wants. Two common settings are
RWS = 1, which implies that the receiver will not buffer any frames that
arrive out of order, and RWS = SWS, which implies that the receiver can
buffer any of the frames the sender transmits. It makes no sense to set
RWS > SWS, since it is impossible for more than SWS frames to arrive
out of order.
Finite Sequence Numbers and Sliding Window
We now return to the one simplification we introduced into the algo-
rithm—our assumption that sequence numbers can grow infinitely large.
In practice, of course, a frame’s sequence number is specified in a header
field of some finite size. For example, a 3-bit field means that there
103104
CHAPTER 2 Direct Links
are eight possible sequence numbers, 0..7. This makes it necessary to
reuse sequence numbers or, stated another way, sequence numbers wrap
around. This introduces the problem of being able to distinguish between
different incarnations of the same sequence numbers, which implies that
the number of possible sequence numbers must be larger than the num-
ber of outstanding frames allowed. For example, stop-and-wait allowed
one outstanding frame at a time and had two distinct sequence num-
bers.
Suppose we have one more number in our space of sequence numbers
than we have potentially outstanding frames; that is, SWS ≤ MaxSeqNum
- 1, where MaxSeqNum is the number of available sequence numbers. Is
this sufficient? The answer depends on RWS. If RWS = 1, then MaxSe-
qNum ≥ SWS + 1 is sufficient. If RWS is equal to SWS, then having a
MaxSeqNum just one greater than the sending window size is not good
enough. To see this, consider the situation in which we have the eight
sequence numbers 0 through 7, and SWS = RWS = 7. Suppose the sender
transmits frames 0..6, they are successfully received, but the ACKs are lost.
The receiver is now expecting frames 7, 0..5, but the sender times out
and sends frames 0..6. Unfortunately, the receiver is expecting the second
incarnation of frames 0..5 but gets the first incarnation of these frames.
This is exactly the situation we wanted to avoid.
It turns out that the sending window size can be no more than half as
big as the number of available sequence numbers when RWS = SWS, or
stated more precisely,
SWS < (MaxSeqNum + 1)/ 2
Intuitively, what this is saying is that the sliding window protocol alter-
nates between the two halves of the sequence number space, just as
stop-and-wait alternates between sequence numbers 0 and 1. The only
difference is that it continually slides between the two halves rather than
discretely alternating between them.
Note that this rule is specific to the situation where RWS = SWS. We
leave it as an exercise to determine the more general rule that works
for arbitrary values of RWS and SWS. Also note that the relationship
between the window size and the sequence number space depends on
an assumption that is so obvious that it is easy to overlook, namely, that
frames are not reordered in transit. This cannot happen on a direct point-2.5 Reliable Transmission
to-point link, since there is no way for one frame to overtake another
during transmission. However, we will see the sliding window algorithm
used in a different environments, and we will need to devise another
rule.
Implementation of Sliding Window
The following routines illustrate how we might implement the sending
and receiving sides of the sliding window algorithm. The routines are
taken from a working protocol named, appropriately enough, Sliding
Window Protocol (SWP). So as not to concern ourselves with the adjacent
protocols in the protocol graph, we denote the protocol sitting above SWP
as the high-level protocol (HLP) and the protocol sitting below SWP as the
link-level protocol (LLP).
We start by defining a pair of data structures. First, the frame header is
very simple: it contains a sequence number (SeqNum) and an acknowl-
edgment number (AckNum). It also contains a Flags field that indicates
whether the frame is an ACK or carries data.
typedef u_char SwpSeqno;
typedef struct {
SwpSeqnoSeqNum;/* sequence number of this frame */
SwpSeqnoAckNum;/* ack of received frame */
u_charFlags;/* up to 8 bits worth of flags */
} SwpHdr;
Next, the state of the sliding window algorithm has the following struc-
ture. For the sending side of the protocol, this state includes variables LAR
and LFS, as described earlier in this section, as well as a queue that holds
frames that have been transmitted but not yet acknowledged (sendQ).
The sending state also includes a counting semaphore called sendWin-
dowNotFull. We will see how this is used below, but generally, a semaphore
is a synchronization primitive that supports semWait and semSignal
operations. Every invocation of semSignal increments the semaphore
by 1, and every invocation of semWait decrements s by 1, with the call-
ing process blocked (suspended) should decrementing the semaphore
cause its value to become less than 0. A process that is blocked during
its call to semWait will be allowed to resume as soon as enough semSig-
105106
CHAPTER 2 Direct Links
nal operations have been performed to raise the value of the semaphore
above 0.
For the receiving side of the protocol, the state includes the variable
NFE. This is the next frame expected, the frame with a sequence num-
ber one more that the last frame received (LFR), described earlier in this
section. There is also a queue that holds frames that have been received
out of order (recvQ). Finally, although not shown, the sender and receiver
sliding window sizes are defined by constants SWS and RWS, respec-
tively.
typedef struct {
/* sender side state: */
SwpSeqno
LAR;
/* seqno of last ACK received */
SwpSeqnoLFS;
SemaphoresendWindowNotFull;
/* last frame sent */
SwpHdrhdr;
/* pre-initialized header */
struct sendQ_slot {
Eventtimeout;
Msgmsg;
/* event associated with send
-timeout */
}
sendQ[SWS];
/* receiver side state: */
SwpSeqno
NFE;
/* seqno of next frame expected */
struct recvQ_slot {
}
intreceived;
Msgmsg;
/* is msg valid? */
recvQ[RWS];
} SwpState;
The sending side of SWP is implemented by the procedure sendSWP.
This routine is rather simple. First, semWait causes this process to block
on a semaphore until it is OK to send another frame. Once allowed to pro-
ceed, sendSWP sets the sequence number in the frame’s header, saves
a copy of the frame in the transmit queue (sendQ), schedules a time-
out event to handle the case in which the frame is not acknowledged,2.5 Reliable Transmission
and sends the frame to the next-lower-level protocol, which we denote
as LINK.
One detail worth noting is the call to store_swp_hdr just before the
call to msgAddHdr. This routine translates the C structure that holds the
SWP header (state->hdr) into a byte string that can be safely attached to
the front of the message (hbuf). This routine (not shown) must translate
each integer field in the header into network byte order and remove any
padding that the compiler has added to the C structure. The issue of byte
order is a nontrivial issue, but for now, it is enough to assume that this
routine places the most significant bit of a multiword integer in the byte
with the highest address.
Another piece of complexity in this routine is the use of semWait and
the sendWindowNotFull semaphore. sendWindowNotFull is initialized to
the size of the sender’s sliding window, SWS (this initialization is not
shown). Each time the sender transmits a frame, the semWait operation
decrements this count and blocks the sender should the count go to 0.
Each time an ACK is received, the semSignal operation invoked in deliv-
erSWP (see below) increments this count, thus unblocking any waiting
sender.
static int
sendSWP(SwpState *state, Msg *frame)
{
struct sendQ_slot *slot;
hbuf[HLEN];
/* wait for send window to open */
semWait(&state->sendWindowNotFull);
state->hdr.SeqNum = ++state->LFS;
slot = &state->sendQ[state->hdr.SeqNum % SWS];
store_swp_hdr(state->hdr, hbuf);
msgAddHdr(frame, hbuf, HLEN);
msgSaveCopy(&slot->msg, frame);
slot->timeout = evSchedule(swpTimeout, slot,
SWP_SEND_TIMEOUT);
return send(LINK, frame);
}
107108
CHAPTER 2 Direct Links
Before continuing to the receive side of SWP, we need to reconcile a
seeming inconsistency. On the one hand, we have been saying that a high-
level protocol invokes the services of a low-level protocol by calling the
send operation, so we would expect that a protocol that wants to send
a message via SWP would call send(SWP, packet). On the other hand, the
procedure that implements SWP’s send operation is called sendSWP, and
its first argument is a state variable (SwpState). What gives? The answer is
that the operating system provides glue code that translates the generic
call to send into a protocol-specific call to sendSWP. This glue code
maps the first argument to send (the magic protocol variable SWP) into
both a function pointer to sendSWP and a pointer to the protocol state
that SWP needs to do its job. The reason we have the high-level proto-
col indirectly invoke the protocol-specific function through the generic
function call is that we want to limit how much information the high-
level protocol has coded in it about the low-level protocol. This makes
it easier to change the protocol graph configuration at some time in the
future.
Now we move on to SWP’s protocol-specific implementation of the
deliver operation, which is given in procedure deliverSWP. This routine
actually handles two different kinds of incoming messages: ACKs for
frames sent earlier from this node and data frames arriving at this node. In
a sense, the ACK half of this routine is the counterpart to the sender side
of the algorithm given in sendSWP. A decision as to whether the incom-
ing message is an ACK or a data frame is made by checking the Flags field
in the header. Note that this particular implementation does not support
piggybacking ACKs on data frames.
When the incoming frame is an ACK, deliverSWP simply finds the slot
in the transmit queue (sendQ) that corresponds to the ACK, cancels the
timeout event, and frees the frame saved in that slot. This work is actu-
ally done in a loop since the ACK may be cumulative. The only other thing
to note about this case is the call to subroutine swpInWindow. This sub-
routine, which is given below, ensures that the sequence number for the
frame being acknowledged is within the range of ACKs that the sender
currently expects to receive.
When the incoming frame contains data, deliverSWP first calls msgSt-
ripHdr and load_swp_hdr to extract the header from the frame. Routine
load_swp_hdr is the counterpart to store_swp_hdr discussed earlier; it
translates a byte string into the C data structure that holds the SWP2.5 Reliable Transmission
header. deliverSWP then calls swpInWindow to make sure the sequence
number of the frame is within the range of sequence numbers that it
expects. If it is, the routine loops over the set of consecutive frames it
has received and passes them up to the higher-level protocol by invok-
ing the deliverHLP routine. It also sends a cumulative ACK back to the
sender but does so by looping over the receive queue (it does not use the
SeqNumToAck variable used in the prose description given earlier in this
section).
static int
deliverSWP(SwpState state, Msg *frame)
{
SwpHdrhdr;
char*hbuf;
hbuf = msgStripHdr(frame, HLEN);
load_swp_hdr(&hdr, hbuf)
if (hdr->Flags & FLAG_ACK_VALID)
{
/* received an acknowledgment---do SENDER side */
if (swpInWindow(hdr.AckNum, state->LAR + 1,
state->LFS))
{
do
{
struct sendQ_slot *slot;
slot = &state->sendQ[++state->LAR % SWS];
evCancel(slot->timeout);
msgDestroy(&slot->msg);
semSignal(&state->sendWindowNotFull);
} while (state->LAR != hdr.AckNum);
}
}
if (hdr.Flags & FLAG_HAS_DATA)
{
struct recvQ_slot *slot;
/* received data packet---do RECEIVER side */
109110
CHAPTER 2 Direct Links
slot = &state->recvQ[hdr.SeqNum % RWS];
if (!swpInWindow(hdr.SeqNum, state->NFE,
state->NFE + RWS - 1))
{
/* drop the message */
return SUCCESS;
}
msgSaveCopy(&slot->msg, frame);
slot->received = TRUE;
if (hdr.SeqNum == state->NFE)
{
Msg m;
while (slot->received)
{
deliver(HLP, &slot->msg);
msgDestroy(&slot->msg);
slot->received = FALSE;
slot = &state->recvQ[++state->NFE % RWS];
}
/* send ACK: */
prepare_ack(&m, state->NFE - 1);
send(LINK, &m);
msgDestroy(&m);
}
}
return SUCCESS;
}
Finally, swpInWindow is a simple subroutine that checks to see if a given
sequence number falls between some minimum and maximum sequence
number.
static bool
swpInWindow(SwpSeqno seqno, SwpSeqno min, SwpSeqno max)
{
SwpSeqno pos, maxpos;
pos
= seqno - min;
/* pos *should* be in range
[0..MAX) */2.5 Reliable Transmission
maxpos = max - min + 1;
/* maxpos is in range
[0..MAX] */
return pos < maxpos;
}
Frame Order and Flow Control
The sliding window protocol is perhaps the best known algorithm in com-
puter networking. What is easily confused about the algorithm, however,
is that it can be used to serve three different roles. The first role is the one
we have been concentrating on in this section—to reliably deliver frames
across an unreliable link. (In general, the algorithm can be used to reliably
deliver messages across an unreliable network.) This is the core function
of the algorithm.
The second role that the sliding window algorithm can serve is to pre-
serve the order in which frames are transmitted. This is easy to do at
the receiver—since each frame has a sequence number, the receiver just
makes sure that it does not pass a frame up to the next-higher-level pro-
tocol until it has already passed up all frames with a smaller sequence
number. That is, the receiver buffers (i.e., does not pass along) out-of-
order frames. The version of the sliding window algorithm described in
this section does preserve frame order, although we could imagine a vari-
ation in which the receiver passes frames to the next protocol without
waiting for all earlier frames to be delivered. A question we should ask
ourselves is whether we really need the sliding window protocol to keep
the frames in order at the link level or whether, instead, this functionality
should be implemented by a protocol higher in the stack.
The third role that the sliding window algorithm sometimes plays is
to support flow control—a feedback mechanism by which the receiver is
able to throttle the sender. Such a mechanism is used to keep the sender
from overrunning the receiver—that is, from transmitting more data than
the receiver is able to process. This is usually accomplished by augment-
ing the sliding window protocol so that the receiver not only acknowl-
edges frames it has received but also informs the sender of how many
frames it has room to receive. The number of frames that the receiver is
capable of receiving corresponds to how much free buffer space it has. As
in the case of ordered delivery, we need to make sure that flow control is
necessary at the link level before incorporating it into the sliding window
protocol.
111112
CHAPTER 2 Direct Links
One important concept to take away from this discussion is the system design
principle we call separation of concerns. That is, you must be careful to distinguish
between different functions that are sometimes rolled together in one mecha-
nism, and you must make sure that each function is necessary and being sup-
ported in the most effective way. In this particular case, reliable delivery, ordered
delivery, and ﬂow control are sometimes combined in a single sliding window
protocol, and we should ask ourselves if this is the right thing to do at the link
level.
2.5.3 Concurrent Logical Channels
The data link protocol used in the original ARPANET provides an interest-
ing alternative to the sliding window protocol in that it is able to keep the
pipe full while still using the simple stop-and-wait algorithm. One impor-
tant consequence of this approach is that the frames sent over a given
link are not kept in any particular order. The protocol also implies noth-
ing about flow control.
The idea underlying the ARPANET protocol, which we refer to as con-
current logical channels, is to multiplex several logical channels onto a
single point-to-point link and to run the stop-and-wait algorithm on each
of these logical channels. There is no relationship maintained among the
frames sent on any of the logical channels, yet because a different frame
can be outstanding on each of the several logical channels, the sender can
keep the link full.
More precisely, the sender keeps 3 bits of state for each channel: a
Boolean, saying whether the channel is currently busy; the 1-bit sequence
number to use the next time a frame is sent on this logical channel; and
the next sequence number to expect on a frame that arrives on this chan-
nel. When the node has a frame to send, it uses the lowest idle channel,
and otherwise, it behaves just like stop-and-wait.
In practice, the ARPANET supported 8 logical channels over each
ground link and 16 over each satellite link. In the ground-link case, the
header for each frame included a 3-bit channel number and a 1-bit
sequence number, for a total of 4 bits. This is exactly the number of
bits the sliding window protocol requires to support up to 8 outstanding
frames on the link when RWS = SWS.2.6 Multiaccess Networks
2.6 MULTIACCESS NETWORKS
Developed in the mid-1970s by researchers at the Xerox Palo Alto Research
Center (PARC), the Ethernet eventually became the dominant local area
networking technology, emerging from a pack of competing technolo-
gies. Today, it competes mainly with 802.11 wireless networks but remains
extremely popular in campus networks and datacenters. The more gen-
eral name for the technology behind the Ethernet is Carrier Sense, Multi-
ple Access with Collision Detect (CSMA/CD).
As indicated by the CSMA name, the Ethernet is a multiple-access net-
work, meaning that a set of nodes sends and receives frames over a shared
link. You can, therefore, think of an Ethernet as being like a bus that has
multiple stations plugged into it. The “carrier sense” in CSMA/CD means
that all the nodes can distinguish between an idle and a busy link, and
“collision detect” means that a node listens as it transmits and can there-
fore detect when a frame it is transmitting has interfered (collided) with a
frame transmitted by another node.
The Ethernet has its roots in an early packet radio network, called
Aloha, developed at the University of Hawaii to support computer com-
munication across the Hawaiian Islands. Like the Aloha network, the fun-
damental problem faced by the Ethernet is how to mediate access to a
shared medium fairly and efficiently (in Aloha, the medium was the atmo-
sphere, while in the Ethernet, the medium was originally a coax cable).
The core idea in both Aloha and the Ethernet is an algorithm that con-
trols when each node can transmit.
Modern Ethernet links are now largely point-to-point; that is, they con-
nect one host to an Ethernet switch, or they interconnect switches. As a
consequence, the “multiple-access” algorithm is not used much in today’s
wired Ethernets, but a variant is now used in wireless networks, such as
802.11 networks (also known as Wi-Fi). Due to the enormous influence of
Ethernet, we chose to describe its classic algorithm here and then explain
how it has been adapted to Wi-Fi in the next section. We will also discuss
Ethernet switches elsewhere. For now, we will focus on how a single Eth-
ernet link works.
Digital Equipment Corporation and Intel Corporation joined Xerox to
define a 10-Mbps Ethernet standard in 1978. This standard then formed
the basis for IEEE standard 802.3, which additionally defines a much
wider collection of physical media over which an Ethernet can operate,
including 100-Mbps, 1-Gbps, 10-Gbps, 40-Gbps, and 100-Gbps versions.
113114
CHAPTER 2 Direct Links
2.6.1 Physical Properties
Ethernet segments were originally implemented using coaxial cable of
length up to 500 m. (Modern Ethernets use twisted copper pairs, usually a
particular type known as “Category 5,” or optical fibers, and in some cases
can be quite a lot longer than 500 m.) This cable was similar to the type
used for cable TV. Hosts connected to an Ethernet segment by tapping
into it. A transceiver, a small device directly attached to the tap, detected
when the line was idle and drove the signal when the host was transmit-
ting. It also received incoming signals. The transceiver, in turn, connected
to an Ethernet adaptor, which was plugged into the host. This configura-
tion is shown in Figure 2.19.
■ FIGURE 2.19 Ethernet transceiver and adaptor.
Multiple Ethernet segments can be joined together by repeaters (or a
multiport variant of a repeater, called a hub). A repeater is a device that
forwards digital signals, much like an amplifier forwards analog signals;
repeaters do not understand bits or frames. No more than four repeaters
could be positioned between any pair of hosts, meaning that a classical
Ethernet had a total reach of only 2500 m. For example, using just two
repeaters between any pair of hosts supports a configuration similar to
the one illustrated in Figure 2.20; that is, a segment running down the
spine of a building with a segment on each floor.
Any signal placed on the Ethernet by a host is broadcast over the
entire network; that is, the signal is propagated in both directions, and
repeaters and hubs forward the signal on all outgoing segments. Termi-
nators attached to the end of each segment absorb the signal and keep it2.6 Multiaccess Networks
■ FIGURE 2.20 Ethernet repeater, interconnecting segments to form a larger collision domain.
from bouncing back and interfering with trailing signals. The original Eth-
ernet specifications used the Manchester encoding scheme described in
an earlier section, while 4B/5B encoding (or the similar 8B/10B scheme)
is used today on higher-speed Ethernets.
It is important to understand that whether a given Ethernet spans a
single segment, a linear sequence of segments connected by repeaters, or
multiple segments connected in a star configuration, data transmitted by
any one host on that Ethernet reach all the other hosts. This is the good
news. The bad news is that all these hosts are competing for access to the
same link, and, as a consequence, they are said to be in the same collision
domain. The multiaccess part of the Ethernet is all about dealing with the
competition for the link that arises in a collision domain.
2.6.2 Access Protocol
We now turn our attention to the algorithm that controls access to a
shared Ethernet link. This algorithm is commonly called the Ethernet’s
media access control (MAC). It is typically implemented in hardware on
the network adaptor. We will not describe the hardware per se but instead
focus on the algorithm it implements. First, however, we describe the Eth-
ernet’s frame format and addresses.
115116
CHAPTER 2 Direct Links
Frame Format
Each Ethernet frame is defined by the format given in Figure 2.21. The
64-bit preamble allows the receiver to synchronize with the signal; it is
a sequence of alternating 0s and 1s. Both the source and destination
hosts are identified with a 48-bit address. The packet type field serves
as the demultiplexing key; it identifies to which of possibly many higher-
level protocols this frame should be delivered. Each frame contains up to
1500 bytes of data. Minimally, a frame must contain at least 46 bytes of
data, even if this means the host has to pad the frame before transmit-
ting it. The reason for this minimum frame size is that the frame must
be long enough to detect a collision; we discuss this more below. Finally,
each frame includes a 32-bit CRC. Like the HDLC protocol described in an
earlier section, the Ethernet is a bit-oriented framing protocol. Note that
from the host’s perspective, an Ethernet frame has a 14-byte header: two
6-byte addresses and a 2-byte type field. The sending adaptor attaches
the preamble and CRC before transmitting, and the receiving adaptor
removes them.
■ FIGURE 2.21 Ethernet frame format.
Addresses
Each host on an Ethernet—in fact, every Ethernet host in the world—has a
unique Ethernet address. Technically, the address belongs to the adaptor,
not the host; it is usually burned into ROM. Ethernet addresses are typi-
cally printed in a form humans can read as a sequence of six numbers sep-
arated by colons. Each number corresponds to 1 byte of the 6-byte address
and is given by a pair of hexadecimal digits, one for each of the 4-bit nib-
bles in the byte; leading 0s are dropped. For example, 8:0:2b:e4:b1:2 is the
human-readable representation of Ethernet address
00001000 00000000 00101011 11100100 10110001 00000010
To ensure that every adaptor gets a unique address, each manufac-
turer of Ethernet devices is allocated a different prefix that must be
prepended to the address on every adaptor they build. For example,
Advanced Micro Devices has been assigned the 24-bit prefix 080020 (or2.6 Multiaccess Networks
8:0:20). A given manufacturer then makes sure the address suffixes it pro-
duces are unique.
Each frame transmitted on an Ethernet is received by every adap-
tor connected to that Ethernet. Each adaptor recognizes those frames
addressed to its address and passes only those frames on to the host. (An
adaptor can also be programmed to run in promiscuous mode, in which
case it delivers all received frames to the host, but this is not the normal
mode.) In addition to these unicast addresses, an Ethernet address con-
sisting of all 1s is treated as a broadcast address; all adaptors pass frames
addressed to the broadcast address up to the host. Similarly, an address
that has the first bit set to 1 but is not the broadcast address is called a
multicast address. A given host can program its adaptor to accept some
set of multicast addresses. Multicast addresses are used to send messages
to some subset of the hosts on an Ethernet (e.g., all file servers). To sum-
marize, an Ethernet adaptor receives all frames and accepts:
■frames addressed to its own address;
■frames addressed to the broadcast address;
■frames addressed to a multicast address, if it has been instructed to
listen to that address;
■all frames, if it has been placed in promiscuous mode.
It passes to the host only the frames that it accepts.
Transmitter Algorithm
As we have just seen, the receiver side of the Ethernet protocol is sim-
ple; the real smarts are implemented at the sender’s side. The transmitter
algorithm is defined as follows.
When the adaptor has a frame to send and the line is idle, it transmits
the frame immediately; there is no negotiation with the other adaptors.
The upper bound of 1500 bytes in the message means that the adaptor
can occupy the line for only a fixed length of time.
When an adaptor has a frame to send and the line is busy, it waits for
the line to go idle and then transmits immediately. (To be more precise, all
adaptors wait 9.6 µs after the end of one frame before beginning to trans-
mit the next frame. This is true for both the sender of the first frame as
well as those nodes listening for the line to become idle.) The Ethernet is
said to be a 1-persistent protocol because an adaptor with a frame to send
transmits with probability 1 whenever a busy line goes idle. In general,
a p-persistent algorithm transmits with probability 0 ≤ p ≤ 1 after a line
117118
CHAPTER 2 Direct Links
becomes idle and defers with probability q = 1 − p. The reasoning behind
choosing a p < 1 is that there might be multiple adaptors waiting for the
busy line to become idle, and we do not want all of them to begin trans-
mitting at the same time. If each adaptor transmits immediately with a
probability of, say, 33%, then up to three adaptors can be waiting to trans-
mit, and the odds are that only one will begin transmitting when the line
becomes idle. Despite this reasoning, an Ethernet adaptor always trans-
mits immediately after noticing that the network has become idle and has
been very effective in doing so.
To complete the story about p-persistent protocols for the case when
p < 1, you might wonder how long a sender that loses the coin flip (i.e.,
decides to defer) has to wait before it can transmit. The answer for the
Aloha network, which originally developed this style of protocol, was to
divide time into discrete slots, with each slot corresponding to the length
of time it takes to transmit a full frame. Whenever a node has a frame
to send and it senses an empty (idle) slot, it transmits with probability p
and defers until the next slot with probability q = 1 − p. If that next slot is
also empty, the node again decides to transmit or defer, with probabilities
p and q, respectively. If that next slot is not empty—that is, some other
station has decided to transmit—then the node simply waits for the next
idle slot and the algorithm repeats.
Returning to our discussion of the Ethernet, because there is no cen-
tralized control, it is possible for two (or more) adaptors to begin trans-
mitting at the same time, either because both found the line to be idle or
because both had been waiting for a busy line to become idle. When this
happens, the two (or more) frames are said to collide on the network. Each
sender, because the Ethernet supports collision detection, is able to deter-
mine that a collision is in progress. At the moment an adaptor detects that
its frame is colliding with another, it first makes sure to transmit a 32-bit
jamming sequence and then stops the transmission. Thus, a transmitter
will minimally send 96 bits in the case of a collision: 64-bit preamble plus
32-bit jamming sequence.
One way that an adaptor will send only 96 bits—which is sometimes
called a runt frame—is if the two hosts are close to each other. Had the
two hosts been farther apart, they would have had to transmit longer, and
thus send more bits, before detecting the collision. In fact, the worst-case
scenario happens when the two hosts are at opposite ends of the Ethernet.
To know for sure that the frame it just sent did not collide with another2.6 Multiaccess Networks
frame, the transmitter may need to send as many as 512 bits. Not coin-
cidentally, every Ethernet frame must be at least 512 bits (64 bytes) long:
14 bytes of header plus 46 bytes of data plus 4 bytes of CRC.
Why 512 bits? The answer is related to another question you might ask
about an Ethernet: Why is its length limited to only 2500 m? Why not 10
or 1000 km? The answer to both questions has to do with the fact that the
farther apart two nodes are, the longer it takes for a frame sent by one to
reach the other, and the network is vulnerable to a collision during this
time.
■ FIGURE 2.22 Worst-case scenario: (a) A sends a frame at time t; (b) A’s frame arrives at B at time t + d; (c) B begins
transmitting at time t + d and collides with A’s frame; (d) B’s runt (32-bit) frame arrives at A at time t + 2 × d.
Figure 2.22 illustrates the worst-case scenario, where hosts A and B
are at opposite ends of the network. Suppose host A begins transmit-
ting a frame at time t, as shown in (a). It takes it one link latency (let
us denote the latency as d) for the frame to reach host B. Thus, the first
bit of A’s frame arrives at B at time t + d, as shown in (b). Suppose an
instant before host A’s frame arrives (i.e., B still sees an idle line), host B
119120
CHAPTER 2 Direct Links
begins to transmit its own frame. B’s frame will immediately collide with
A’s frame, and this collision will be detected by host B (c). Host B will send
the 32-bit jamming sequence, as described above. (B’s frame will be a
runt.) Unfortunately, host A will not know that the collision occurred until
B’s frame reaches it, which will happen one link latency later, at time t +
2 × d, as shown in (d). Host A must continue to transmit until this time
in order to detect the collision. In other words, host A must transmit for
2 × d to be sure that it detects all possible collisions. Considering that a
maximally configured Ethernet is 2500 m long and that there may be up
to four repeaters between any two hosts, the round-trip delay has been
determined to be 51.2 µs, which on a 10-Mbps Ethernet corresponds to
512 bits. The other way to look at this situation is that we need to limit the
Ethernet’s maximum latency to a fairly small value (e.g., 51.2 µs) for the
access algorithm to work; hence, an Ethernet’s maximum length must be
something on the order of 2500 m.
Once an adaptor has detected a collision and stopped its transmission,
it waits a certain amount of time and tries again. Each time it tries to trans-
mit but fails, the adaptor doubles the amount of time it waits before trying
again. This strategy of doubling the delay interval between each retrans-
mission attempt is a general technique known as exponential backoff.
More precisely, the adaptor first delays either 0 or 51.2 µs, selected at ran-
dom. If this effort fails, it then waits 0, 51.2, 102.4, or 153.6 µs (selected
randomly) before trying again; this is k × 51.2 for k = 0..3. After the third
collision, it waits k × 51.2 for k = 0..23 − 1, again selected at random. In
general, the algorithm randomly selects a k between 0 and 2n − 1 and
waits k × 51.2 µs, where n is the number of collisions experienced so far.
The adaptor gives up after a given number of tries and reports a trans-
mit error to the host. Adaptors typically retry up to 16 times, although the
backoff algorithm caps n in the above formula at 10.
2.6.3 Longevity of Ethernet
Ethernet has been the dominant local area network technology for over 30
years. Today, it is typically deployed point-to-point rather than tapping
into a coax cable, it often runs at speeds of 1 or 10 Gbps rather than 10
Mbps, and it allows jumbo packets with up to 9000 bytes of data rather
than 1500 bytes. But it remains backwards compatible with the original
standard. This makes it worth saying a few words about why Ethernets2.7 Wireless Networks
have been so successful so that we can understand the properties we
should emulate with any technology that tries to replace it.
First, an Ethernet is extremely easy to administer and maintain: there
are no routing or configuration tables to be kept up-to-date, and it is
easy to add a new host to the network. It is hard to imagine a sim-
pler network to administer. Second, it is inexpensive: cable/fiber is rel-
atively cheap, and the only other cost is the network adaptor on each
host. Ethernet became deeply entrenched for these reasons, and any
switch-based approach that aspired to displace it required additional
investment in infrastructure (the switches), on top of the cost of each
adaptor. The switch-based variant of Ethernet did eventually succeed in
replacing multiaccess Ethernet, but this is primarily because it could be
deployed incrementally—with some hosts connected by point-to-point
links to switches while others remained tapped into coax and connected
to repeaters or hubs—all the while retaining the simplicity of network
administration.
2.7 WIRELESS NETWORKS
Wireless technologies differ from wired links in some important ways
while at the same time sharing many common properties. Like wired
links, issues of bit errors are of great concern—typically even more so
due to the unpredictable noise environment of most wireless links. Fram-
ing and reliability also have to be addressed. Unlike wired links, power
is a big issue for wireless, especially because wireless links are often
used by small mobile devices (like phones and sensors) that have lim-
ited access to power (e.g., a small battery). Furthermore, you cannot
go blasting away at arbitrarily high power with a radio transmitter—
there are concerns about interference with other devices and usually
regulations about how much power a device may emit at any given
frequency.
Wireless media are also inherently multiaccess; it is difficult to direct
your radio transmission to just a single receiver or to avoid receiving
radio signals from any transmitter with enough power in your neigh-
borhood. Hence, media access control is a central issue for wireless
links. And, because it is hard to control who receives your signal when
you transmit over the air, issues of eavesdropping may also have to be
addressed.
121122
CHAPTER 2 Direct Links
Token rings
For many years, there were two main ways to build a LAN: Ethernet or token
ring. The most prevalent form of token ring was invented by IBM and stan-
dardized as IEEE 802.5. Token rings have a number of things in common with
Ethernet: the ring behaves like a single shared medium and employs a dis-
tributed algorithm to decide which station can transmit on to that medium
at any given time; and every node on a given ring can see all the packets
transmitted by other nodes.
The most obvious difference between token ring and Ethernet is the
topology, where the nodes in a token ring form a loop. That is, each node
is connected to a pair of neighbors, one upstream and one downstream. The
“token” is just a special sequence of bits which circulates around the ring;
each node receives and then forwards the token. When a node that has a
frame to transmit sees the token, it takes the token off the ring (i.e., it does
not forward the special bit pattern) and instead inserts its frame into the
ring. Each node along the way simply forwards the frame, with the destina-
tion node saving a copy and forwarding the message onto the next node
on the ring. When the frame makes its way back around to the sender, this
node strips its frame off the ring (rather than continuing to forward it) and
reinserts the token. In this way, some node downstream will have the oppor-
tunity to transmit a frame. The media access algorithm is fair in the sense that
as the token circulates around the ring, each node gets a chance to transmit.
Nodes are serviced in a round-robin fashion.
Finally, it is worth noting that just as Ethernet was inspired by the Aloha
network designed by researchers at the University of Hawaii, the ﬁrst token
ring network was originally designed by researchers at Cambridge Univer-
sity. The Cambridge Ring and Aloha were contemporary research projects in
the mid-1970s.
There is a baffling assortment of different wireless technologies, each
of which makes different tradeoffs in various dimensions. One simple way
to categorize the different technologies is by the data rates they provide
and how far apart communicating nodes can be. Other important dif-
ferences include which part of the electromagnetic spectrum they use
(including whether it requires a license) and how much power they con-
sume. In this section, we discuss two prominent wireless technologies:
Wi-Fi (more formally known as 802.11) and Bluetooth. The next section
discusses cellular networks in the context of ISP access services. Table 2.3
gives an overview of these technologies and how they compare to each
other.2.7 Wireless Networks
Table 2.3 Overview of leading wireless technologies.
Bluetooth (802.15.1)Wi-Fi (802.11)Typical link length10 m100 mTens of kilome-
ters
4G cellular
Typical data rate2 Mbps (shared)150–450 Mbps1–5 Mbps
Typical useLink a peripheral
to a computerLink a computer
to a wired baseLink mobile phone
to a wired tower
Wired technology
analogyUSBEthernetPON
You may recall that bandwidth sometimes means the width of a fre-
quency band in hertz and sometimes the data rate of a link. Because both
these concepts come up in discussions of wireless networks, we are going
to use bandwidth here in its stricter sense—width of a frequency band—
and use the term data rate to describe the number of bits per second that
can be sent over the link, as in Table 2.3.
2.7.1 Basic Issues
Because wireless links all share the same medium, the challenge is to
share that medium efficiently, without unduly interfering with each other.
Most of this sharing is accomplished by dividing it up along the dimen-
sions of frequency and space. Exclusive use of a particular frequency in a
particular geographic area may be allocated to an individual entity such
as a corporation. It is feasible to limit the area covered by an electromag-
netic signal because such signals weaken, or attenuate, with the distance
from their origin. To reduce the area covered by your signal, reduce the
power of your transmitter.
These allocations are typically determined by government agencies,
such as the Federal Communications Commission (FCC) in the United
States. Specific bands (frequency ranges) are allocated to certain uses.
Some bands are reserved for government use. Other bands are reserved
for uses such as AM radio, FM radio, television, satellite communication,
and cellular phones. Specific frequencies within these bands are then
licensed to individual organizations for use within certain geographical
areas. Finally, several frequency bands are set aside for license-exempt
usage—bands in which a license is not needed.
Devices that use license-exempt frequencies are still subject to certain
restrictions to make that otherwise unconstrained sharing work. Most
123124
CHAPTER 2 Direct Links
important of these is a limit on transmission power. This limits the range
of a signal, making it less likely to interfere with another signal. For exam-
ple, a cordless phone (a common unlicensed device) might have a range
of about 100 feet.
One idea that shows up a lot when spectrum is shared among many
devices and applications is spread spectrum. The idea behind spread
spectrum is to spread the signal over a wider frequency band so as to
minimize the impact of interference from other devices. (Spread spec-
trum was originally designed for military use, so these “other devices”
were often attempting to jam the signal.) For example, frequency hop-
ping is a spread spectrum technique that involves transmitting the signal
over a random sequence of frequencies; that is, first transmitting at one
frequency, then a second, then a third, and so on. The sequence of fre-
quencies is not truly random but is instead computed algorithmically by a
pseudorandom number generator. The receiver uses the same algorithm
as the sender and initializes it with the same seed; hence, it is able to hop
frequencies in sync with the transmitter to correctly receive the frame.
This scheme reduces interference by making it unlikely that two signals
would be using the same frequency for more than the infrequent isolated
bit.
A second spread spectrum technique, called direct sequence, adds
redundancy for greater tolerance of interference. Each bit of data is repre-
sented by multiple bits in the transmitted signal so that if some of the
transmitted bits are damaged by interference, there is usually enough
redundancy to recover the original bit. For each bit the sender wants to
transmit, it actually sends the exclusive-OR of that bit and n random bits.
As with frequency hopping, the sequence of random bits is generated by
a pseudorandom number generator known to both the sender and the
receiver. The transmitted values, known as an n-bit chipping code, spread
the signal across a frequency band that is n times wider than the frame
would have otherwise required. Figure 2.23 gives an example of a 4-bit
chipping sequence.
Different parts of the electromagnetic spectrum have different prop-
erties, making some better suited to communication and some less so.
For example, some can penetrate buildings and some cannot. Govern-
ments regulate only the prime communication portion: the radio and
microwave ranges. As demand for prime spectrum increases, there is
great interest in the spectrum that is becoming available as analog tele-
vision is phased out in favor of digital.2.7 Wireless Networks
■ FIGURE 2.23 Example 4-bit chipping sequence.
In many wireless networks today, we observe that there are two dif-
ferent classes of endpoints. One endpoint, sometimes described as the
base station, usually has no mobility but has a wired (or at least high-
bandwidth) connection to the Internet or other networks, as shown in
Figure 2.24. The node at the other end of the link—shown here as a client
node—is often mobile and relies on its link to the base station for all of its
communication with other nodes.
Observe that in Figure 2.24, we have used a wavy pair of lines to rep-
resent the wireless “link” abstraction provided between two devices (e.g.,
between a base station and one of its client nodes). One of the interesting
aspects of wireless communication is that it naturally supports point-to-
multipoint communication, because radio waves sent by one device can
be simultaneously received by many devices. However, it is often useful
to create a point-to-point link abstraction for higher-layer protocols, and
we will see examples of how this works later in this section.
Note that in Figure 2.24, communication between nonbase (client)
nodes is routed via the base station. This is in spite of the fact that radio
waves emitted by one client node may well be received by other client
nodes—the common base station model does not permit direct commu-
nication between the client nodes.
This topology implies three qualitatively different levels of mobility.
The first level is no mobility, such as when a receiver must be in a fixed
location to receive a directional transmission from the base station. The
second level is mobility within the range of a base, as is the case with Blue-
tooth. The third level is mobility between bases, as is the case with cell
phones and Wi-Fi.
An alternative topology that is seeing increasing interest is the mesh or
ad hoc network. In a wireless mesh, nodes are peers; that is, there is no
125126
CHAPTER 2 Direct Links
■ FIGURE 2.24 A wireless network using a base station.
special base station node. Messages may be forwarded via a chain of peer
nodes as long as each node is within range of the preceding node. This is
illustrated in Figure 2.25. This allows the wireless portion of a network to
extend beyond the limited range of a single radio. From the point of view
of competition between technologies, this allows a shorter-range technol-
ogy to extend its range and potentially compete with a longer-range tech-
nology. Meshes also offer fault tolerance by providing multiple routes for
a message to get from point A to point B. A mesh network can be extended
incrementally, with incremental costs. On the other hand, a mesh network
requires nonbase nodes to have a certain level of sophistication in their
hardware and software, potentially increasing per-unit costs and power
consumption, a critical consideration for battery-powered devices. Wire-
less mesh networks are of considerable research interest, but they are still
in their relative infancy compared to networks with base stations. Wireless
sensor networks, another hot emerging technology, often form wireless
meshes.
Now that we have covered some of the common wireless issues, let us
take a look at the details of two common wireless technologies.2.7 Wireless Networks
■ FIGURE 2.25 A wireless ad hoc or mesh network.
2.7.2 802.11/Wi-Fi
Most readers will have used a wireless network based on the IEEE 802.11
standards, often referred to as Wi-Fi. Wi-Fi is technically a trademark,
owned by a trade group called the Wi-Fi Alliance, which certifies prod-
uct compliance with 802.11. Like Ethernet, 802.11 is designed for use
in a limited geographical area (homes, office buildings, campuses), and
its primary challenge is to mediate access to a shared communication
medium—in this case, signals propagating through space.
Physical Properties
802.11 defines a number of different physical layers that operate in vari-
ous frequency bands and provide a range of different data rates.
127128
CHAPTER 2 Direct Links
The original 802.11 standard defined two radio-based physical lay-
ers standards, one using frequency hopping (over 79 1-MHz-wide fre-
quency bandwidths) and the other using direct sequence spread spec-
trum (with an 11-bit chipping sequence). Both provided data rates in
the 2 Mbps range. Subsequently, the physical layer standard 802.11b was
added, using a variant of direct sequence and supporting up to 11 Mbps.
These three standards all operated in the license-exempt 2.4-GHz fre-
quency band of the electromagnetic spectrum. Then came 802.11a, which
delivered up to 54 Mbps using a variant of frequency division multiplex-
ing called orthogonal frequency division multiplexing (OFDM). 802.11a
runs in the license-exempt 5-GHz band. 802.11g followed and, also using
OFDM, delivered up to 54 Mbps. 802.11g is backward compatible with
802.11b (and returns to the 2.4-GHz band).
At the time of writing, many devices support 802.11n or 802.11ac,
which typically achieve per-device data rates of 150 Mbps to 450 Mbps,
respectively. This improvement is partly due to the use of multiple anten-
nas and allowing greater wireless channel bandwidths. The use of multi-
ple antennas is often called MIMO for multiple-input, multiple-output.
The latest emerging standard, 802.11ax, promises another substantial
improvement in throughput, in part by adopting many of the coding and
modulation techniques used in the 4G/5G cellular network, which we
describe in the next section.
It is common for commercial products to support more than one fla-
vor of 802.11; many base stations support all five variants (a,b, g, n, and
ac). This not only ensures compatibility with any device that supports any
one of the standards but also makes it possible for two such products to
choose the highest bandwidth option for a particular environment.
It is worth noting that while all the 802.11 standards define a maximum
bit rate that can be supported, they mostly support lower bit rates as well
(e.g., 802.11a allows for bit rates of 6, 9, 12, 18, 24, 36, 48, and 54 Mbps). At
lower bit rates, it is easier to decode transmitted signals in the presence
of noise. Different modulation schemes are used to achieve the various
bit rates. In addition, the amount of redundant information in the form
of error-correcting codes is varied. More redundant information means
higher resilience to bit errors at the cost of lowering the effective data rate
(since more of the transmitted bits are redundant).
The systems try to pick an optimal bit rate based on the noise environ-
ment in which they find themselves; the algorithms for bit rate selection
can be quite complex. Interestingly, the 802.11 standards do not specify a2.7 Wireless Networks
particular approach but leave the algorithms to the various vendors. The
basic approach to picking a bit rate is to estimate the bit error rate either
by directly measuring the signal-to-noise ratio (SNR) at the physical layer
or by estimating the SNR by measuring how often packets are successfully
transmitted and acknowledged. In some approaches, a sender will occa-
sionally probe a higher bit rate by sending one or more packets at that rate
to see if it succeeds.
Collision Avoidance
At first glance, it might seem that a wireless protocol would follow the
same algorithm as the Ethernet—wait until the link becomes idle before
transmitting and back off should a collision occur—and, to a first approx-
imation, this is what 802.11 does. The additional complication for wire-
less is that while a node on an Ethernet receives every other node’s
transmissions and can transmit and receive at the same time, neither
of these conditions holds for wireless nodes. This makes detection of
collisions rather more complex. The reason wireless nodes cannot usu-
ally transmit and receive at the same time (on the same frequency) is
that the power generated by the transmitter is much higher than any
received is likely to be and so swamps the receiving circuitry. The reason
a node may not receive transmissions from another node is because that
node may be too far away or blocked by an obstacle. This situation is a
bit more complex than it first appears, as the following discussion will
illustrate.
■ FIGURE 2.26 The hidden node problem. Although A and C are hidden from each other, their signals can collide at B.
(B’s reach is not shown.)
129130
CHAPTER 2 Direct Links
Consider the situation depicted in Figure 2.26, where A and C are both
within range of B but not each other. Suppose both A and C want to com-
municate with B, and so they each send it a frame. A and C are unaware of
each other, since their signals do not carry that far. These two frames col-
lide with each other at B, but unlike an Ethernet, neither A nor C is aware
of this collision. A and C are said to be hidden nodes with respect to each
other.
■ FIGURE 2.27 The exposed node problem. Although B and C are exposed to each other’s signals, there is no interference
if B transmits to A while C transmits to D. (A’ and D’s reaches are not shown.)
A related problem, called the exposed node problem, occurs under the
circumstances illustrated in Figure 2.27, where each of the four nodes is
able to send and receive signals that reach just the nodes to its immedi-
ate left and right. For example, B can exchange frames with A and C, but it
cannot reach D, while C can reach B and D but not A. Suppose B is sending
to A. Node C is aware of this communication because it hears B’s trans-
mission. It would be a mistake, however, for C to conclude that it cannot
transmit to anyone just because it can hear B’s transmission. For exam-
ple, suppose C wants to transmit to node D. This is not a problem, since
C’s transmission to D will not interfere with A’s ability to receive from B. (It
would interfere with A sending to B, but B is transmitting in our example.)
802.11 addresses these problems by using CSMA/CA, where the CA
stands for collision avoidance, in contrast to the collision detection of
CSMA/CD used on Ethernets. There are a few pieces to make this work.
The Carrier Sense part seems simple enough: before sending a packet,
the transmitter checks if it can hear any other transmissions; if not, it2.7 Wireless Networks
sends. However, because of the hidden node problem, just waiting for the
absence of signals from other transmitters does not guarantee that a col-
lision will not occur from the perspective of the receiver. For this reason,
one part of CSMA/CA is an explicit ACK from the receiver to the sender.
If the packet was successfully decoded and passed its CRC at the receiver,
the receiver sends an ACK back to the sender.
Note that if a collision does occur, it will render the entire packet use-
less. For this reason, 802.11 adds an optional mechanism called RTS-CTS
(Ready to Send-Clear to Send). This goes some way toward addressing the
hidden node problem. The sender sends an RTS—a short packet—to the
intended receiver, and if that packet is received successfully, the receiver
responds with another short packet, the CTS. Even though the RTS may
not have been heard by a hidden node, the CTS probably will be. This
effectively tells the nodes within range of the receiver that they should not
send anything for a while—the amount of time of the intended transmis-
sion is included in the RTS and CTS packets. After that time plus a small
interval has passed, the carrier can be assumed to be available again, and
another node is free to try to send.
Of course, two nodes might detect an idle link and try to transmit an
RTS frame at the same time, causing their RTS frames to collide with each
other. The senders realize the collision has happened when they do not
receive the CTS frame after a period of time, in which case they each wait
a random amount of time before trying again. The amount of time a given
node delays is defined by an exponential backoff algorithm very much like
that used on the Ethernet.
After a successful RTS-CTS exchange, the sender sends its data packet
and, if all goes well, receives an ACK for that packet. In the absence of a
timely ACK, the sender will try again to request usage of the channel, using
the same process described above. By this time, of course, other nodes
may again be trying to get access to the channel as well.
Distribution System
As described so far, 802.11 would be suitable for a network with a mesh
(ad hoc) topology, and development of an 802.11s standard for mesh
networks is nearing completion. At the current time, however, nearly all
802.11 networks use a base-station-oriented topology.
Instead of all nodes being created equal, some nodes are allowed to
roam (e.g., your laptop) and some are connected to a wired network
infrastructure. 802.11 calls these base stations access points (APs), and
131132
CHAPTER 2 Direct Links
they are connected to each other by a so-called distribution system.
Figure 2.28 illustrates a distribution system that connects three access
points, each of which services the nodes in some region. Each access
point operates on some channel in the appropriate frequency range, and
each AP will typically be on a different channel than its neighbors.
■ FIGURE 2.28 Access points connected to a distribution system.
The details of the distribution system are not important to this discus-
sion—it could be an Ethernet, for example. The only important point is
that the distribution network operates at the link layer, the same proto-
col layer as the wireless links. In other words, it does not depend on any
higher-level protocols (such as the network layer).
Although two nodes can communicate directly with each other if they
are within reach of each other, the idea behind this configuration is that
each node associates itself with one access point. For node A to commu-
nicate with node E, for example, A first sends a frame to its access point
(AP-1), which forwards the frame across the distribution system to AP-
3, which finally transmits the frame to E. How AP-1 knew to forward the
message to AP-3 is beyond the scope of 802.11; it may have used a bridg-
ing protocol. What 802.11 does specify is how nodes select their access
points and, more interestingly, how this algorithm works in light of nodes
moving from one cell to another.
The technique for selecting an AP is called scanning and involves the
following four steps:2.7 Wireless Networks
1. The node sends a Probe frame.
2. All APs within reach reply with a Probe Response frame.
3. The node selects one of the access points and sends that AP an Associ-
ation Request frame.
4. The AP replies with an Association Response frame.
A node engages this protocol whenever it joins the network, as well
as when it becomes unhappy with its current AP. This might happen, for
example, because the signal from its current AP has weakened due to the
node moving away from it. Whenever a node acquires a new AP, the new
AP notifies the old AP of the change (this happens in step 4) via the distri-
bution system.
■ FIGURE 2.29 Node mobility.
Consider the situation shown in Figure 2.29, where node C moves from
the cell serviced by AP-1 to the cell serviced by AP-2. As it moves, it sends
Probe frames, which eventually result in Probe Response frames from AP-
2. At some point, C prefers AP-2 over AP-1, and so it associates itself with
that access point.
The mechanism just described is called active scanning since the node
is actively searching for an access point. APs also periodically send a
Beacon frame that advertises the capabilities of the access point; these
include the transmission rates supported by the AP. This is called passive
133134
CHAPTER 2 Direct Links
scanning, and a node can change to this AP based on the Beacon frame
simply by sending an Association Request frame back to the access point.
Frame Format
Most of the 802.11 frame format, which is depicted in Figure 2.30, is
exactly what we would expect. The frame contains the source and des-
tination node addresses, each of which is 48 bits long; up to 2312 bytes
of data; and a 32-bit CRC. The Control field contains three subfields of
interest (not shown): a 6-bit Type field that indicates whether the frame
that carries data is an RTS or CTS frame or is being used by the scanning
algorithm and a pair of 1-bit fields—called ToDS and FromDS—that are
described below.
■ FIGURE 2.30 802.11 frame format.
The peculiar thing about the 802.11 frame format is that it contains
four, rather than two, addresses. How these addresses are interpreted
depends on the settings of the ToDS and FromDS bits in the frame’s Con-
trol field. This is to account for the possibility that the frame had to be
forwarded across the distribution system, which would mean that the
original sender is not necessarily the same as the most recent transmitting
node. Similar reasoning applies to the destination address. In the simplest
case, when one node is sending directly to another, both the DS bits are 0,
Addr1 identifies the target node, and Addr2 identifies the source node. In
the most complex case, both DS bits are set to 1, indicating that the mes-
sage went from a wireless node onto the distribution system, and then
from the distribution system to another wireless node. With both bits set,
Addr1 identifies the ultimate destination, Addr2 identifies the immediate
sender (the one that forwarded the frame from the distribution system to
the ultimate destination), Addr3 identifies the intermediate destination
(the one that accepted the frame from a wireless node and forwarded it
across the distribution system), and Addr4 identifies the original source.
In terms of the example given in Figure 2.28, Addr1 corresponds to E,
Addr2 identifies AP-3, Addr3 corresponds to AP-1, and Addr4 identifies A.2.7 Wireless Networks
Security of Wireless Links
One of the fairly obvious problems of wireless links compared to wires
or fibers is that you cannot be too sure where your data have gone. You
can probably figure out if they were received by the intended receiver, but
there is no telling how many other receivers might have also picked up
your transmission. So, if you are concerned about the privacy of your data,
wireless networks present a challenge.
Even if you are not concerned about data privacy—or perhaps have
taken care of it in some other way—you may be concerned about an
unauthorized user injecting data into your network. If nothing else, such
a user might be able to consume resources that you would prefer to con-
sume yourself, such as the finite bandwidth between your house and your
ISP.
For these reasons, wireless networks typically come with some sort of
mechanism to control access to both the link itself and the transmitted
data. These mechanisms are often categorized as wireless security. The
widely adopted WPA2 is described in Chapter 8.
2.7.3 Bluetooth (802.15.1)
Bluetooth fills the niche of very short-range communication between
mobile phones, PDAs, notebook computers, and other personal or periph-
eral devices. For example, Bluetooth can be used to connect a mobile
phone to a headset or a notebook computer to a keyboard. Roughly
speaking, Bluetooth is a more convenient alternative to connecting two
devices with a wire. In such applications, it is not necessary to pro-
vide much range or bandwidth. This means that Bluetooth radios can
use quite low power transmission, since transmission power is one of
the main factors affecting bandwidth and range of wireless links. This
matches the target applications for Bluetooth-enabled devices—most of
them are battery-powered (such as the ubiquitous phone headset), and
hence it is important that they do not consume much power.
Bluetooth operates in the license-exempt band at 2.45 GHz. Bluetooth
links have typical bandwidths around 1 to 3 Mbps and a range of about
10 m. For this reason, and because the communicating devices typically
belong to one individual or group, Bluetooth is sometimes categorized as
a Personal Area Network (PAN).
Bluetooth is specified by an industry consortium called the Bluetooth
Special Interest Group. It specifies an entire suite of protocols, going
135136
CHAPTER 2 Direct Links
beyond the link layer to define application protocols, which it calls pro-
files, for a range of applications. For example, there is a profile for synchro-
nizing a PDA with a personal computer. Another profile gives a mobile
computer access to a wired LAN in the manner of 802.11, although this
was not Bluetooth’s original goal. The IEEE 802.15.1 standard is based on
Bluetooth but excludes the application protocols.
The basic Bluetooth network configuration, called a piconet, consists
of a master device and up to seven slave devices, as shown in Figure 2.31.
Any communication is between the master and a slave; the slaves do not
communicate directly with each other. Because slaves have a simpler role,
their Bluetooth hardware and software can be simpler and cheaper.
■ FIGURE 2.31 A Bluetooth piconet.
Since Bluetooth operates in a license-exempt band, it is required to
use a spread spectrum technique to deal with possible interference in
the band. It uses frequency hopping with 79 channels (frequencies), using2.8 Access Networks
each for 625 µs at a time. This provides a natural time slot for Bluetooth
to use for synchronous time division multiplexing. A frame takes up one,
three, or five consecutive time slots. Only the master can start to transmit
in odd-numbered slots. A slave can start to transmit in an even-numbered
slot—but only in response to a request from the master during the previ-
ous slot, thereby preventing any contention between the slave devices.
A slave device can be parked; that is, it is set to an inactive, low-power
state. A parked device cannot communicate on the piconet; it can only be
reactivated by the master. A piconet can have up to 255 parked devices in
addition to its active slave devices.
In the realm of very low-power, short-range communication, there
are a few other technologies besides Bluetooth. One of these is ZigBee,
devised by the ZigBee alliance and standardized as IEEE 802.15.4. It is
designed for situations where the bandwidth requirements are low and
power consumption must be very low to give very long battery life. It is
also intended to be simpler and cheaper than Bluetooth, making it feasi-
ble to incorporate in cheaper devices such as sensors. Sensors are becom-
ing an increasingly important class of networked devices as technology
advances to the point where very cheap small devices can be deployed in
large quantities to monitor things like temperature, humidity, and energy
consumption in a building.
2.8 ACCESS NETWORKS
In addition to the Ethernet and Wi-Fi connections we typically use to
connect to the Internet at home, at work, at school, and in many pub-
lic spaces, most of us connect to the Internet over an access or broadband
service that we buy from an ISP. This section describes two such technolo-
gies: Passive Optical Networks (PONs), commonly referred to as fiber-to-
the-home, and cellular networks that connect our mobile devices. In both
cases, the networks are multiaccess (like Ethernet and Wi-Fi), but as we
will see, their approach to mediating access is quite different.
To set a little more context, ISPs (e.g., telco or cable companies) often
operate a national backbone, and connected to the periphery of that
backbone are hundreds or thousands of edge sites, each of which serves
a city or neighborhood. These edge sites are commonly called Central
Offices in the telco world and Head Ends in the cable world, but despite
their names implying “centralized” and “root of the hierarchy,” these sites
are at the very edge of the ISP’s network; the ISP side of the last mile that
137138
CHAPTER 2 Direct Links
directly connects to customers. PONs and cellular access networks are
anchored in these facilities.3
2.8.1 Passive Optical Network
PON is the technology most commonly used to deliver fiber-based broad-
band to homes and businesses. PON adopts a point-to-multipoint design,
which means the network is structured as a tree, with a single point start-
ing in the ISP’s network and then fanning out to reach up to 1024 homes.
PON gets its name from the fact that the splitters are passive: they forward
optical signals downstream and upstream without actively storing and
forwarding frames. In this way, they are the optical variant of repeaters
used in the classic Ethernet. Framing then happens at the source in the
ISP’s premises, in a device called an Optical Line Terminal (OLT), and at
the endpoints in individual homes, in a device called an Optical Network
Unit (ONU).
Figure 2.32 shows an example PON, simplified to depict just one ONU
and one OLT. In practice, a central office would include multiple OLTs
connecting to thousands of customer homes. For completeness, Fig-
ure 2.32 also includes two other details about how the PON is connected
to the ISP’s backbone (and hence to the rest of the Internet). The Agg
Switch aggregates traffic from a set of OLTs, and the BNG (Broadband
Network Gateway) is a piece of telco equipment that, among many other
things, meters Internet traffic for the sake of billing. As its name implies,
the BNG is effectively the gateway between the access network (every-
thing to the left of the BNG) and the Internet (everything to the right of
the BNG).
Because the splitters are passive, PON has to implement some form
of multiaccess protocol. The approach it adopts can be summarized as
follows. First, upstream and downstream traffic are transmitted on two
different optical wavelengths, so they are completely independent of each
other. Downstream traffic starts at the OLT, and the signal is propagated
down every link in the PON. As a consequence, every frame reaches
every ONU. This device then looks at a unique identifier in the individual
frames sent over the wavelength and either keeps the frame (if the iden-
tifier is for it) or drops it (if not). Encryption is used to keep ONUs from
eavesdropping on their neighbors’ traffic.
3 DSL is the legacy, copper-based counterpart to PON. DSL links are also terminated
in telco central offices, but we do not describe this technology, since it is being
phased out.2.8 Access Networks
■ FIGURE 2.32 An example PON that connects OLTs in the central oﬃce to ONUs in homes and businesses.
Upstream traffic is then time-division multiplexed on the upstream
wavelength, with each ONU periodically getting a turn to transmit.
Because the ONUs are distributed over a fairly wide area (measured in
kilometers) and at different distances from the OLT, it is not practical for
them to transmit based on synchronized clocks, as in SONET. Instead,
the ONT transmits grants to the individual ONUs, giving them a time
interval during which they can transmit. In other words, the single OLT
is responsible for centrally implementing the round-robin sharing of the
shared PON. This includes the possibility that the OLT can grant each
ONU a different share of time, effectively implementing different levels of
service.
PON is similar to Ethernet in the sense that it defines a sharing algo-
rithm that has evolved over time to accommodate higher and higher
bandwidths. G-PON (Gigabit-PON) is the most widely deployed today,
supporting a bandwidth of 2.25 Gbps. XGS-PON (10 Gigabit-PON) is just
now starting to be deployed.
2.8.2 Cellular Network
While cellular telephone technology had its roots in analog voice com-
munication, data services based on cellular standards are now the norm.
Like Wi-Fi, cellular networks transmit data at certain bandwidths in the
radio spectrum. Unlike Wi-Fi, which permits anyone to use a channel at
either 2.4 or 5 GHz (all you have to do is set up a base station, as many of
us do in our homes), exclusive use of various frequency bands have been
auctioned off and licensed to service providers, who in turn sell mobile
access service to their subscribers.
139140
CHAPTER 2 Direct Links
The frequency bands that are used for cellular networks vary around
the world and are complicated by the fact that ISPs often simultane-
ously support both old/legacy technologies and new/next-generation
technologies, each of which occupies a different frequency band. The
high-level summary is that traditional cellular technologies range from
700 MHz to 2400 MHz, with new mid-spectrum allocations now happen-
ing at 6 GHz and millimeter-wave (mmWave) allocations opening above
24 GHz.
Citizens Broadband Radio Service (CBRS)
In addition to the licensed bands, there is also an unlicensed band at 3.5 GHz
set aside in North America, called Citizens Broadband Radio Service (CBRS),
that anyone with a cellular radio can use. Similar unlicensed bands are being
set up in other countries as well. This opens the door for setting up private
cellular networks, for example, within a university campus, an enterprise, or
a manufacturing plant.
To be more precise, the CBRS band allows three tiers of users to share
the spectrum: ﬁrst right of use goes to the original owners of this spectrum,
naval radars, and satellite ground stations; followed by priority users who
receive this right over 10-MHz bands for three years via regional auctions;
and ﬁnally the rest of the population, who can access and utilize a portion
of this band as long as they ﬁrst check with a central database of registered
users.
Like 802.11, cellular technology relies on the use of base stations that
are connected to a wired network. In the case of the cellular network, the
base stations are often called Broadband Base Units (BBUs), the mobile
devices that connect to them are usually referred to as User Equipment
(UE), and the set of BBUs are anchored at an Evolved Packet Core (EPC)
hosted in a central office. The wireless network served by the EPC is often
called a Radio Access Network (RAN).
BBUs officially go by another name—Evolved NodeB, often abbrevi-
ated eNodeB or eNB—where NodeB is what the radio unit was called in
an early incarnation of cellular networks (and has since evolved). Given
that the cellular world continues to evolve at a rapid pace and eNBs are
soon to be upgraded to gNBs, we have decided to use the more generic
and less cryptic BBU.
Figure 2.33 depicts one possible configuration of the end-to-end sce-
nario, with a few additional bits of detail. The EPC has multiple sub-2.8 Access Networks
components, including an MME (Mobility Management Entity), an HSS
(Home Subscriber Server), and an S/PGW (Session/Packet Gateway) pair;
the first tracks and manages the movement of UEs throughout the RAN,
the second is a database that contains subscriber-related information,
and the Gateway pair processes and forwards packets between the RAN
and the Internet (it forms the EPC’s user plane). We say “one possible con-
figuration” because the cellular standards allow wide variability in how
many S/PGWs a given MME is responsible for, making it possible for a sin-
gle MME to manage mobility across a wide geographic area that is served
by multiple central offices. Finally, while not explicitly illustrated in Fig-
ure 2.33, it is sometimes the case that the ISP’s PON is used to connect the
remote BBUs back to the central office.
■ FIGURE 2.33 A Radio Access Network (RAN) connecting a set of cellular devices (UEs) to an Evolved Packet Core (EPC)
hosted in a central oﬃce.
The geographic area served by a BBU’s antenna is called a cell. A BBU
could serve a single cell or use multiple directional antennas to serve mul-
tiple cells. Cells do not have crisp boundaries, and they overlap. Where
they overlap, a UE could potentially communicate with multiple BBUs.
At any time, however, the UE is in communication with, and under the
control of, just one BBU. As the device begins to leave a cell, it moves
into an area of overlap with one or more other cells. The current BBU
senses the weakening signal from the phone and gives control of the
device to whichever base station is receiving the strongest signal from it.
If the device is involved in a call or other network session at the time, the
session must be transferred to the new base station in what is called a
handoff. The decision-making process for handoffs is under the purview
141142
CHAPTER 2 Direct Links
of the MME, which has historically been a proprietary aspect of the cel-
lular equipment vendors (although open-source MME implementations
are now starting to be available).
There have been multiple generations of protocols implementing the
cellular network, colloquially known as 1G, 2G, 3G, and so on. The first
two generations supported only voice, with 3G defining the transition to
broadband access, supporting data rates measured in hundreds of kilo-
bits per second. Today, the industry is at 4G (supporting data rates of
typically a few megabits per second) and is in the process of transition-
ing to 5G (with the promise of a 10-fold increase in data rates).
As of 3G, the generational designation actually corresponds to a stan-
dard defined by the 3GPP (3rd Generation Partnership Project). Even
though its name has “3G” in it, the 3GPP continues to define the standard
for 4G and 5G, each of which corresponds to a release of the standard.
Release 15, which is now published, is considered the demarcation point
between 4G and 5G. By another name, this sequence of releases and gen-
erations is called LTE, which stands for Long-Term Evolution. The main
takeaway is that while standards are published as a sequence of discrete
releases, the industry as a whole has been on a fairly well-defined evolu-
tionary path known as LTE. This section uses LTE terminology but high-
lights the changes coming with 5G when appropriate.
The main innovation of LTE’s air interface is how it allocates the avail-
able radio spectrum to UEs. Unlike Wi-Fi, which is contention based, LTE
uses a reservation-based strategy. This difference is rooted in each sys-
tem’s fundamental assumption about utilization: Wi-Fi assumes a lightly
loaded network (and hence optimistically transmits when the wireless
link is idle and backs off if contention is detected), while cellular networks
assume (and strive for) high utilization (and hence explicitly assign differ-
ent users to different “shares” of the available radio spectrum).
The state-of-the-art media access mechanism for LTE is called Orthog-
onal Frequency-Division Multiple Access (OFDMA). The idea is to multi-
plex data over a set of 12 orthogonal subcarrier frequencies, each of which
is modulated independently. The “Multiple Access” in OFDMA implies
that data can simultaneously be sent on behalf of multiple users, each
on a different subcarrier frequency and for a different duration of time.
The subbands are narrow (e.g., 15 kHz), but the coding of user data into
OFDMA symbols is designed to minimize the risk of data loss due to inter-
ference between adjacent bands.2.8 Access Networks
The use of OFDMA naturally leads to conceptualizing the radio spec-
trum as a two-dimensional resource, as shown in Figure 2.34. The min-
imal schedulable unit, called a Resource Element (RE), corresponds to a
15-kHz-wide band around one subcarrier frequency and the time it takes
to transmit one OFDMA symbol. The number of bits that can be encoded
in each symbol depends on the modulation rate, so, for example, using
Quadrature Amplitude Modulation (QAM), 16-QAM yields 4 bits per sym-
bol and 64-QAM yields 6 bits per symbol.
■ FIGURE 2.34 The available radio spectrum abstractly represented by a two-dimensional grid of schedulable Resource
Elements.
A scheduler makes allocation decisions at the granularity of blocks of
7 × 12 = 84 resource elements, called a Physical Resource Block (PRB).
Figure 2.34 shows two back-to-back PRBs, where UEs are depicted by
different-colored blocks. Of course, time continues to flow along one axis,
and depending on the size of the licensed frequency band, there may be
many more subcarrier slots (and hence PRBs) available along the other
axis, so the scheduler is essentially scheduling a sequence of PRBs for
transmission.
The 1-ms Transmission Time Interval (TTI) shown in Figure 2.34 corre-
sponds to the time frame in which the BBU receives feedback from UEs
about the quality of the signal they are experiencing. This feedback, called
a Channel Quality Indicator (CQI), essentially reports the observed signal-
to-noise ratio, which impacts the UE’s ability to recover the data bits. The
base station then uses this information to adapt how it allocates the avail-
able radio spectrum to the UEs it is serving.
143144
CHAPTER 2 Direct Links
Up to this point, the description of how we schedule the radio spec-
trum is specific to 4G. The transition from 4G to 5G introduces additional
degrees of freedom in how the radio spectrum is scheduled, making it
possible to adapt the cellular network to a more diverse set of devices and
applications domains.
Fundamentally, 5G defines a family of waveforms—unlike 4G, which
specified only one waveform—each optimized for a different band in the
radio spectrum.4 The bands with carrier frequencies below 1 GHz are
designed to deliver mobile broadband and massive Internet of Things
(IoT) services with a primary focus on range. Carrier frequencies between
1 GHz and 6 GHz are designed to offer wider bandwidths, focusing on
mobile broadband and mission-critical applications. Carrier frequencies
above 24 GHz (mmWaves) are designed to provide superwide bandwidths
over short, line-of-sight coverage.
These different waveforms affect the scheduling and subcarrier inter-
vals (i.e., the “size” of the Resource Elements just described).
■For sub-1-GHz bands, 5G allows maximum 50 MHz bandwidths. In
this case, there are two waveforms: one with subcarrier spacing of
15 kHz and another of 30 kHz. (We used 15 kHz in the example
shown in Figure 2.34.) The corresponding scheduling intervals are
0.5 ms and 0.25 ms, respectively. (We used 0.5 ms in the example
shown in Figure 2.34.)
■For 1-GHz to 6-GHz bands, maximum bandwidths go up to 100 MHz.
Correspondingly, there are three waveforms, with subcarrier spac-
ings of 15 kHz, 30 kHz, and 60 kHz, corresponding to scheduling
intervals of 0.5 ms, 0.25 ms, and 0.125 ms, respectively.
■For millimeter bands, bandwidths may go up to 400 MHz. There are
two waveforms, with subcarrier spacings of 60 kHz and 120 kHz.
Both have scheduling intervals of 0.125 ms.
This range of options is important because it adds another degree of
freedom to the scheduler. In addition to allocating resource blocks to
users, it has the ability to dynamically adjust the size of the resource
blocks by changing the wave form being used in the band it is responsible
for scheduling.
4 A waveform is the frequency-, amplitude-, and phase shift-independent property
(shape) of a signal. A sine wave is an example waveform.2.8 Access Networks
Whether 4G or 5G, the scheduling algorithm is a challenging opti-
mization problem, with the objective of simultaneously (a) maximizing
utilization of the available frequency band and (b) ensuring that every
UE receives the level of service it requires. This algorithm is not speci-
fied by 3GPP but rather is the proprietary intellectual property of the BBU
vendors.
s we start to explore how softwarization is transforming the net-
work, we should recognize that it is the access network that con-
nects homes, businesses, and mobile users to the Internet that is
undergoing the most radical change. The ﬁber-to-the-home and
cellular networks described in Section 2.8 are currently con-
structed from complex hardware appliances (e.g., OLTs, BNGs,
BBUs, EPCs). Not only have these devices historically been
closed and proprietary, but the vendors that sell them have
typically bundled a broad and diverse collection of func-
tionality in each. As a consequence, they have become
expensive to build, complicated to operate, and slow to
change.
A
PERSPECTIVE: RACE TO THE EDGE
In response, network operators are actively transition-
ing from these purpose-built appliances to open soft-
ware running on commodity servers, switches, and
access devices. This initiative is often called CORD, which
is an acronym for Central Ofﬁce Rearchitected as a
Datacenter, and as the name suggests, the idea is to build
the telco central ofﬁce (or the cable head end, resulting in
the acronym HERD) using exactly the same technologies as in
the large datacenters that make up the cloud.
The motivation for operators to do this is in part to beneﬁt from
the cost savings that come from replacing purpose-built appliances
with commodity hardware, but it is mostly driven by the need to acceler-
ate the pace of innovation. Their goal is to enable new classes of edge
services—e.g., public safety, autonomous vehicles, automated factories, IoT, immer-
sive user interfaces—that beneﬁt from low-latency connectivity to end users and,
more importantly, to the increasing number of devices those users surround them-
selves with. This results in a multitier cloud similar to the one shown in Figure 2.35.
145146
CHAPTER 2 Direct Links
■ FIGURE 2.35 Emerging multitier cloud including datacenter-based public clouds, IXP-hosted distributed clouds, and
access-based edge clouds, such as CORD. While there are on the order of 150 IXP-hosted clouds worldwide, we can expect
there to be thousands or even tens of thousands of edge clouds.
This is all part of the growing trend to move functionality out of the datacen-
ter and closer to the network edge, a trend that puts cloud providers and network
operators on a collision course. Cloud providers, in pursuit of low-latency/high-
bandwidth applications, are moving out of the datacenter and toward the edge at
the same time network operators are adopting the best practices and technologies
of the cloud to the edge that already exists and implements the access network. It
is impossible to say how this will all play out over time; both industries have their
particular advantages.
On the one hand, cloud providers believe that by saturating metro areas with
edge clusters and abstracting away the access network, they can build an edge
presence with low enough latency and high enough bandwidth to serve the next
generation of edge applications. In this scenario, the access network remains a dumb
bit-pipe, allowing cloud providers to excel at what they do best: run scalable cloud
services on commodity hardware.
On the other hand, network operators believe that by building the next-generation
access network using cloud technology, they will be able to colocate edge applica-
tions in the access network. This scenario comes with built-in advantages: an existing
and widely distributed physical footprint, existing operational support, and native
support for both mobility and guaranteed service.
While acknowledging both of these possibilities, there is a third outcome that
is not only worth considering but also worth working toward: the democratization
of the network edge. The idea is to make the access-edge cloud accessible to any-
one and not strictly the domain of incumbent cloud providers or network operators.
There are three reasons to be optimistic about this possibility:
1. Hardware and software for the access network are becoming commoditized and
open. This is a key enabler that we were just talking about. If it helps telcos and
cablecos be agile, then it can provide the same value to anyone.Exercises
2. There is demand. Enterprises in the automotive, factory, and warehouse space
increasingly want to deploy private 5G networks for a variety of physical automa-
tion use cases (e.g., a garage where a remote valet parks your car or a factory ﬂoor
making use of automation robots).
3. Spectrum is becoming available. 5G is opening up for use in an unlicensed or
lightly licensed model in the U.S. and Germany as two prime examples, with other
countries soon to follow. This means 5G should have around 100–200 MHz of
spectrum available for private use.
In short, the access network has historically been the purview of the telcos, cable-
cos, and the vendors that sell them proprietary boxes, but the softwarization and
virtualization of the access network opens the door for anyone (from smart cities to
underserved rural areas to apartment complexes to manufacturing plants) to estab-
lish an access-edge cloud and connect it to the public Internet. We expect it to
become as easy to do this as it is today to deploy a Wi-Fi router. Doing so not only
brings the access-edge into new (edgier) environments but also has the potential to
open the access network to developers that instinctively go where there are oppor-
tunities to innovate.
I BROADER PERSPECTIVE
■To continue reading about the cloudification of the Internet, see the
text section Perspective: Virtual Networks All the Way Down.
■To learn more about the transformation taking place in access net-
works, we recommend: CORD: Central Office Re-architectured as a
Datacenter (Peterson, et al., IEEE Communications, Oct 2016) and
Democratizing the Network Edge (Peterson, et al., ACM SIGCOMM
CCR, April 2019).
